{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. Environment Config\n",
        "##1.1 conda installation"
      ],
      "metadata": {
        "id": "Zxv9YQXcZMIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "id": "8vqSZqWYZC2Z",
        "outputId": "f5cb1f35-9708-4db7-ece2-c671101c1d6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "ğŸ“¦ Installing...\n",
            "ğŸ“Œ Adjusting configuration...\n",
            "ğŸ©¹ Patching environment...\n",
            "â² Done in 0:00:10\n",
            "ğŸ” Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.2 3DFuse depends"
      ],
      "metadata": {
        "id": "En2llOhNZgtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/KU-CVLAB/3DFuse.git\n",
        "%cd /content/3DFuse\n",
        "!conda create -n 3DFuse python=3.8"
      ],
      "metadata": {
        "id": "EaFg2TI_ZyGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 3DFuse\n",
        "!/usr/local/envs/3DFuse/bin/python -m pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!/usr/local/envs/3DFuse/bin/python -m pip install git+https://github.com/facebookresearch/pytorch3d@c8af1c45ca9f4fdd4e59b49172ca74983ff3147a#egg=pytorch3d\n",
        "!/usr/local/envs/3DFuse/bin/python -m pip install -r requirements.txt\n",
        "!/usr/local/envs/3DFuse/bin/python -m pip install ipykernel"
      ],
      "metadata": {
        "id": "VWoBpL-gbBiJ",
        "outputId": "12e185ad-ae7a-4a21-cf3f-e498ec32643a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3DFuse\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Collecting torch==1.12.1+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp38-cp38-linux_x86_64.whl (1837.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m830.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.1+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp38-cp38-linux_x86_64.whl (23.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.12.1\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp38-cp38-linux_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions (from torch==1.12.1+cu113)\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting numpy (from torchvision==0.13.1+cu113)\n",
            "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from torchvision==0.13.1+cu113)\n",
            "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.13.1+cu113)\n",
            "  Downloading Pillow-9.5.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2 (from requests->torchvision==0.13.1+cu113)\n",
            "  Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m195.9/195.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5 (from requests->torchvision==0.13.1+cu113)\n",
            "  Downloading https://download.pytorch.org/whl/idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1 (from requests->torchvision==0.13.1+cu113)\n",
            "  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m123.2/123.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17 (from requests->torchvision==0.13.1+cu113)\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m157.0/157.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, typing-extensions, pillow, numpy, idna, charset-normalizer, certifi, torch, requests, torchvision, torchaudio\n",
            "Successfully installed certifi-2023.5.7 charset-normalizer-3.1.0 idna-3.4 numpy-1.24.3 pillow-9.5.0 requests-2.30.0 torch-1.12.1+cu113 torchaudio-0.12.1+cu113 torchvision-0.13.1+cu113 typing-extensions-4.5.0 urllib3-2.0.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch3d\n",
            "  Cloning https://github.com/facebookresearch/pytorch3d (to revision c8af1c45ca9f4fdd4e59b49172ca74983ff3147a) to /tmp/pip-install-a4rbl3pz/pytorch3d_f98e0cbb1aa64bbd824f2c5ef34eecb7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorch3d /tmp/pip-install-a4rbl3pz/pytorch3d_f98e0cbb1aa64bbd824f2c5ef34eecb7\n",
            "  Running command git rev-parse -q --verify 'sha^c8af1c45ca9f4fdd4e59b49172ca74983ff3147a'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/pytorch3d c8af1c45ca9f4fdd4e59b49172ca74983ff3147a\n",
            "  Running command git checkout -q c8af1c45ca9f4fdd4e59b49172ca74983ff3147a\n",
            "  Resolved https://github.com/facebookresearch/pytorch3d to commit c8af1c45ca9f4fdd4e59b49172ca74983ff3147a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fvcore (from pytorch3d)\n",
            "  Using cached fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath (from pytorch3d)\n",
            "  Using cached iopath-0.1.10.tar.gz (42 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from fvcore->pytorch3d) (1.24.3)\n",
            "Collecting yacs>=0.1.6 (from fvcore->pytorch3d)\n",
            "  Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1 (from fvcore->pytorch3d)\n",
            "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm (from fvcore->pytorch3d)\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor>=1.1 (from fvcore->pytorch3d)\n",
            "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from fvcore->pytorch3d) (9.5.0)\n",
            "Collecting tabulate (from fvcore->pytorch3d)\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from iopath->pytorch3d) (4.5.0)\n",
            "Collecting portalocker (from iopath->pytorch3d)\n",
            "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: pytorch3d, fvcore, iopath\n",
            "  Building wheel for pytorch3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch3d: filename=pytorch3d-0.7.2-cp38-cp38-linux_x86_64.whl size=5963210 sha256=58a2dfd898c2945a55545041dfc50ea7ce51659162d2938630bdba39375f0984\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/6a/33/c62d7b0f247686a7f631cf6380967f1f54445eff3279e455aa\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61405 sha256=7f173243ecaba6566bba6db8e3f1499e4dbfa4bddd17e7cea056a53e2ffba4cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31531 sha256=bad5b4257b916bb8c31a8cb13a2305b808cb4bdc2708a506fffe6c7825e8a2fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built pytorch3d fvcore iopath\n",
            "Installing collected packages: tqdm, termcolor, tabulate, pyyaml, portalocker, yacs, iopath, fvcore, pytorch3d\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.7.0 pytorch3d-0.7.2 pyyaml-6.0 tabulate-0.9.0 termcolor-2.3.0 tqdm-4.65.0 yacs-0.1.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/point-e (from -r requirements.txt (line 29))\n",
            "  Cloning https://github.com/openai/point-e to /tmp/pip-req-build-emqtmrdt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/point-e /tmp/pip-req-build-emqtmrdt\n",
            "  Resolved https://github.com/openai/point-e to commit fc8a607c08a3ea804cc82bf1ef8628f88a3a5d2f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/diffusers (from -r requirements.txt (line 30))\n",
            "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-lb7ob9dm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-lb7ob9dm\n",
            "  Resolved https://github.com/huggingface/diffusers to commit 94a0c644a8ce5b05a969859e0814ef4883ac870e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/cloneofsimo/lora.git (from -r requirements.txt (line 31))\n",
            "  Cloning https://github.com/cloneofsimo/lora.git to /tmp/pip-req-build-uzx72t7f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cloneofsimo/lora.git /tmp/pip-req-build-uzx72t7f\n",
            "  Resolved https://github.com/cloneofsimo/lora.git to commit bdd51b04c49fa90a88919a19850ec3b4cf3c5ecd\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/Ir1d/image-background-remove-tool@2b68f5276d0f2e90f607c7845c60d2bddb79d5ba (from -r requirements.txt (line 32))\n",
            "  Cloning https://github.com/Ir1d/image-background-remove-tool (to revision 2b68f5276d0f2e90f607c7845c60d2bddb79d5ba) to /tmp/pip-req-build-iokx50kb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Ir1d/image-background-remove-tool /tmp/pip-req-build-iokx50kb\n",
            "  Running command git rev-parse -q --verify 'sha^2b68f5276d0f2e90f607c7845c60d2bddb79d5ba'\n",
            "  Running command git fetch -q https://github.com/Ir1d/image-background-remove-tool 2b68f5276d0f2e90f607c7845c60d2bddb79d5ba\n",
            "  Resolved https://github.com/Ir1d/image-background-remove-tool to commit 2b68f5276d0f2e90f607c7845c60d2bddb79d5ba\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio (from -r requirements.txt (line 1))\n",
            "  Using cached gradio-3.29.0-py3-none-any.whl (17.3 MB)\n",
            "Collecting albumentations==1.3.0 (from -r requirements.txt (line 2))\n",
            "  Using cached albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
            "Collecting opencv-contrib-python==4.3.0.36 (from -r requirements.txt (line 3))\n",
            "  Downloading opencv_contrib_python-4.3.0.36-cp38-cp38-manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio==2.9.0 (from -r requirements.txt (line 4))\n",
            "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio-ffmpeg==0.4.2 (from -r requirements.txt (line 5))\n",
            "  Downloading imageio_ffmpeg-0.4.2-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning==1.5.0 (from -r requirements.txt (line 6))\n",
            "  Downloading pytorch_lightning-1.5.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf==2.1.1 (from -r requirements.txt (line 7))\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting test-tube>=0.7.5 (from -r requirements.txt (line 8))\n",
            "  Downloading test_tube-0.7.5.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting streamlit==1.12.1 (from -r requirements.txt (line 9))\n",
            "  Downloading streamlit-1.12.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.3.0 (from -r requirements.txt (line 10))\n",
            "  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Collecting transformers (from -r requirements.txt (line 11))\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webdataset==0.2.5 (from -r requirements.txt (line 12))\n",
            "  Downloading webdataset-0.2.5-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kornia==0.6 (from -r requirements.txt (line 13))\n",
            "  Downloading kornia-0.6.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m367.1/367.1 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting open_clip_torch==2.0.2 (from -r requirements.txt (line 14))\n",
            "  Downloading open_clip_torch-2.0.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting invisible-watermark>=0.1.5 (from -r requirements.txt (line 15))\n",
            "  Downloading invisible_watermark-0.1.5-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit-drawable-canvas==0.8.0 (from -r requirements.txt (line 16))\n",
            "  Downloading streamlit_drawable_canvas-0.8.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics==0.6.0 (from -r requirements.txt (line 17))\n",
            "  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m329.4/329.4 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm==0.6.12 (from -r requirements.txt (line 18))\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict==2.4.0 (from -r requirements.txt (line 19))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting yapf==0.32.0 (from -r requirements.txt (line 20))\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.2/190.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prettytable==3.6.0 (from -r requirements.txt (line 21))\n",
            "  Downloading prettytable-3.6.0-py3-none-any.whl (27 kB)\n",
            "Collecting safetensors==0.2.7 (from -r requirements.txt (line 22))\n",
            "  Downloading safetensors-0.2.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting basicsr==1.4.2 (from -r requirements.txt (line 23))\n",
            "  Downloading basicsr-1.4.2.tar.gz (172 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pydantic (from -r requirements.txt (line 24))\n",
            "  Downloading pydantic-1.10.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click (from -r requirements.txt (line 25))\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting easydict (from -r requirements.txt (line 26))\n",
            "  Downloading easydict-1.10.tar.gz (6.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from -r requirements.txt (line 27)) (0.9.0)\n",
            "Collecting plotly (from -r requirements.txt (line 28))\n",
            "  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate (from -r requirements.txt (line 33))\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from albumentations==1.3.0->-r requirements.txt (line 2)) (1.24.3)\n",
            "Collecting scipy (from albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image>=0.16.1 (from albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading scikit_image-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from albumentations==1.3.0->-r requirements.txt (line 2)) (6.0)\n",
            "Collecting qudida>=0.0.4 (from albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Collecting opencv-python-headless>=4.1.1 (from albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from imageio==2.9.0->-r requirements.txt (line 4)) (9.5.0)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from pytorch-lightning==1.5.0->-r requirements.txt (line 6)) (1.12.1+cu113)\n",
            "Collecting future>=0.17.1 (from pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading future-0.18.3.tar.gz (840 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from pytorch-lightning==1.5.0->-r requirements.txt (line 6)) (4.65.0)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0 (from pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard>=2.2.0 (from pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyDeprecate==0.3.1 (from pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting packaging>=17.0 (from pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from pytorch-lightning==1.5.0->-r requirements.txt (line 6)) (4.5.0)\n",
            "Collecting antlr4-python3-runtime==4.8 (from omegaconf==2.1.1->-r requirements.txt (line 7))\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting altair>=3.2.0 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading altair-5.0.0-py3-none-any.whl (477 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m477.4/477.4 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blinker>=1.0.0 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Collecting cachetools>=4.0 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting importlib-metadata>=1.4 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Collecting pandas>=0.21.0 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading pandas-2.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<4,>=3.12 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=4.0 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading pyarrow-12.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.0/39.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck>=0.1.dev5 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pympler>=0.9 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.4 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from streamlit==1.12.1->-r requirements.txt (line 9)) (2.30.0)\n",
            "Collecting rich>=10.11.0 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading rich-13.3.5-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m238.7/238.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semver (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading semver-3.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting toml (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting tornado>=5.0 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading tornado-6.3.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m426.8/426.8 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzlocal>=1.1 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading tzlocal-4.3-py3-none-any.whl (20 kB)\n",
            "Collecting validators>=0.2 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gitpython!=3.1.19 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchdog (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting braceexpand (from webdataset==0.2.5->-r requirements.txt (line 12))\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from open_clip_torch==2.0.2->-r requirements.txt (line 14)) (0.13.1+cu113)\n",
            "Collecting ftfy (from open_clip_torch==2.0.2->-r requirements.txt (line 14))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex (from open_clip_torch==2.0.2->-r requirements.txt (line 14))\n",
            "  Downloading regex-2023.5.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m771.9/771.9 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub (from open_clip_torch==2.0.2->-r requirements.txt (line 14))\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wcwidth (from prettytable==3.6.0->-r requirements.txt (line 21))\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Collecting lmdb (from basicsr==1.4.2->-r requirements.txt (line 23))\n",
            "  Downloading lmdb-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.9/298.9 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python (from basicsr==1.4.2->-r requirements.txt (line 23))\n",
            "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tb-nightly (from basicsr==1.4.2->-r requirements.txt (line 23))\n",
            "  Downloading tb_nightly-2.14.0a20230509-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.1 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading gradio_client-0.2.2-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.9/287.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py[linkify]>=2.0.0 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markupsafe (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting matplotlib (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading matplotlib-3.7.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdit-py-plugins<=0.3.3 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading orjson-3.8.12-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pygments>=2.12.0 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading websockets-11.0.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from transformers->-r requirements.txt (line 11))\n",
            "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r requirements.txt (line 11))\n",
            "  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx (from invisible-watermark>=0.1.5->-r requirements.txt (line 15))\n",
            "  Downloading onnx-1.14.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime (from invisible-watermark>=0.1.5->-r requirements.txt (line 15))\n",
            "  Downloading onnxruntime-1.14.1-cp38-cp38-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyWavelets>=1.1.1 (from invisible-watermark>=0.1.5->-r requirements.txt (line 15))\n",
            "  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tenacity>=6.2.0 (from plotly->-r requirements.txt (line 28))\n",
            "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
            "Collecting clip@ git+https://github.com/openai/CLIP.git (from point-e==0.0.0->-r requirements.txt (line 29))\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-install-9fgcd1vk/clip_18a98d1dfdac4298abb3e7eabbd78036\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-install-9fgcd1vk/clip_18a98d1dfdac4298abb3e7eabbd78036\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fire (from point-e==0.0.0->-r requirements.txt (line 29))\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting humanize (from point-e==0.0.0->-r requirements.txt (line 29))\n",
            "  Downloading humanize-4.6.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from lora-diffusion==0.1.7->-r requirements.txt (line 31))\n",
            "  Downloading wandb-0.15.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mediapipe (from lora-diffusion==0.1.7->-r requirements.txt (line 31))\n",
            "  Downloading mediapipe-0.9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.4 (from streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow (from imageio==2.9.0->-r requirements.txt (line 4))\n",
            "  Downloading Pillow-9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing~=3.7.4.3 (from carvekit==4.1.0->-r requirements.txt (line 32))\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencv-python (from basicsr==1.4.2->-r requirements.txt (line 23))\n",
            "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.11.1 (from albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru~=0.6.0 (from carvekit==4.1.0->-r requirements.txt (line 32))\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading uvicorn-0.17.6-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading fastapi-0.78.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette~=0.19.1 (from carvekit==4.1.0->-r requirements.txt (line 32))\n",
            "  Downloading starlette-0.19.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic (from -r requirements.txt (line 24))\n",
            "  Downloading pydantic-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm>=4.41.0 (from pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools~=62.3.2 (from carvekit==4.1.0->-r requirements.txt (line 32))\n",
            "  Downloading setuptools-62.3.4-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading aiofiles-0.8.0-py3-none-any.whl (13 kB)\n",
            "Collecting psutil (from accelerate->-r requirements.txt (line 33))\n",
            "  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m282.1/282.1 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema>=3.0 (from altair>=3.2.0->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting toolz (from altair>=3.2.0->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0 (from starlette~=0.19.1->carvekit==4.1.0->-r requirements.txt (line 32))\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs>=17.3.0 (from aiohttp->gradio->-r requirements.txt (line 1))\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from aiohttp->gradio->-r requirements.txt (line 1)) (3.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->gradio->-r requirements.txt (line 1))\n",
            "  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio->-r requirements.txt (line 1))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->gradio->-r requirements.txt (line 1))\n",
            "  Downloading yarl-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m266.9/266.9 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio->-r requirements.txt (line 1))\n",
            "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.3/161.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio->-r requirements.txt (line 1))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zipp>=0.5 (from importlib-metadata>=1.4->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 1))\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 1))\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=0.21.0->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzdata>=2022.1 (from pandas>=0.21.0->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six>=1.5 (from python-dateutil->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting scikit-learn>=0.19.1 (from qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests>=2.4->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from requests>=2.4->streamlit==1.12.1->-r requirements.txt (line 9)) (2023.5.7)\n",
            "Collecting charset-normalizer<4.0,>=2.0 (from aiohttp->gradio->-r requirements.txt (line 1))\n",
            "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from requests>=2.4->streamlit==1.12.1->-r requirements.txt (line 9)) (3.4)\n",
            "Collecting scipy (from albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading scipy-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx>=2.8 (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tifffile>=2019.7.26 (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading tifffile-2023.4.12-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m219.4/219.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lazy_loader>=0.1 (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio>=1.48.2 (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading grpcio-1.54.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3 (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1 (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6)) (0.40.0)\n",
            "Collecting pytz-deprecation-shim (from tzlocal>=1.1->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting backports.zoneinfo (from tzlocal>=1.1->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading backports.zoneinfo-0.2.1-cp38-cp38-manylinux1_x86_64.whl (74 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asgiref>=3.4.0 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 1))\n",
            "  Downloading asgiref-3.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 1))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator>=3.4.0 (from validators>=0.2->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from fire->point-e==0.0.0->-r requirements.txt (line 29)) (2.3.0)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio->-r requirements.txt (line 1))\n",
            "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio (from httpx->gradio->-r requirements.txt (line 1))\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->gradio->-r requirements.txt (line 1))\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10 (from matplotlib->gradio->-r requirements.txt (line 1))\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->gradio->-r requirements.txt (line 1))\n",
            "  Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib->gradio->-r requirements.txt (line 1))\n",
            "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.3.1 (from matplotlib->gradio->-r requirements.txt (line 1))\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources>=3.2.0 (from matplotlib->gradio->-r requirements.txt (line 1))\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting flatbuffers>=2.0 (from mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 31))\n",
            "  Downloading flatbuffers-23.5.8-py2.py3-none-any.whl (26 kB)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 31))\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Collecting coloredlogs (from onnxruntime->invisible-watermark>=0.1.5->-r requirements.txt (line 15))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy (from onnxruntime->invisible-watermark>=0.1.5->-r requirements.txt (line 15))\n",
            "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 31))\n",
            "  Downloading sentry_sdk-1.22.2-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m203.3/203.3 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 31))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 31))\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 31))\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting appdirs>=1.4.3 (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 31))\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting pkgutil-resolve-name>=1.3.10 (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.12.1->-r requirements.txt (line 9))\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 1))\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Collecting joblib>=1.1.1 (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 2))\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 31))\n",
            "  Downloading cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m442.7/442.7 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->invisible-watermark>=0.1.5->-r requirements.txt (line 15))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mpmath>=0.19 (from sympy->onnxruntime->invisible-watermark>=0.1.5->-r requirements.txt (line 15))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 31))\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 6))\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'opencv-contrib-python' candidate (version 4.3.0.36 at https://files.pythonhosted.org/packages/c2/f5/94c1efe1324e8d2955c96ec611df126f0b319c9e605cadcc2361d3ed3f3e/opencv_contrib_python-4.3.0.36-cp38-cp38-manylinux2014_x86_64.whl (from https://pypi.org/simple/opencv-contrib-python/))\n",
            "Reason for being yanked: Release deprecated\u001b[0m\u001b[33m\n",
            "\u001b[0mBuilding wheels for collected packages: basicsr, antlr4-python3-runtime, test-tube, easydict, point-e, diffusers, lora-diffusion, carvekit, future, typing, validators, clip, ffmpy, fire, pathtools\n",
            "  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214823 sha256=0ad9c4b51478b929280aa5a38b2448a70df37f9d6ddbea1f535f2e73940e0894\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/d3/95/e17d0bcdd7dcfb0dbf79db006711e434c42036efbf6695ef7f\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=53e605d4a9487bd460d27b5d2db22c77e54119a69d6b56007b324f1dcd8f3845\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
            "  Building wheel for test-tube (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for test-tube: filename=test_tube-0.7.5-py3-none-any.whl size=25329 sha256=0f76a32d11abed4b51398eaf4234bd745bca16fedf321be3da35982a8c122aac\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/b0/3a/00ea66dbb0d9ce470ce1bdcb854a6fa030c279c316cb27ca9e\n",
            "  Building wheel for easydict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easydict: filename=easydict-1.10-py3-none-any.whl size=6492 sha256=9e5596aa1ba35d742d904a24c07dba862edc0fb455f3b7bfbb822d0982c252a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/4e/02/c9c3154e4845bfdbf1fdf344f5a89f16dcbb4f627a908c9974\n",
            "  Building wheel for point-e (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for point-e: filename=point_e-0.0.0-py3-none-any.whl size=49733 sha256=2fbb9ecb0445b8462bde883f276f8636811e6f6651851dd110844efb663d3ccd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xu13_9d1/wheels/de/ea/25/8e667c44eaf1be249d3f9bc12685426ace2f3aa541f0e1daf7\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.17.0.dev0-py3-none-any.whl size=965690 sha256=490b739aeada0cff97858d83aa8a016dc558d1493f20f8140ee2adbde928fe90\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xu13_9d1/wheels/c6/77/b7/6d22ce35b79fbe5cc7513554d61c918bb4bf3eac5fdb8ae787\n",
            "  Building wheel for lora-diffusion (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lora-diffusion: filename=lora_diffusion-0.1.7-py3-none-any.whl size=37976 sha256=445d89c864393e17b0d8ba8b86df3d91057f9b53e70b4997271a4e8a173fdaa6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xu13_9d1/wheels/fa/9c/bf/ae45ca4c3793714475c74aabab9ef9fecd511cbb997aa989fb\n",
            "  Building wheel for carvekit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for carvekit: filename=carvekit-4.1.0-py3-none-any.whl size=76111 sha256=9582ae31aa445e9a3a53dcf1b38845c87b9790344584d1cccb80708f6abf2a37\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/b9/cb/07b8e0ec96ff4bf964786a0ce79b8a3f4cc5041c5e7f50d36e\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492022 sha256=3e1cb446e30d6f40acd566d9edb81e19c90b596450bbe5270f6a3fd995b956b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/0b/ee/e6994fadb42c1354dcccb139b0bf2795271bddfe6253ccdf11\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26305 sha256=ed761d2d9fbf1b4f3bc72a7d0572c008a1d96619cb4090b70c10f56aba590aad\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/5d/01/3083e091b57809dad979ea543def62d9d878950e3e74f0c930\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=abbc485c4fbefef118581a565c63708563895cf4a8ef5eeb05d02188592c00cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/09/72/3eb74d236bb48bd0f3c6c3c83e4e0c5bbfcbcad7c6c3539db8\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369370 sha256=d7f57efd729e9229bc51e6ee12e37c1640bcaf56e6f10bdd3139720eecdd6d40\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xu13_9d1/wheels/ab/4f/3a/5e51521b55997aa6f0690e095c08824219753128ce8d9969a3\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=e632c767fb104c3782cd3275784297a772899625caab4a503cf584646c931e3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/5b/59/913b443e7369dc04b61f607a746b6f7d83fb65e2e19fcc958d\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=8e967bb77d0ae92e0b1fc023f9c8d89c2ba82d74e15fd98e497c102735b06137\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/eb/43/7295e71293b218ddfd627f935229bf54af9018add7fbb5aac6\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=ec790d456e89346f24a0751b9439644b33bd99bac7daa3dc8beeff6aebc8e461\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built basicsr antlr4-python3-runtime test-tube easydict point-e diffusers lora-diffusion carvekit future typing validators clip ffmpy fire pathtools\n",
            "Installing collected packages: yapf, wcwidth, tokenizers, safetensors, pytz, pydub, pathtools, mpmath, lmdb, flatbuffers, ffmpy, einops, easydict, braceexpand, appdirs, antlr4-python3-runtime, addict, zipp, websockets, watchdog, urllib3, uc-micro-py, tzdata, typing, tqdm, tornado, toolz, toml, threadpoolctl, tensorboard-data-server, tenacity, sympy, sniffio, smmap, six, setuptools, setproctitle, semver, semantic-version, regex, python-multipart, pyrsistent, pyparsing, pympler, pygments, pyDeprecate, pydantic, pycparser, pyasn1, psutil, protobuf, prettytable, pkgutil-resolve-name, pillow, packaging, orjson, omegaconf, oauthlib, numpy, networkx, multidict, mdurl, markupsafe, loguru, lazy_loader, kiwisolver, joblib, imageio-ffmpeg, humanize, humanfriendly, h11, grpcio, future, ftfy, fsspec, frozenlist, fonttools, filelock, decorator, cycler, click, charset-normalizer, cachetools, blinker, backports.zoneinfo, attrs, async-timeout, asgiref, aiofiles, absl-py, yarl, werkzeug, webdataset, validators, uvicorn, torchmetrics, tifffile, sentry-sdk, scipy, rsa, requests, PyWavelets, pytz-deprecation-shim, python-dateutil, pyasn1-modules, pyarrow, plotly, opencv-python-headless, opencv-python, opencv-contrib-python, onnx, markdown-it-py, linkify-it-py, kornia, jinja2, importlib-resources, importlib-metadata, imageio, gitdb, fire, docker-pycreds, contourpy, coloredlogs, CFFI, anyio, aiosignal, accelerate, tzlocal, starlette, sounddevice, scikit-learn, scikit-image, rich, requests-oauthlib, pydeck, pandas, onnxruntime, mdit-py-plugins, matplotlib, markdown, jsonschema, huggingface-hub, httpcore, google-auth, gitpython, aiohttp, wandb, transformers, timm, qudida, open_clip_torch, mediapipe, invisible-watermark, httpx, google-auth-oauthlib, fastapi, diffusers, clip, altair, tensorboard, tb-nightly, streamlit, point-e, lora-diffusion, gradio-client, carvekit, albumentations, test-tube, streamlit-drawable-canvas, pytorch-lightning, gradio, basicsr\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.2\n",
            "    Uninstalling urllib3-2.0.2:\n",
            "      Successfully uninstalled urllib3-2.0.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.5.0\n",
            "    Uninstalling Pillow-9.5.0:\n",
            "      Successfully uninstalled Pillow-9.5.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.1.0\n",
            "    Uninstalling charset-normalizer-3.1.0:\n",
            "      Successfully uninstalled charset-normalizer-3.1.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.30.0\n",
            "    Uninstalling requests-2.30.0:\n",
            "      Successfully uninstalled requests-2.30.0\n",
            "Successfully installed CFFI-1.15.1 PyWavelets-1.4.1 absl-py-1.4.0 accelerate-0.19.0 addict-2.4.0 aiofiles-0.8.0 aiohttp-3.8.4 aiosignal-1.3.1 albumentations-1.3.0 altair-5.0.0 antlr4-python3-runtime-4.8 anyio-3.6.2 appdirs-1.4.4 asgiref-3.6.0 async-timeout-4.0.2 attrs-23.1.0 backports.zoneinfo-0.2.1 basicsr-1.4.2 blinker-1.6.2 braceexpand-0.1.7 cachetools-5.3.0 carvekit-4.1.0 charset-normalizer-2.0.12 click-8.1.3 clip-1.0 coloredlogs-15.0.1 contourpy-1.0.7 cycler-0.11.0 decorator-5.1.1 diffusers-0.17.0.dev0 docker-pycreds-0.4.0 easydict-1.10 einops-0.3.0 fastapi-0.78.0 ffmpy-0.3.0 filelock-3.12.0 fire-0.5.0 flatbuffers-23.5.8 fonttools-4.39.3 frozenlist-1.3.3 fsspec-2023.5.0 ftfy-6.1.1 future-0.18.3 gitdb-4.0.10 gitpython-3.1.31 google-auth-2.17.3 google-auth-oauthlib-1.0.0 gradio-3.29.0 gradio-client-0.2.2 grpcio-1.54.0 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 huggingface-hub-0.14.1 humanfriendly-10.0 humanize-4.6.0 imageio-2.9.0 imageio-ffmpeg-0.4.2 importlib-metadata-6.6.0 importlib-resources-5.12.0 invisible-watermark-0.1.5 jinja2-3.1.2 joblib-1.2.0 jsonschema-4.17.3 kiwisolver-1.4.4 kornia-0.6.0 lazy_loader-0.2 linkify-it-py-2.0.2 lmdb-1.4.1 loguru-0.6.0 lora-diffusion-0.1.7 markdown-3.4.3 markdown-it-py-2.2.0 markupsafe-2.1.2 matplotlib-3.7.1 mdit-py-plugins-0.3.3 mdurl-0.1.2 mediapipe-0.9.3.0 mpmath-1.3.0 multidict-6.0.4 networkx-3.1 numpy-1.22.4 oauthlib-3.2.2 omegaconf-2.1.1 onnx-1.14.0 onnxruntime-1.14.1 open_clip_torch-2.0.2 opencv-contrib-python-4.3.0.36 opencv-python-4.5.5.64 opencv-python-headless-4.7.0.72 orjson-3.8.12 packaging-23.1 pandas-2.0.1 pathtools-0.1.2 pillow-9.0.1 pkgutil-resolve-name-1.3.10 plotly-5.14.1 point-e-0.0.0 prettytable-3.6.0 protobuf-3.20.3 psutil-5.9.5 pyDeprecate-0.3.1 pyarrow-12.0.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycparser-2.21 pydantic-1.9.2 pydeck-0.8.1b0 pydub-0.25.1 pygments-2.15.1 pympler-1.0.1 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 python-multipart-0.0.6 pytorch-lightning-1.5.0 pytz-2023.3 pytz-deprecation-shim-0.1.0.post0 qudida-0.0.4 regex-2023.5.5 requests-2.27.1 requests-oauthlib-1.3.1 rich-13.3.5 rsa-4.9 safetensors-0.2.7 scikit-image-0.20.0 scikit-learn-1.2.2 scipy-1.9.1 semantic-version-2.10.0 semver-3.0.0 sentry-sdk-1.22.2 setproctitle-1.3.2 setuptools-62.3.4 six-1.16.0 smmap-5.0.0 sniffio-1.3.0 sounddevice-0.4.6 starlette-0.19.1 streamlit-1.12.1 streamlit-drawable-canvas-0.8.0 sympy-1.11.1 tb-nightly-2.14.0a20230509 tenacity-8.2.2 tensorboard-2.13.0 tensorboard-data-server-0.7.0 test-tube-0.7.5 threadpoolctl-3.1.0 tifffile-2023.4.12 timm-0.6.12 tokenizers-0.13.3 toml-0.10.2 toolz-0.12.0 torchmetrics-0.6.0 tornado-6.3.1 tqdm-4.64.1 transformers-4.28.1 typing-3.7.4.3 tzdata-2023.3 tzlocal-4.3 uc-micro-py-1.0.2 urllib3-1.26.15 uvicorn-0.17.6 validators-0.20.0 wandb-0.15.2 watchdog-3.0.0 wcwidth-0.2.6 webdataset-0.2.5 websockets-11.0.3 werkzeug-2.3.4 yapf-0.32.0 yarl-1.9.2 zipp-3.15.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p weights\n",
        "%cd /content/3DFuse/weights\n",
        "!wget https://huggingface.co/jyseo/3DFuse_weights/resolve/main/models/3DFuse_sparse_depth_injector.ckpt\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "EB8vbj_jtdBM",
        "outputId": "1e7ca134-82a9-4c41-da8e-7ad6936d09e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3DFuse/weights\n",
            "--2023-05-10 03:31:39--  https://huggingface.co/jyseo/3DFuse_weights/resolve/main/models/3DFuse_sparse_depth_injector.ckpt\n",
            "Resolving huggingface.co (huggingface.co)... 18.160.249.78, 18.160.249.31, 18.160.249.70, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.160.249.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/b7/16/b7162dcbcfb6f808c35f3722d3de234ec9dab8ab1f743676a6c9f6912670b9a4/afce750825b9fcaac18c987c88996a182ab34bcaa87c263a33185c0abf676340?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%273DFuse_sparse_depth_injector.ckpt%3B+filename%3D%223DFuse_sparse_depth_injector.ckpt%22%3B&Expires=1683948700&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2I3LzE2L2I3MTYyZGNiY2ZiNmY4MDhjMzVmMzcyMmQzZGUyMzRlYzlkYWI4YWIxZjc0MzY3NmE2YzlmNjkxMjY3MGI5YTQvYWZjZTc1MDgyNWI5ZmNhYWMxOGM5ODdjODg5OTZhMTgyYWIzNGJjYWE4N2MyNjNhMzMxODVjMGFiZjY3NjM0MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODM5NDg3MDB9fX1dfQ__&Signature=QnnmzoAIyP45b-1SeGJzfl0-qrvoxwUy1f5AdNDa9IHccjH96D0wH8Ja2fsKBp%7E-t2ItRB1LhQOp2mXTzIscpPHVUMqaAma8vl9w-G5e8SylF5irxArupqLvOPMLqpSWS0vJAIQy7IxUthJAbaJ6KpKXkLKKusmFrLIBSXX79UjoLizya-3gCm4l-wASnucQ8KNd0ZAVVxfrdZtdQE%7ER66zHmgkP9wNRuTdM5vDl1hERC6Vo5L-h9OT-lkgeJFfZSWHOqB5NNiRFjBC3KuB5YY9vlhpA8y7vH5oe7y23R0CEkahq4RzihJkmID6vKDe4rryBTT5V7hU9KUyGc6EbHg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-05-10 03:31:39--  https://cdn-lfs.huggingface.co/repos/b7/16/b7162dcbcfb6f808c35f3722d3de234ec9dab8ab1f743676a6c9f6912670b9a4/afce750825b9fcaac18c987c88996a182ab34bcaa87c263a33185c0abf676340?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%273DFuse_sparse_depth_injector.ckpt%3B+filename%3D%223DFuse_sparse_depth_injector.ckpt%22%3B&Expires=1683948700&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2I3LzE2L2I3MTYyZGNiY2ZiNmY4MDhjMzVmMzcyMmQzZGUyMzRlYzlkYWI4YWIxZjc0MzY3NmE2YzlmNjkxMjY3MGI5YTQvYWZjZTc1MDgyNWI5ZmNhYWMxOGM5ODdjODg5OTZhMTgyYWIzNGJjYWE4N2MyNjNhMzMxODVjMGFiZjY3NjM0MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODM5NDg3MDB9fX1dfQ__&Signature=QnnmzoAIyP45b-1SeGJzfl0-qrvoxwUy1f5AdNDa9IHccjH96D0wH8Ja2fsKBp%7E-t2ItRB1LhQOp2mXTzIscpPHVUMqaAma8vl9w-G5e8SylF5irxArupqLvOPMLqpSWS0vJAIQy7IxUthJAbaJ6KpKXkLKKusmFrLIBSXX79UjoLizya-3gCm4l-wASnucQ8KNd0ZAVVxfrdZtdQE%7ER66zHmgkP9wNRuTdM5vDl1hERC6Vo5L-h9OT-lkgeJFfZSWHOqB5NNiRFjBC3KuB5YY9vlhpA8y7vH5oe7y23R0CEkahq4RzihJkmID6vKDe4rryBTT5V7hU9KUyGc6EbHg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.26, 18.154.185.27, 18.154.185.64, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8601299457 (8.0G) [binary/octet-stream]\n",
            "Saving to: â€˜3DFuse_sparse_depth_injector.ckptâ€™\n",
            "\n",
            "3DFuse_sparse_depth 100%[===================>]   8.01G   104MB/s    in 48s     \n",
            "\n",
            "2023-05-10 03:32:27 (172 MB/s) - â€˜3DFuse_sparse_depth_injector.ckptâ€™ saved [8601299457/8601299457]\n",
            "\n",
            "3DFuse_sparse_depth_injector.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/3DFuse\n",
        "\n",
        "!/usr/local/envs/3DFuse/bin/python gradio_app.py --share"
      ],
      "metadata": {
        "id": "6ckZ52bSuGc_",
        "outputId": "a0f9f2b8-8bcf-449c-d3df-f75fe68ecc81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3DFuse\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.23.0-py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting comm>=0.1.1 (from ipykernel)\n",
            "  Downloading comm-0.1.3-py3-none-any.whl (6.6 kB)\n",
            "Collecting debugpy>=1.6.5 (from ipykernel)\n",
            "  Downloading debugpy-1.6.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython>=7.23.1 (from ipykernel)\n",
            "  Downloading ipython-8.12.2-py3-none-any.whl (797 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m797.8/797.8 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-client>=6.1.12 (from ipykernel)\n",
            "  Downloading jupyter_client-8.2.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-core!=5.0.*,>=4.12 (from ipykernel)\n",
            "  Downloading jupyter_core-5.3.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline>=0.1 (from ipykernel)\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting nest-asyncio (from ipykernel)\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from ipykernel) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from ipykernel) (5.9.5)\n",
            "Collecting pyzmq>=20 (from ipykernel)\n",
            "  Downloading pyzmq-25.0.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado>=6.1 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from ipykernel) (6.3.1)\n",
            "Collecting traitlets>=5.4.0 (from ipykernel)\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backcall (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pickleshare (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments>=2.4.0 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (2.15.1)\n",
            "Collecting stack-data (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (4.5.0)\n",
            "Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel) (6.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
            "Collecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel)\n",
            "  Downloading platformdirs-3.5.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.15.0)\n",
            "Collecting parso<0.9.0,>=0.8.0 (from jedi>=0.16->ipython>=7.23.1->ipykernel)\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel) (0.2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/3DFuse/lib/python3.8/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting pure-eval (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pure-eval, ptyprocess, pickleshare, executing, backcall, traitlets, pyzmq, prompt-toolkit, platformdirs, pexpect, parso, nest-asyncio, debugpy, asttokens, stack-data, matplotlib-inline, jupyter-core, jedi, comm, jupyter-client, ipython, ipykernel\n",
            "Successfully installed asttokens-2.2.1 backcall-0.2.0 comm-0.1.3 debugpy-1.6.7 executing-1.2.0 ipykernel-6.23.0 ipython-8.12.2 jedi-0.18.2 jupyter-client-8.2.0 jupyter-core-5.3.0 matplotlib-inline-0.1.6 nest-asyncio-1.5.6 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 platformdirs-3.5.0 prompt-toolkit-3.0.38 ptyprocess-0.7.0 pure-eval-0.2.2 pyzmq-25.0.2 stack-data-0.6.2 traitlets-5.9.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m/usr/local/envs/3DFuse/lib/python3.8/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Row, please remove them: {'scale': 1.0}\n",
            "  warnings.warn(\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://a82329ae242485f02e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "seed set to 893589510\n",
            "creating base model...\n",
            "creating upsample model...\n",
            "downloading base checkpoint...\n",
            "downloading upsampler checkpoint...\n",
            "130it [06:15,  2.89s/it]\n",
            "seed set to 893589510\n",
            "loaded config\n",
            " \n",
            "family: sd\n",
            "sd:\n",
            "  variant: v1\n",
            "  v2_highres: false\n",
            "  prompt: a comfortable bed \n",
            "  scale: 100.0\n",
            "  precision: autocast\n",
            "  dir: ./results/bed/lora/final_lora.safetensors\n",
            "  alpha: 0.3\n",
            "lr: 0.05\n",
            "n_steps: 10000\n",
            "vox:\n",
            "  model_type: V_SD\n",
            "  bbox_len: 1.0\n",
            "  grid_size:\n",
            "  - 100\n",
            "  - 100\n",
            "  - 100\n",
            "  step_ratio: 0.5\n",
            "  density_shift: -1.0\n",
            "  ray_march_weight_thres: 0.0001\n",
            "  c: 4\n",
            "  blend_bg_texture: false\n",
            "  bg_texture_hw: 4\n",
            "pose:\n",
            "  rend_hw: 64\n",
            "  FoV: 60.0\n",
            "  R: 1.5\n",
            "emptiness_scale: 10\n",
            "emptiness_weight: 10000\n",
            "emptiness_step: 0.5\n",
            "emptiness_multiplier: 20.0\n",
            "depth_weight: 0\n",
            "var_red: true\n",
            "exp_dir: ./results\n",
            "ti_step: 500\n",
            "pt_step: 500\n",
            "initial: bed\n",
            "random_seed: 0\n",
            "semantic_model: Karlo\n",
            "bg_preprocess: True\n",
            "num_initial_image: 4\n",
            "\n",
            "PTI : Placeholder Tokens ['<0>']\n",
            "PTI : Initializer Tokens ['cat']\n",
            "Downloading (â€¦)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 10.9MB/s]\n",
            "Downloading (â€¦)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 126MB/s]\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 272kB/s]\n",
            "Downloading (â€¦)okenizer_config.json: 100% 806/806 [00:00<00:00, 466kB/s]\n",
            "Downloading (â€¦)_encoder/config.json: 100% 617/617 [00:00<00:00, 353kB/s]\n",
            "Downloading model.safetensors: 100% 492M/492M [00:02<00:00, 167MB/s]\n",
            "Downloading (â€¦)main/vae/config.json: 100% 547/547 [00:00<00:00, 242kB/s]\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 335M/335M [00:01<00:00, 168MB/s]\n",
            "Downloading (â€¦)ain/unet/config.json: 100% 743/743 [00:00<00:00, 393kB/s]\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 3.44G/3.44G [00:21<00:00, 162MB/s]\n",
            "/usr/local/envs/3DFuse/lib/python3.8/site-packages/diffusers/configuration_utils.py:215: FutureWarning:\n",
            "\n",
            "It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
            "\n",
            "Downloading (â€¦)cheduler_config.json: 100% 308/308 [00:00<00:00, 144kB/s]\n",
            "Steps:   0% 0/500 [00:00<?, ?it/s]a rendition of the <0>\n",
            "tensor(0.0010, device='cuda:0')\n",
            "tensor([[0.3697]], device='cuda:0')\n",
            "Current Norm : tensor([0.3758], device='cuda:0')\n",
            "Steps:   0% 1/500 [00:01<12:17,  1.48s/it, loss=0.0892, lr=0.002]a photo of a clean <0>\n",
            "Steps:   0% 2/500 [00:02<11:06,  1.34s/it, loss=0.00449, lr=0.00199]a photo of a clean <0>\n",
            "Steps:   1% 3/500 [00:03<10:36,  1.28s/it, loss=0.0617, lr=0.00199] a close-up photo of a <0>\n",
            "Steps:   1% 4/500 [00:05<10:26,  1.26s/it, loss=0.00252, lr=0.00198]a photo of the cool <0>\n",
            "tensor(0.0021, device='cuda:0')\n",
            "tensor([[0.3786]], device='cuda:0')\n",
            "Current Norm : tensor([0.3828], device='cuda:0')\n",
            "Steps:   1% 5/500 [00:06<10:23,  1.26s/it, loss=0.0024, lr=0.00198] a photo of the cool <0>\n",
            "Steps:   1% 6/500 [00:07<10:19,  1.25s/it, loss=0.035, lr=0.00198] a cropped photo of the <0>\n",
            "Steps:   1% 7/500 [00:08<10:14,  1.25s/it, loss=0.00501, lr=0.00197]a photo of a <0>\n",
            "Steps:   2% 8/500 [00:10<10:09,  1.24s/it, loss=0.0224, lr=0.00197] a rendering of a <0>\n",
            "tensor(0.0030, device='cuda:0')\n",
            "tensor([[0.3868]], device='cuda:0')\n",
            "Current Norm : tensor([0.3894], device='cuda:0')\n",
            "Steps:   2% 9/500 [00:11<10:09,  1.24s/it, loss=0.000918, lr=0.00196]a photo of my <0>\n",
            "Steps:   2% 10/500 [00:12<10:06,  1.24s/it, loss=0.0312, lr=0.00196]  a photo of my <0>\n",
            "Steps:   2% 11/500 [00:13<09:54,  1.22s/it, loss=0.0413, lr=0.00196]a dark photo of the <0>\n",
            "Steps:   2% 12/500 [00:14<09:44,  1.20s/it, loss=0.0312, lr=0.00195]a good photo of the <0>\n",
            "tensor(0.0032, device='cuda:0')\n",
            "tensor([[0.3936]], device='cuda:0')\n",
            "Current Norm : tensor([0.3949], device='cuda:0')\n",
            "Steps:   3% 13/500 [00:16<09:41,  1.19s/it, loss=0.0449, lr=0.00195]a dark photo of the <0>\n",
            "Steps:   3% 14/500 [00:17<09:38,  1.19s/it, loss=0.00275, lr=0.00194]a photo of my <0>\n",
            "Steps:   3% 15/500 [00:18<09:34,  1.19s/it, loss=0.00889, lr=0.00194]a close-up photo of the <0>\n",
            "Steps:   3% 16/500 [00:19<09:32,  1.18s/it, loss=0.0134, lr=0.00194] a photo of the large <0>\n",
            "tensor(0.0072, device='cuda:0')\n",
            "tensor([[0.3988]], device='cuda:0')\n",
            "Current Norm : tensor([0.3991], device='cuda:0')\n",
            "Steps:   3% 17/500 [00:20<09:32,  1.19s/it, loss=0.0217, lr=0.00193]a photo of a dirty <0>\n",
            "Steps:   4% 18/500 [00:22<09:29,  1.18s/it, loss=0.00984, lr=0.00193]a cropped photo of the <0>\n",
            "Steps:   4% 19/500 [00:23<09:36,  1.20s/it, loss=0.000427, lr=0.00192]a photo of a clean <0>\n",
            "Steps:   4% 20/500 [00:24<09:45,  1.22s/it, loss=0.00411, lr=0.00192] a rendition of the <0>\n",
            "tensor(0.0025, device='cuda:0')\n",
            "tensor([[0.4041]], device='cuda:0')\n",
            "Current Norm : tensor([0.4033], device='cuda:0')\n",
            "Steps:   4% 21/500 [00:25<09:54,  1.24s/it, loss=0.00222, lr=0.00192]a photo of the nice <0>\n",
            "Steps:   4% 22/500 [00:27<09:57,  1.25s/it, loss=0.0176, lr=0.00191] a close-up photo of a <0>\n",
            "Steps:   5% 23/500 [00:28<09:57,  1.25s/it, loss=0.0017, lr=0.00191]a photo of a clean <0>\n",
            "Steps:   5% 24/500 [00:29<09:58,  1.26s/it, loss=0.00942, lr=0.0019]a photo of the weird <0>\n",
            "tensor(0.0025, device='cuda:0')\n",
            "tensor([[0.4089]], device='cuda:0')\n",
            "Current Norm : tensor([0.4072], device='cuda:0')\n",
            "Steps:   5% 25/500 [00:30<10:03,  1.27s/it, loss=0.00126, lr=0.0019]a rendition of a <0>\n",
            "Steps:   5% 26/500 [00:32<10:01,  1.27s/it, loss=0.0256, lr=0.0019] a photo of the nice <0>\n",
            "Steps:   5% 27/500 [00:33<09:56,  1.26s/it, loss=0.0226, lr=0.00189]a photo of one <0>\n",
            "Steps:   6% 28/500 [00:34<09:59,  1.27s/it, loss=0.0552, lr=0.00189]a close-up photo of the <0>\n",
            "tensor(0.0038, device='cuda:0')\n",
            "tensor([[0.4133]], device='cuda:0')\n",
            "Current Norm : tensor([0.4108], device='cuda:0')\n",
            "Steps:   6% 29/500 [00:35<09:50,  1.25s/it, loss=0.00237, lr=0.00188]a close-up photo of a <0>\n",
            "Steps:   6% 30/500 [00:37<09:39,  1.23s/it, loss=0.0059, lr=0.00188] a photo of the large <0>\n",
            "Steps:   6% 31/500 [00:38<09:30,  1.22s/it, loss=0.00707, lr=0.00188]a rendition of a <0>\n",
            "Steps:   6% 32/500 [00:39<09:24,  1.21s/it, loss=0.00348, lr=0.00187]the photo of a <0>\n",
            "tensor(0.0027, device='cuda:0')\n",
            "tensor([[0.4169]], device='cuda:0')\n",
            "Current Norm : tensor([0.4138], device='cuda:0')\n",
            "Steps:   7% 33/500 [00:40<09:23,  1.21s/it, loss=0.00482, lr=0.00187]a cropped photo of the <0>\n",
            "Steps:   7% 34/500 [00:41<09:19,  1.20s/it, loss=0.0026, lr=0.00186] a close-up photo of a <0>\n",
            "Steps:   7% 35/500 [00:43<09:14,  1.19s/it, loss=0.026, lr=0.00186] a dark photo of the <0>\n",
            "Steps:   7% 36/500 [00:44<09:11,  1.19s/it, loss=0.0434, lr=0.00186]a rendering of a <0>\n",
            "tensor(0.0036, device='cuda:0')\n",
            "tensor([[0.4201]], device='cuda:0')\n",
            "Current Norm : tensor([0.4163], device='cuda:0')\n",
            "Steps:   7% 37/500 [00:45<09:12,  1.19s/it, loss=0.0369, lr=0.00185]a photo of the <0>\n",
            "Steps:   8% 38/500 [00:46<09:21,  1.22s/it, loss=0.0212, lr=0.00185]a cropped photo of the <0>\n",
            "Steps:   8% 39/500 [00:47<09:28,  1.23s/it, loss=0.00134, lr=0.00184]a photo of a nice <0>\n",
            "Steps:   8% 40/500 [00:49<09:31,  1.24s/it, loss=0.00178, lr=0.00184]a bright photo of the <0>\n",
            "tensor(0.0038, device='cuda:0')\n",
            "tensor([[0.4228]], device='cuda:0')\n",
            "Current Norm : tensor([0.4186], device='cuda:0')\n",
            "Steps:   8% 41/500 [00:50<09:36,  1.26s/it, loss=0.0248, lr=0.00184] a rendition of the <0>\n",
            "Steps:   8% 42/500 [00:51<09:34,  1.25s/it, loss=0.000402, lr=0.00183]a rendition of a <0>\n",
            "Steps:   9% 43/500 [00:52<09:32,  1.25s/it, loss=0.00042, lr=0.00183] a close-up photo of the <0>\n",
            "Steps:   9% 44/500 [00:54<09:31,  1.25s/it, loss=0.000393, lr=0.00182]a good photo of the <0>\n",
            "tensor(0.0019, device='cuda:0')\n",
            "tensor([[0.4252]], device='cuda:0')\n",
            "Current Norm : tensor([0.4206], device='cuda:0')\n",
            "Steps:   9% 45/500 [00:55<09:33,  1.26s/it, loss=0.00787, lr=0.00182] a rendition of a <0>\n",
            "Steps:   9% 46/500 [00:56<09:30,  1.26s/it, loss=0.0296, lr=0.00182] a photo of a <0>\n",
            "Steps:   9% 47/500 [00:57<09:22,  1.24s/it, loss=0.0596, lr=0.00181]a dark photo of the <0>\n",
            "Steps:  10% 48/500 [00:59<09:09,  1.22s/it, loss=0.00609, lr=0.00181]a rendering of a <0>\n",
            "tensor(0.0042, device='cuda:0')\n",
            "tensor([[0.4271]], device='cuda:0')\n",
            "Current Norm : tensor([0.4222], device='cuda:0')\n",
            "Steps:  10% 49/500 [01:00<09:04,  1.21s/it, loss=0.00199, lr=0.0018] a photo of the cool <0>\n",
            "Steps:  10% 50/500 [01:01<08:57,  1.20s/it, loss=0.000699, lr=0.0018]a good photo of a <0>\n",
            "Steps:  10% 51/500 [01:02<08:52,  1.19s/it, loss=0.00886, lr=0.0018] a rendition of the <0>\n",
            "Steps:  10% 52/500 [01:03<08:47,  1.18s/it, loss=0.0108, lr=0.00179]a photo of the large <0>\n",
            "tensor(0.0041, device='cuda:0')\n",
            "tensor([[0.4284]], device='cuda:0')\n",
            "Current Norm : tensor([0.4233], device='cuda:0')\n",
            "Steps:  11% 53/500 [01:05<08:47,  1.18s/it, loss=0.00126, lr=0.00179]a rendition of the <0>\n",
            "Steps:  11% 54/500 [01:06<08:42,  1.17s/it, loss=0.0286, lr=0.00178] a dark photo of the <0>\n",
            "Steps:  11% 55/500 [01:07<08:38,  1.17s/it, loss=0.00902, lr=0.00178]a cropped photo of the <0>\n",
            "Steps:  11% 56/500 [01:08<08:47,  1.19s/it, loss=0.0294, lr=0.00178] a photo of the cool <0>\n",
            "tensor(0.0054, device='cuda:0')\n",
            "tensor([[0.4295]], device='cuda:0')\n",
            "Current Norm : tensor([0.4242], device='cuda:0')\n",
            "Steps:  11% 57/500 [01:09<08:57,  1.21s/it, loss=0.0437, lr=0.00177]a bright photo of the <0>\n",
            "Steps:  12% 58/500 [01:11<09:01,  1.22s/it, loss=0.0207, lr=0.00177]a photo of the weird <0>\n",
            "Steps:  12% 59/500 [01:12<09:02,  1.23s/it, loss=0.0249, lr=0.00176]a photo of the <0>\n",
            "Steps:  12% 60/500 [01:13<09:03,  1.24s/it, loss=0.0128, lr=0.00176]a photo of the small <0>\n",
            "tensor(0.0046, device='cuda:0')\n",
            "tensor([[0.4301]], device='cuda:0')\n",
            "Current Norm : tensor([0.4248], device='cuda:0')\n",
            "Steps:  12% 61/500 [01:14<09:08,  1.25s/it, loss=0.000796, lr=0.00176]a rendering of a <0>\n",
            "Steps:  12% 62/500 [01:16<09:04,  1.24s/it, loss=0.0503, lr=0.00175]  a cropped photo of the <0>\n",
            "Steps:  13% 63/500 [01:17<09:03,  1.24s/it, loss=0.00267, lr=0.00175]a photo of the large <0>\n",
            "Steps:  13% 64/500 [01:18<09:02,  1.24s/it, loss=0.000468, lr=0.00174]a good photo of the <0>\n",
            "tensor(0.0051, device='cuda:0')\n",
            "tensor([[0.4306]], device='cuda:0')\n",
            "Current Norm : tensor([0.4253], device='cuda:0')\n",
            "Steps:  13% 65/500 [01:19<09:04,  1.25s/it, loss=0.025, lr=0.00174]   a good photo of the <0>\n",
            "Steps:  13% 66/500 [01:20<08:51,  1.23s/it, loss=0.0103, lr=0.00174]a bright photo of the <0>\n",
            "Steps:  13% 67/500 [01:22<08:41,  1.20s/it, loss=0.0441, lr=0.00173]a rendering of a <0>\n",
            "Steps:  14% 68/500 [01:23<08:33,  1.19s/it, loss=0.00321, lr=0.00173]a photo of a clean <0>\n",
            "tensor(0.0051, device='cuda:0')\n",
            "tensor([[0.4312]], device='cuda:0')\n",
            "Current Norm : tensor([0.4258], device='cuda:0')\n",
            "Steps:  14% 69/500 [01:24<08:30,  1.18s/it, loss=0.0272, lr=0.00172] a photo of a <0>\n",
            "Steps:  14% 70/500 [01:25<08:25,  1.18s/it, loss=0.0573, lr=0.00172]a photo of a dirty <0>\n",
            "Steps:  14% 71/500 [01:26<08:23,  1.17s/it, loss=0.00218, lr=0.00172]a photo of a dirty <0>\n",
            "Steps:  14% 72/500 [01:27<08:20,  1.17s/it, loss=0.0118, lr=0.00171] a photo of the large <0>\n",
            "tensor(0.0049, device='cuda:0')\n",
            "tensor([[0.4315]], device='cuda:0')\n",
            "Current Norm : tensor([0.4262], device='cuda:0')\n",
            "Steps:  15% 73/500 [01:29<08:21,  1.17s/it, loss=0.0294, lr=0.00171]a cropped photo of a <0>\n",
            "Steps:  15% 74/500 [01:30<08:20,  1.17s/it, loss=0.0155, lr=0.0017] a photo of the large <0>\n",
            "Steps:  15% 75/500 [01:31<08:29,  1.20s/it, loss=0.00221, lr=0.0017]a photo of the cool <0>\n",
            "Steps:  15% 76/500 [01:32<08:35,  1.22s/it, loss=0.000411, lr=0.0017]a photo of a <0>\n",
            "tensor(0.0042, device='cuda:0')\n",
            "tensor([[0.4319]], device='cuda:0')\n",
            "Current Norm : tensor([0.4265], device='cuda:0')\n",
            "Steps:  15% 77/500 [01:34<08:43,  1.24s/it, loss=0.0475, lr=0.00169] a photo of the weird <0>\n",
            "Steps:  16% 78/500 [01:35<08:45,  1.25s/it, loss=0.00529, lr=0.00169]a photo of the <0>\n",
            "Steps:  16% 79/500 [01:36<08:46,  1.25s/it, loss=0.00105, lr=0.00168]a dark photo of the <0>\n",
            "Steps:  16% 80/500 [01:37<08:47,  1.25s/it, loss=0.0034, lr=0.00168] a close-up photo of a <0>\n",
            "tensor(0.0030, device='cuda:0')\n",
            "tensor([[0.4322]], device='cuda:0')\n",
            "Current Norm : tensor([0.4268], device='cuda:0')\n",
            "Steps:  16% 81/500 [01:39<08:50,  1.27s/it, loss=0.0225, lr=0.00168]the photo of a <0>\n",
            "Steps:  16% 82/500 [01:40<08:49,  1.27s/it, loss=0.0104, lr=0.00167]a close-up photo of a <0>\n",
            "Steps:  17% 83/500 [01:41<08:47,  1.27s/it, loss=0.00329, lr=0.00167]a cropped photo of a <0>\n",
            "Steps:  17% 84/500 [01:42<08:45,  1.26s/it, loss=0.0167, lr=0.00166] a good photo of the <0>\n",
            "tensor(0.0044, device='cuda:0')\n",
            "tensor([[0.4323]], device='cuda:0')\n",
            "Current Norm : tensor([0.4269], device='cuda:0')\n",
            "Steps:  17% 85/500 [01:44<08:36,  1.24s/it, loss=0.000573, lr=0.00166]a good photo of the <0>\n",
            "Steps:  17% 86/500 [01:45<08:26,  1.22s/it, loss=0.0997, lr=0.00166]  a bright photo of the <0>\n",
            "Steps:  17% 87/500 [01:46<08:18,  1.21s/it, loss=0.0097, lr=0.00165]a photo of the <0>\n",
            "Steps:  18% 88/500 [01:47<08:12,  1.20s/it, loss=0.017, lr=0.00165] a photo of a cool <0>\n",
            "tensor(0.0047, device='cuda:0')\n",
            "tensor([[0.4323]], device='cuda:0')\n",
            "Current Norm : tensor([0.4270], device='cuda:0')\n",
            "Steps:  18% 89/500 [01:48<08:11,  1.20s/it, loss=0.03, lr=0.00164] a good photo of a <0>\n",
            "Steps:  18% 90/500 [01:50<08:07,  1.19s/it, loss=0.0183, lr=0.00164]a photo of the cool <0>\n",
            "Steps:  18% 91/500 [01:51<08:04,  1.18s/it, loss=0.00198, lr=0.00164]a photo of the nice <0>\n",
            "Steps:  18% 92/500 [01:52<08:02,  1.18s/it, loss=0.108, lr=0.00163]  a photo of a small <0>\n",
            "tensor(0.0057, device='cuda:0')\n",
            "tensor([[0.4322]], device='cuda:0')\n",
            "Current Norm : tensor([0.4270], device='cuda:0')\n",
            "Steps:  19% 93/500 [01:53<08:11,  1.21s/it, loss=0.0661, lr=0.00163]a good photo of the <0>\n",
            "Steps:  19% 94/500 [01:54<08:19,  1.23s/it, loss=0.0242, lr=0.00162]a photo of the clean <0>\n",
            "Steps:  19% 95/500 [01:56<08:21,  1.24s/it, loss=0.0241, lr=0.00162]a close-up photo of the <0>\n",
            "Steps:  19% 96/500 [01:57<08:23,  1.25s/it, loss=0.021, lr=0.00162] the photo of a <0>\n",
            "tensor(0.0058, device='cuda:0')\n",
            "tensor([[0.4321]], device='cuda:0')\n",
            "Current Norm : tensor([0.4269], device='cuda:0')\n",
            "Steps:  19% 97/500 [01:58<08:26,  1.26s/it, loss=0.0363, lr=0.00161]a photo of the large <0>\n",
            "Steps:  20% 98/500 [02:00<08:24,  1.26s/it, loss=0.000656, lr=0.00161]a photo of a dirty <0>\n",
            "Steps:  20% 99/500 [02:01<08:24,  1.26s/it, loss=0.0254, lr=0.0016]   a photo of a cool <0>\n",
            "Steps:  20% 100/500 [02:02<08:24,  1.26s/it, loss=0.0106, lr=0.0016]a photo of a dirty <0>\n",
            "tensor(0.0055, device='cuda:0')\n",
            "tensor([[0.4320]], device='cuda:0')\n",
            "Current Norm : tensor([0.4269], device='cuda:0')\n",
            "Steps:  20% 101/500 [02:03<08:25,  1.27s/it, loss=0.0651, lr=0.0016]a rendition of a <0>\n",
            "Steps:  20% 102/500 [02:05<08:23,  1.27s/it, loss=0.0302, lr=0.00159]a photo of a <0>\n",
            "Steps:  21% 103/500 [02:06<08:10,  1.24s/it, loss=0.0053, lr=0.00159]a photo of a small <0>\n",
            "Steps:  21% 104/500 [02:07<08:01,  1.22s/it, loss=0.0336, lr=0.00158]a photo of my <0>\n",
            "tensor(0.0054, device='cuda:0')\n",
            "tensor([[0.4321]], device='cuda:0')\n",
            "Current Norm : tensor([0.4270], device='cuda:0')\n",
            "Steps:  21% 105/500 [02:08<07:58,  1.21s/it, loss=0.00482, lr=0.00158]a rendition of the <0>\n",
            "Steps:  21% 106/500 [02:09<07:52,  1.20s/it, loss=0.00847, lr=0.00158]a rendering of a <0>\n",
            "Steps:  21% 107/500 [02:10<07:47,  1.19s/it, loss=0.0447, lr=0.00157] a photo of a <0>\n",
            "Steps:  22% 108/500 [02:12<07:44,  1.18s/it, loss=0.000836, lr=0.00157]a photo of the clean <0>\n",
            "tensor(0.0057, device='cuda:0')\n",
            "tensor([[0.4321]], device='cuda:0')\n",
            "Current Norm : tensor([0.4271], device='cuda:0')\n",
            "Steps:  22% 109/500 [02:13<07:42,  1.18s/it, loss=0.0112, lr=0.00156]  a rendering of a <0>\n",
            "Steps:  22% 110/500 [02:14<07:40,  1.18s/it, loss=0.0113, lr=0.00156]a close-up photo of the <0>\n",
            "Steps:  22% 111/500 [02:15<07:38,  1.18s/it, loss=0.000566, lr=0.00156]a good photo of a <0>\n",
            "Steps:  22% 112/500 [02:16<07:47,  1.21s/it, loss=0.0107, lr=0.00155]  a photo of the nice <0>\n",
            "tensor(0.0065, device='cuda:0')\n",
            "tensor([[0.4321]], device='cuda:0')\n",
            "Current Norm : tensor([0.4271], device='cuda:0')\n",
            "Steps:  23% 113/500 [02:18<07:55,  1.23s/it, loss=0.000935, lr=0.00155]a photo of a nice <0>\n",
            "Steps:  23% 114/500 [02:19<07:58,  1.24s/it, loss=0.0198, lr=0.00154]  a cropped photo of a <0>\n",
            "Steps:  23% 115/500 [02:20<07:58,  1.24s/it, loss=0.0197, lr=0.00154]a photo of the small <0>\n",
            "Steps:  23% 116/500 [02:22<08:01,  1.26s/it, loss=0.00599, lr=0.00154]a rendition of a <0>\n",
            "tensor(0.0056, device='cuda:0')\n",
            "tensor([[0.4319]], device='cuda:0')\n",
            "Current Norm : tensor([0.4270], device='cuda:0')\n",
            "Steps:  23% 117/500 [02:23<08:02,  1.26s/it, loss=0.00335, lr=0.00153]a rendition of the <0>\n",
            "Steps:  24% 118/500 [02:24<08:00,  1.26s/it, loss=0.0509, lr=0.00153] a photo of a clean <0>\n",
            "Steps:  24% 119/500 [02:25<07:58,  1.26s/it, loss=0.0293, lr=0.00152]a good photo of a <0>\n",
            "Steps:  24% 120/500 [02:27<07:56,  1.25s/it, loss=0.0175, lr=0.00152]a photo of one <0>\n",
            "tensor(0.0057, device='cuda:0')\n",
            "tensor([[0.4318]], device='cuda:0')\n",
            "Current Norm : tensor([0.4270], device='cuda:0')\n",
            "Steps:  24% 121/500 [02:28<07:57,  1.26s/it, loss=0.0339, lr=0.00152]a cropped photo of the <0>\n",
            "Steps:  24% 122/500 [02:29<07:46,  1.23s/it, loss=0.00324, lr=0.00151]a photo of the cool <0>\n",
            "Steps:  25% 123/500 [02:30<07:38,  1.22s/it, loss=0.00347, lr=0.00151]a rendering of a <0>\n",
            "Steps:  25% 124/500 [02:31<07:31,  1.20s/it, loss=0.011, lr=0.0015]   a photo of a small <0>\n",
            "tensor(0.0054, device='cuda:0')\n",
            "tensor([[0.4317]], device='cuda:0')\n",
            "Current Norm : tensor([0.4269], device='cuda:0')\n",
            "Steps:  25% 125/500 [02:33<07:29,  1.20s/it, loss=0.000528, lr=0.0015]a bright photo of the <0>\n",
            "Steps:  25% 126/500 [02:34<07:25,  1.19s/it, loss=0.085, lr=0.0015]   a photo of the nice <0>\n",
            "Steps:  25% 127/500 [02:35<07:23,  1.19s/it, loss=0.0162, lr=0.00149]a photo of the small <0>\n",
            "Steps:  26% 128/500 [02:36<07:20,  1.18s/it, loss=0.0124, lr=0.00149]a photo of the weird <0>\n",
            "tensor(0.0057, device='cuda:0')\n",
            "tensor([[0.4316]], device='cuda:0')\n",
            "Current Norm : tensor([0.4269], device='cuda:0')\n",
            "Steps:  26% 129/500 [02:37<07:21,  1.19s/it, loss=0.00826, lr=0.00148]a cropped photo of the <0>\n",
            "Steps:  26% 130/500 [02:39<07:31,  1.22s/it, loss=0.00439, lr=0.00148]a rendering of a <0>\n",
            "Steps:  26% 131/500 [02:40<07:37,  1.24s/it, loss=0.0275, lr=0.00148] a cropped photo of the <0>\n",
            "Steps:  26% 132/500 [02:41<07:38,  1.25s/it, loss=0.00296, lr=0.00147]the photo of a <0>\n",
            "tensor(0.0097, device='cuda:0')\n",
            "tensor([[0.4313]], device='cuda:0')\n",
            "Current Norm : tensor([0.4267], device='cuda:0')\n",
            "Steps:  27% 133/500 [02:42<07:41,  1.26s/it, loss=0.0432, lr=0.00147] a photo of a clean <0>\n",
            "Steps:  27% 134/500 [02:44<07:40,  1.26s/it, loss=0.000733, lr=0.00146]a rendering of a <0>\n",
            "Steps:  27% 135/500 [02:45<07:40,  1.26s/it, loss=0.0132, lr=0.00146]  a photo of the nice <0>\n",
            "Steps:  27% 136/500 [02:46<07:38,  1.26s/it, loss=0.0042, lr=0.00146]a photo of the cool <0>\n",
            "tensor(0.0079, device='cuda:0')\n",
            "tensor([[0.4310]], device='cuda:0')\n",
            "Current Norm : tensor([0.4265], device='cuda:0')\n",
            "Steps:  27% 137/500 [02:47<07:39,  1.26s/it, loss=0.00199, lr=0.00145]the photo of a <0>\n",
            "Steps:  28% 138/500 [02:49<07:36,  1.26s/it, loss=0.00332, lr=0.00145]a photo of the small <0>\n",
            "Steps:  28% 139/500 [02:50<07:35,  1.26s/it, loss=0.0176, lr=0.00144] a rendering of a <0>\n",
            "Steps:  28% 140/500 [02:51<07:23,  1.23s/it, loss=0.0274, lr=0.00144]a photo of a clean <0>\n",
            "tensor(0.0070, device='cuda:0')\n",
            "tensor([[0.4309]], device='cuda:0')\n",
            "Current Norm : tensor([0.4264], device='cuda:0')\n",
            "Steps:  28% 141/500 [02:52<07:17,  1.22s/it, loss=0.00377, lr=0.00144]a photo of the cool <0>\n",
            "Steps:  28% 142/500 [02:53<07:10,  1.20s/it, loss=0.00058, lr=0.00143]a photo of a nice <0>\n",
            "Steps:  29% 143/500 [02:55<07:05,  1.19s/it, loss=0.0106, lr=0.00143] the photo of a <0>\n",
            "Steps:  29% 144/500 [02:56<07:03,  1.19s/it, loss=0.00833, lr=0.00142]a rendition of the <0>\n",
            "tensor(0.0081, device='cuda:0')\n",
            "tensor([[0.4307]], device='cuda:0')\n",
            "Current Norm : tensor([0.4263], device='cuda:0')\n",
            "Steps:  29% 145/500 [02:57<07:03,  1.19s/it, loss=0.0313, lr=0.00142] a rendition of the <0>\n",
            "Steps:  29% 146/500 [02:58<06:59,  1.18s/it, loss=0.00738, lr=0.00142]a dark photo of the <0>\n",
            "Steps:  29% 147/500 [02:59<06:56,  1.18s/it, loss=0.0259, lr=0.00141] a photo of a small <0>\n",
            "Steps:  30% 148/500 [03:01<06:57,  1.19s/it, loss=0.0325, lr=0.00141]a photo of one <0>\n",
            "tensor(0.0068, device='cuda:0')\n",
            "tensor([[0.4306]], device='cuda:0')\n",
            "Current Norm : tensor([0.4263], device='cuda:0')\n",
            "Steps:  30% 149/500 [03:02<07:06,  1.22s/it, loss=0.00814, lr=0.0014]a rendering of a <0>\n",
            "Steps:  30% 150/500 [03:03<07:10,  1.23s/it, loss=0.00522, lr=0.0014]a rendering of a <0>\n",
            "Steps:  30% 151/500 [03:04<07:12,  1.24s/it, loss=0.0018, lr=0.0014] a cropped photo of a <0>\n",
            "Steps:  30% 152/500 [03:06<07:12,  1.24s/it, loss=0.00105, lr=0.00139]the photo of a <0>\n",
            "tensor(0.0086, device='cuda:0')\n",
            "tensor([[0.4305]], device='cuda:0')\n",
            "Current Norm : tensor([0.4263], device='cuda:0')\n",
            "Steps:  31% 153/500 [03:07<07:14,  1.25s/it, loss=0.0599, lr=0.00139] a dark photo of the <0>\n",
            "Steps:  31% 154/500 [03:08<07:13,  1.25s/it, loss=0.0386, lr=0.00138]a close-up photo of the <0>\n",
            "Steps:  31% 155/500 [03:09<07:12,  1.25s/it, loss=0.0356, lr=0.00138]a cropped photo of the <0>\n",
            "Steps:  31% 156/500 [03:11<07:14,  1.26s/it, loss=0.00048, lr=0.00138]a good photo of the <0>\n",
            "tensor(0.0182, device='cuda:0')\n",
            "tensor([[0.4301]], device='cuda:0')\n",
            "Current Norm : tensor([0.4260], device='cuda:0')\n",
            "Steps:  31% 157/500 [03:12<07:15,  1.27s/it, loss=0.0469, lr=0.00137] a photo of the small <0>\n",
            "Steps:  32% 158/500 [03:13<07:04,  1.24s/it, loss=0.00098, lr=0.00137]a good photo of a <0>\n",
            "Steps:  32% 159/500 [03:14<06:56,  1.22s/it, loss=0.025, lr=0.00136]  a rendition of a <0>\n",
            "Steps:  32% 160/500 [03:16<06:50,  1.21s/it, loss=0.0133, lr=0.00136]a good photo of a <0>\n",
            "tensor(0.0069, device='cuda:0')\n",
            "tensor([[0.4298]], device='cuda:0')\n",
            "Current Norm : tensor([0.4258], device='cuda:0')\n",
            "Steps:  32% 161/500 [03:17<06:48,  1.20s/it, loss=0.0299, lr=0.00136]a photo of the nice <0>\n",
            "Steps:  32% 162/500 [03:18<06:43,  1.19s/it, loss=0.0319, lr=0.00135]a photo of a nice <0>\n",
            "Steps:  33% 163/500 [03:19<06:40,  1.19s/it, loss=0.00162, lr=0.00135]a photo of one <0>\n",
            "Steps:  33% 164/500 [03:20<06:37,  1.18s/it, loss=0.00572, lr=0.00134]a photo of one <0>\n",
            "tensor(0.0073, device='cuda:0')\n",
            "tensor([[0.4295]], device='cuda:0')\n",
            "Current Norm : tensor([0.4256], device='cuda:0')\n",
            "Steps:  33% 165/500 [03:21<06:37,  1.19s/it, loss=0.00419, lr=0.00134]a rendering of a <0>\n",
            "Steps:  33% 166/500 [03:23<06:34,  1.18s/it, loss=0.0126, lr=0.00134] a photo of a small <0>\n",
            "Steps:  33% 167/500 [03:24<06:41,  1.20s/it, loss=0.00117, lr=0.00133]the photo of a <0>\n",
            "Steps:  34% 168/500 [03:25<06:45,  1.22s/it, loss=0.00704, lr=0.00133]a photo of a clean <0>\n",
            "tensor(0.0068, device='cuda:0')\n",
            "tensor([[0.4293]], device='cuda:0')\n",
            "Current Norm : tensor([0.4255], device='cuda:0')\n",
            "Steps:  34% 169/500 [03:26<06:49,  1.24s/it, loss=0.0565, lr=0.00132] a photo of the <0>\n",
            "Steps:  34% 170/500 [03:28<06:49,  1.24s/it, loss=0.0017, lr=0.00132]a photo of a dirty <0>\n",
            "Steps:  34% 171/500 [03:29<06:49,  1.25s/it, loss=0.0839, lr=0.00132]a rendering of a <0>\n",
            "Steps:  34% 172/500 [03:30<06:49,  1.25s/it, loss=0.00911, lr=0.00131]a photo of the clean <0>\n",
            "tensor(0.0075, device='cuda:0')\n",
            "tensor([[0.4292]], device='cuda:0')\n",
            "Current Norm : tensor([0.4254], device='cuda:0')\n",
            "Steps:  35% 173/500 [03:31<06:50,  1.26s/it, loss=0.0504, lr=0.00131] a photo of a small <0>\n",
            "Steps:  35% 174/500 [03:33<06:49,  1.26s/it, loss=0.0226, lr=0.0013] a photo of the weird <0>\n",
            "Steps:  35% 175/500 [03:34<06:49,  1.26s/it, loss=0.0055, lr=0.0013]a rendition of a <0>\n",
            "Steps:  35% 176/500 [03:35<06:48,  1.26s/it, loss=0.0163, lr=0.0013]a photo of a cool <0>\n",
            "tensor(0.0070, device='cuda:0')\n",
            "tensor([[0.4289]], device='cuda:0')\n",
            "Current Norm : tensor([0.4252], device='cuda:0')\n",
            "Steps:  35% 177/500 [03:36<06:40,  1.24s/it, loss=0.000922, lr=0.00129]a photo of the cool <0>\n",
            "Steps:  36% 178/500 [03:38<06:32,  1.22s/it, loss=0.00548, lr=0.00129] a photo of my <0>\n",
            "Steps:  36% 179/500 [03:39<06:26,  1.21s/it, loss=0.00101, lr=0.00128]a dark photo of the <0>\n",
            "Steps:  36% 180/500 [03:40<06:21,  1.19s/it, loss=0.00667, lr=0.00128]a photo of a dirty <0>\n",
            "tensor(0.0082, device='cuda:0')\n",
            "tensor([[0.4286]], device='cuda:0')\n",
            "Current Norm : tensor([0.4249], device='cuda:0')\n",
            "Steps:  36% 181/500 [03:41<06:20,  1.19s/it, loss=0.0856, lr=0.00128] a photo of the <0>\n",
            "Steps:  36% 182/500 [03:42<06:16,  1.18s/it, loss=0.00383, lr=0.00127]a photo of one <0>\n",
            "Steps:  37% 183/500 [03:43<06:13,  1.18s/it, loss=0.00261, lr=0.00127]a photo of the cool <0>\n",
            "Steps:  37% 184/500 [03:45<06:11,  1.18s/it, loss=0.0395, lr=0.00126] a photo of the weird <0>\n",
            "tensor(0.0082, device='cuda:0')\n",
            "tensor([[0.4281]], device='cuda:0')\n",
            "Current Norm : tensor([0.4246], device='cuda:0')\n",
            "Steps:  37% 185/500 [03:46<06:20,  1.21s/it, loss=0.0189, lr=0.00126]a photo of a nice <0>\n",
            "Steps:  37% 186/500 [03:47<06:24,  1.22s/it, loss=0.000854, lr=0.00126]the photo of a <0>\n",
            "Steps:  37% 187/500 [03:48<06:25,  1.23s/it, loss=0.00123, lr=0.00125] a photo of the weird <0>\n",
            "Steps:  38% 188/500 [03:50<06:25,  1.24s/it, loss=0.0231, lr=0.00125] the photo of a <0>\n",
            "tensor(0.0062, device='cuda:0')\n",
            "tensor([[0.4277]], device='cuda:0')\n",
            "Current Norm : tensor([0.4242], device='cuda:0')\n",
            "Steps:  38% 189/500 [03:51<06:28,  1.25s/it, loss=0.00445, lr=0.00124]a photo of the large <0>\n",
            "Steps:  38% 190/500 [03:52<06:28,  1.25s/it, loss=0.0283, lr=0.00124] a photo of the small <0>\n",
            "Steps:  38% 191/500 [03:53<06:26,  1.25s/it, loss=0.000506, lr=0.00124]a photo of the small <0>\n",
            "Steps:  38% 192/500 [03:55<06:25,  1.25s/it, loss=0.00465, lr=0.00123] a photo of the nice <0>\n",
            "tensor(0.0072, device='cuda:0')\n",
            "tensor([[0.4273]], device='cuda:0')\n",
            "Current Norm : tensor([0.4240], device='cuda:0')\n",
            "Steps:  39% 193/500 [03:56<06:24,  1.25s/it, loss=0.00483, lr=0.00123]a photo of the <0>\n",
            "Steps:  39% 194/500 [03:57<06:23,  1.25s/it, loss=0.0159, lr=0.00122] a rendition of the <0>\n",
            "Steps:  39% 195/500 [03:58<06:14,  1.23s/it, loss=0.0034, lr=0.00122]a photo of the clean <0>\n",
            "Steps:  39% 196/500 [04:00<06:08,  1.21s/it, loss=0.0172, lr=0.00122]a rendition of the <0>\n",
            "tensor(0.0537, device='cuda:0')\n",
            "tensor([[0.4264]], device='cuda:0')\n",
            "Current Norm : tensor([0.4232], device='cuda:0')\n",
            "Steps:  39% 197/500 [04:01<06:04,  1.20s/it, loss=0.00255, lr=0.00121]a photo of a dirty <0>\n",
            "Steps:  40% 198/500 [04:02<05:59,  1.19s/it, loss=0.025, lr=0.00121]  a rendering of a <0>\n",
            "Steps:  40% 199/500 [04:03<05:55,  1.18s/it, loss=0.00921, lr=0.0012]a photo of the <0>\n",
            "Steps:  40% 200/500 [04:04<05:52,  1.17s/it, loss=0.0221, lr=0.0012] a photo of the weird <0>\n",
            "tensor(0.0122, device='cuda:0')\n",
            "tensor([[0.4259]], device='cuda:0')\n",
            "Current Norm : tensor([0.4228], device='cuda:0')\n",
            "Steps:  40% 201/500 [04:05<05:52,  1.18s/it, loss=0.00303, lr=0.0012]a photo of the <0>\n",
            "Steps:  40% 202/500 [04:07<05:49,  1.17s/it, loss=0.0156, lr=0.00119]a good photo of the <0>\n",
            "Steps:  41% 203/500 [04:08<05:48,  1.17s/it, loss=0.000441, lr=0.00119]a rendition of a <0>\n",
            "Steps:  41% 204/500 [04:09<05:54,  1.20s/it, loss=0.0216, lr=0.00118]  a cropped photo of the <0>\n",
            "tensor(0.0066, device='cuda:0')\n",
            "tensor([[0.4258]], device='cuda:0')\n",
            "Current Norm : tensor([0.4227], device='cuda:0')\n",
            "Steps:  41% 205/500 [04:10<06:00,  1.22s/it, loss=0.0124, lr=0.00118]a photo of the clean <0>\n",
            "Steps:  41% 206/500 [04:12<06:02,  1.23s/it, loss=0.00605, lr=0.00118]a rendition of a <0>\n",
            "Steps:  41% 207/500 [04:13<06:02,  1.24s/it, loss=0.0117, lr=0.00117] a photo of the small <0>\n",
            "Steps:  42% 208/500 [04:14<06:02,  1.24s/it, loss=0.00617, lr=0.00117]a dark photo of the <0>\n",
            "tensor(0.0062, device='cuda:0')\n",
            "tensor([[0.4257]], device='cuda:0')\n",
            "Current Norm : tensor([0.4227], device='cuda:0')\n",
            "Steps:  42% 209/500 [04:15<06:03,  1.25s/it, loss=0.0022, lr=0.00116] a close-up photo of a <0>\n",
            "Steps:  42% 210/500 [04:17<06:04,  1.26s/it, loss=0.0202, lr=0.00116]a cropped photo of a <0>\n",
            "Steps:  42% 211/500 [04:18<06:03,  1.26s/it, loss=0.0267, lr=0.00116]a cropped photo of the <0>\n",
            "Steps:  42% 212/500 [04:19<06:01,  1.26s/it, loss=0.00984, lr=0.00115]a good photo of the <0>\n",
            "tensor(0.0109, device='cuda:0')\n",
            "tensor([[0.4257]], device='cuda:0')\n",
            "Current Norm : tensor([0.4228], device='cuda:0')\n",
            "Steps:  43% 213/500 [04:20<06:00,  1.26s/it, loss=0.0341, lr=0.00115] a photo of a nice <0>\n",
            "Steps:  43% 214/500 [04:21<05:52,  1.23s/it, loss=0.0198, lr=0.00114]a photo of the small <0>\n",
            "Steps:  43% 215/500 [04:23<05:45,  1.21s/it, loss=0.000551, lr=0.00114]a rendition of the <0>\n",
            "Steps:  43% 216/500 [04:24<05:39,  1.20s/it, loss=0.0373, lr=0.00114]  a cropped photo of a <0>\n",
            "tensor(0.0058, device='cuda:0')\n",
            "tensor([[0.4257]], device='cuda:0')\n",
            "Current Norm : tensor([0.4228], device='cuda:0')\n",
            "Steps:  43% 217/500 [04:25<05:38,  1.19s/it, loss=0.0374, lr=0.00113]a close-up photo of the <0>\n",
            "Steps:  44% 218/500 [04:26<05:34,  1.19s/it, loss=0.00155, lr=0.00113]a photo of a small <0>\n",
            "Steps:  44% 219/500 [04:27<05:31,  1.18s/it, loss=0.00655, lr=0.00112]a cropped photo of a <0>\n",
            "Steps:  44% 220/500 [04:29<05:29,  1.18s/it, loss=0.0413, lr=0.00112] a cropped photo of the <0>\n",
            "tensor(0.0137, device='cuda:0')\n",
            "tensor([[0.4256]], device='cuda:0')\n",
            "Current Norm : tensor([0.4227], device='cuda:0')\n",
            "Steps:  44% 221/500 [04:30<05:28,  1.18s/it, loss=0.0109, lr=0.00112]a photo of the clean <0>\n",
            "Steps:  44% 222/500 [04:31<05:35,  1.21s/it, loss=0.0258, lr=0.00111]a cropped photo of the <0>\n",
            "Steps:  45% 223/500 [04:32<05:38,  1.22s/it, loss=0.00477, lr=0.00111]a photo of my <0>\n",
            "Steps:  45% 224/500 [04:33<05:40,  1.23s/it, loss=0.0389, lr=0.0011]  a close-up photo of a <0>\n",
            "tensor(0.0063, device='cuda:0')\n",
            "tensor([[0.4255]], device='cuda:0')\n",
            "Current Norm : tensor([0.4227], device='cuda:0')\n",
            "Steps:  45% 225/500 [04:35<05:42,  1.24s/it, loss=0.000337, lr=0.0011]a photo of the clean <0>\n",
            "Steps:  45% 226/500 [04:36<05:41,  1.25s/it, loss=0.00172, lr=0.0011] a photo of my <0>\n",
            "Steps:  45% 227/500 [04:37<05:41,  1.25s/it, loss=0.0495, lr=0.00109]a good photo of a <0>\n",
            "Steps:  46% 228/500 [04:39<05:40,  1.25s/it, loss=0.00468, lr=0.00109]a close-up photo of a <0>\n",
            "tensor(0.0074, device='cuda:0')\n",
            "tensor([[0.4254]], device='cuda:0')\n",
            "Current Norm : tensor([0.4227], device='cuda:0')\n",
            "Steps:  46% 229/500 [04:40<05:40,  1.26s/it, loss=0.00663, lr=0.00108]the photo of a <0>\n",
            "Steps:  46% 230/500 [04:41<05:39,  1.26s/it, loss=0.00966, lr=0.00108]a rendition of the <0>\n",
            "Steps:  46% 231/500 [04:42<05:37,  1.26s/it, loss=0.00542, lr=0.00108]a photo of the weird <0>\n",
            "Steps:  46% 232/500 [04:43<05:30,  1.23s/it, loss=0.00523, lr=0.00107]a photo of the large <0>\n",
            "tensor(0.0109, device='cuda:0')\n",
            "tensor([[0.4253]], device='cuda:0')\n",
            "Current Norm : tensor([0.4226], device='cuda:0')\n",
            "Steps:  47% 233/500 [04:45<05:26,  1.22s/it, loss=0.00281, lr=0.00107]a photo of the weird <0>\n",
            "Steps:  47% 234/500 [04:46<05:20,  1.21s/it, loss=0.000607, lr=0.00106]a photo of a clean <0>\n",
            "Steps:  47% 235/500 [04:47<05:16,  1.19s/it, loss=0.00359, lr=0.00106] a cropped photo of the <0>\n",
            "Steps:  47% 236/500 [04:48<05:12,  1.18s/it, loss=0.00439, lr=0.00106]a photo of a <0>\n",
            "tensor(0.0118, device='cuda:0')\n",
            "tensor([[0.4251]], device='cuda:0')\n",
            "Current Norm : tensor([0.4225], device='cuda:0')\n",
            "Steps:  47% 237/500 [04:49<05:11,  1.19s/it, loss=0.000372, lr=0.00105]a rendition of a <0>\n",
            "Steps:  48% 238/500 [04:51<05:09,  1.18s/it, loss=0.0743, lr=0.00105]  a rendition of the <0>\n",
            "Steps:  48% 239/500 [04:52<05:06,  1.18s/it, loss=0.00909, lr=0.00104]a photo of the nice <0>\n",
            "Steps:  48% 240/500 [04:53<05:05,  1.18s/it, loss=0.00474, lr=0.00104]a photo of my <0>\n",
            "tensor(0.0105, device='cuda:0')\n",
            "tensor([[0.4249]], device='cuda:0')\n",
            "Current Norm : tensor([0.4223], device='cuda:0')\n",
            "Steps:  48% 241/500 [04:54<05:13,  1.21s/it, loss=0.0278, lr=0.00104] a close-up photo of the <0>\n",
            "Steps:  48% 242/500 [04:55<05:16,  1.23s/it, loss=0.00947, lr=0.00103]a cropped photo of a <0>\n",
            "Steps:  49% 243/500 [04:57<05:17,  1.23s/it, loss=0.0525, lr=0.00103] a photo of one <0>\n",
            "Steps:  49% 244/500 [04:58<05:17,  1.24s/it, loss=0.0312, lr=0.00102]a photo of the clean <0>\n",
            "tensor(0.0071, device='cuda:0')\n",
            "tensor([[0.4247]], device='cuda:0')\n",
            "Current Norm : tensor([0.4222], device='cuda:0')\n",
            "Steps:  49% 245/500 [04:59<05:19,  1.25s/it, loss=0.00084, lr=0.00102]a cropped photo of the <0>\n",
            "Steps:  49% 246/500 [05:00<05:17,  1.25s/it, loss=0.00346, lr=0.00102]a close-up photo of a <0>\n",
            "Steps:  49% 247/500 [05:02<05:17,  1.25s/it, loss=0.0615, lr=0.00101] a dark photo of the <0>\n",
            "Steps:  50% 248/500 [05:03<05:15,  1.25s/it, loss=0.000912, lr=0.00101]a cropped photo of a <0>\n",
            "tensor(0.0067, device='cuda:0')\n",
            "tensor([[0.4245]], device='cuda:0')\n",
            "Current Norm : tensor([0.4220], device='cuda:0')\n",
            "Steps:  50% 249/500 [05:04<05:15,  1.26s/it, loss=0.00787, lr=0.001]   a good photo of a <0>\n",
            "Steps:  50% 250/500 [05:05<05:14,  1.26s/it, loss=0.000759, lr=0.001]a good photo of a <0>\n",
            "Steps:  50% 251/500 [05:07<05:06,  1.23s/it, loss=0.0478, lr=0.000996]a photo of the small <0>\n",
            "Steps:  50% 252/500 [05:08<05:00,  1.21s/it, loss=0.00161, lr=0.000992]a photo of the nice <0>\n",
            "tensor(0.0137, device='cuda:0')\n",
            "tensor([[0.4241]], device='cuda:0')\n",
            "Current Norm : tensor([0.4217], device='cuda:0')\n",
            "Steps:  51% 253/500 [05:09<04:57,  1.20s/it, loss=0.024, lr=0.000988]  a photo of a cool <0>\n",
            "Steps:  51% 254/500 [05:10<04:52,  1.19s/it, loss=0.0323, lr=0.000984]a good photo of a <0>\n",
            "Steps:  51% 255/500 [05:11<04:49,  1.18s/it, loss=0.0208, lr=0.00098] a good photo of a <0>\n",
            "Steps:  51% 256/500 [05:12<04:47,  1.18s/it, loss=0.00912, lr=0.000976]a photo of the small <0>\n",
            "tensor(0.0103, device='cuda:0')\n",
            "tensor([[0.4238]], device='cuda:0')\n",
            "Current Norm : tensor([0.4215], device='cuda:0')\n",
            "Steps:  51% 257/500 [05:14<04:46,  1.18s/it, loss=0.000929, lr=0.000972]a photo of the nice <0>\n",
            "Steps:  52% 258/500 [05:15<04:44,  1.17s/it, loss=0.0178, lr=0.000968]  a photo of a dirty <0>\n",
            "Steps:  52% 259/500 [05:16<04:48,  1.20s/it, loss=0.0191, lr=0.000964]a good photo of a <0>\n",
            "Steps:  52% 260/500 [05:17<04:51,  1.22s/it, loss=0.0152, lr=0.00096] a cropped photo of the <0>\n",
            "tensor(0.0110, device='cuda:0')\n",
            "tensor([[0.4236]], device='cuda:0')\n",
            "Current Norm : tensor([0.4213], device='cuda:0')\n",
            "Steps:  52% 261/500 [05:19<04:55,  1.23s/it, loss=0.00295, lr=0.000956]a photo of the <0>\n",
            "Steps:  52% 262/500 [05:20<04:54,  1.24s/it, loss=0.0539, lr=0.000952] a photo of a clean <0>\n",
            "Steps:  53% 263/500 [05:21<04:54,  1.24s/it, loss=0.00618, lr=0.000948]a close-up photo of the <0>\n",
            "Steps:  53% 264/500 [05:22<04:53,  1.24s/it, loss=0.00245, lr=0.000944]a photo of a <0>\n",
            "tensor(0.0082, device='cuda:0')\n",
            "tensor([[0.4234]], device='cuda:0')\n",
            "Current Norm : tensor([0.4212], device='cuda:0')\n",
            "Steps:  53% 265/500 [05:24<04:54,  1.26s/it, loss=0.0033, lr=0.00094]  a bright photo of the <0>\n",
            "Steps:  53% 266/500 [05:25<04:53,  1.25s/it, loss=0.0327, lr=0.000936]a photo of the clean <0>\n",
            "Steps:  53% 267/500 [05:26<04:51,  1.25s/it, loss=0.0178, lr=0.000932]a photo of the weird <0>\n",
            "Steps:  54% 268/500 [05:27<04:50,  1.25s/it, loss=0.00126, lr=0.000928]a close-up photo of a <0>\n",
            "tensor(0.0104, device='cuda:0')\n",
            "tensor([[0.4232]], device='cuda:0')\n",
            "Current Norm : tensor([0.4211], device='cuda:0')\n",
            "Steps:  54% 269/500 [05:29<04:44,  1.23s/it, loss=0.022, lr=0.000924]  a photo of a clean <0>\n",
            "Steps:  54% 270/500 [05:30<04:39,  1.21s/it, loss=0.0398, lr=0.00092]a rendition of a <0>\n",
            "Steps:  54% 271/500 [05:31<04:34,  1.20s/it, loss=0.0288, lr=0.000916]a photo of a <0>\n",
            "Steps:  54% 272/500 [05:32<04:32,  1.19s/it, loss=0.00518, lr=0.000912]a cropped photo of a <0>\n",
            "tensor(0.0168, device='cuda:0')\n",
            "tensor([[0.4229]], device='cuda:0')\n",
            "Current Norm : tensor([0.4208], device='cuda:0')\n",
            "Steps:  55% 273/500 [05:33<04:30,  1.19s/it, loss=0.0114, lr=0.000908] a photo of a clean <0>\n",
            "Steps:  55% 274/500 [05:34<04:26,  1.18s/it, loss=0.0457, lr=0.000904]a cropped photo of the <0>\n",
            "Steps:  55% 275/500 [05:36<04:24,  1.18s/it, loss=0.00219, lr=0.0009] a photo of a clean <0>\n",
            "Steps:  55% 276/500 [05:37<04:23,  1.18s/it, loss=0.00368, lr=0.000896]a photo of the weird <0>\n",
            "tensor(0.0114, device='cuda:0')\n",
            "tensor([[0.4226]], device='cuda:0')\n",
            "Current Norm : tensor([0.4206], device='cuda:0')\n",
            "Steps:  55% 277/500 [05:38<04:23,  1.18s/it, loss=0.00102, lr=0.000892]a good photo of the <0>\n",
            "Steps:  56% 278/500 [05:39<04:26,  1.20s/it, loss=0.0629, lr=0.000888] a photo of a dirty <0>\n",
            "Steps:  56% 279/500 [05:41<04:29,  1.22s/it, loss=0.0298, lr=0.000884]a photo of a small <0>\n",
            "Steps:  56% 280/500 [05:42<04:30,  1.23s/it, loss=0.0135, lr=0.00088] a good photo of a <0>\n",
            "tensor(0.0100, device='cuda:0')\n",
            "tensor([[0.4223]], device='cuda:0')\n",
            "Current Norm : tensor([0.4203], device='cuda:0')\n",
            "Steps:  56% 281/500 [05:43<04:32,  1.24s/it, loss=0.014, lr=0.000876]a photo of a <0>\n",
            "Steps:  56% 282/500 [05:44<04:30,  1.24s/it, loss=0.0178, lr=0.000872]a good photo of a <0>\n",
            "Steps:  57% 283/500 [05:46<04:30,  1.25s/it, loss=0.0101, lr=0.000868]a close-up photo of a <0>\n",
            "Steps:  57% 284/500 [05:47<04:31,  1.26s/it, loss=0.000588, lr=0.000864]a close-up photo of a <0>\n",
            "tensor(0.0060, device='cuda:0')\n",
            "tensor([[0.4220]], device='cuda:0')\n",
            "Current Norm : tensor([0.4201], device='cuda:0')\n",
            "Steps:  57% 285/500 [05:48<04:31,  1.26s/it, loss=0.00122, lr=0.00086]  a photo of a nice <0>\n",
            "Steps:  57% 286/500 [05:49<04:30,  1.26s/it, loss=0.0234, lr=0.000856]a good photo of the <0>\n",
            "Steps:  57% 287/500 [05:51<04:27,  1.26s/it, loss=0.0244, lr=0.000852]a good photo of a <0>\n",
            "Steps:  58% 288/500 [05:52<04:20,  1.23s/it, loss=0.0149, lr=0.000848]a dark photo of the <0>\n",
            "tensor(0.0129, device='cuda:0')\n",
            "tensor([[0.4217]], device='cuda:0')\n",
            "Current Norm : tensor([0.4199], device='cuda:0')\n",
            "Steps:  58% 289/500 [05:53<04:16,  1.21s/it, loss=0.00255, lr=0.000844]a photo of the cool <0>\n",
            "Steps:  58% 290/500 [05:54<04:11,  1.20s/it, loss=0.000792, lr=0.00084]a good photo of a <0>\n",
            "Steps:  58% 291/500 [05:55<04:08,  1.19s/it, loss=0.00658, lr=0.000836]a photo of a <0>\n",
            "Steps:  58% 292/500 [05:56<04:05,  1.18s/it, loss=0.000321, lr=0.000832]a photo of a nice <0>\n",
            "tensor(0.0057, device='cuda:0')\n",
            "tensor([[0.4215]], device='cuda:0')\n",
            "Current Norm : tensor([0.4197], device='cuda:0')\n",
            "Steps:  59% 293/500 [05:58<04:04,  1.18s/it, loss=0.0202, lr=0.000828]  a photo of the large <0>\n",
            "Steps:  59% 294/500 [05:59<04:02,  1.18s/it, loss=0.00116, lr=0.000824]a photo of one <0>\n",
            "Steps:  59% 295/500 [06:00<04:00,  1.17s/it, loss=0.00173, lr=0.00082] a good photo of the <0>\n",
            "Steps:  59% 296/500 [06:01<04:03,  1.20s/it, loss=0.0269, lr=0.000816]a good photo of a <0>\n",
            "tensor(0.0080, device='cuda:0')\n",
            "tensor([[0.4212]], device='cuda:0')\n",
            "Current Norm : tensor([0.4195], device='cuda:0')\n",
            "Steps:  59% 297/500 [06:02<04:08,  1.22s/it, loss=0.000758, lr=0.000812]a close-up photo of a <0>\n",
            "Steps:  60% 298/500 [06:04<04:08,  1.23s/it, loss=0.00152, lr=0.000808] a photo of a nice <0>\n",
            "Steps:  60% 299/500 [06:05<04:08,  1.23s/it, loss=0.0031, lr=0.000804] a dark photo of the <0>\n",
            "Steps:  60% 300/500 [06:06<04:07,  1.24s/it, loss=0.00355, lr=0.0008] a photo of a <0>\n",
            "tensor(0.0201, device='cuda:0')\n",
            "tensor([[0.4209]], device='cuda:0')\n",
            "Current Norm : tensor([0.4192], device='cuda:0')\n",
            "Steps:  60% 301/500 [06:07<04:08,  1.25s/it, loss=0.0064, lr=0.000796]a photo of a clean <0>\n",
            "Steps:  60% 302/500 [06:09<04:07,  1.25s/it, loss=0.00741, lr=0.000792]a photo of one <0>\n",
            "Steps:  61% 303/500 [06:10<04:05,  1.25s/it, loss=0.033, lr=0.000788]  a good photo of the <0>\n",
            "Steps:  61% 304/500 [06:11<04:05,  1.25s/it, loss=0.00152, lr=0.000784]a close-up photo of a <0>\n",
            "tensor(0.0087, device='cuda:0')\n",
            "tensor([[0.4206]], device='cuda:0')\n",
            "Current Norm : tensor([0.4190], device='cuda:0')\n",
            "Steps:  61% 305/500 [06:13<04:04,  1.25s/it, loss=0.0078, lr=0.00078]  a photo of the small <0>\n",
            "Steps:  61% 306/500 [06:14<03:58,  1.23s/it, loss=0.0169, lr=0.000776]a cropped photo of a <0>\n",
            "Steps:  61% 307/500 [06:15<03:53,  1.21s/it, loss=0.0385, lr=0.000772]a photo of the weird <0>\n",
            "Steps:  62% 308/500 [06:16<03:49,  1.20s/it, loss=0.00163, lr=0.000768]a photo of the cool <0>\n",
            "tensor(0.0100, device='cuda:0')\n",
            "tensor([[0.4204]], device='cuda:0')\n",
            "Current Norm : tensor([0.4189], device='cuda:0')\n",
            "Steps:  62% 309/500 [06:17<03:47,  1.19s/it, loss=0.0131, lr=0.000764] a photo of a cool <0>\n",
            "Steps:  62% 310/500 [06:18<03:45,  1.19s/it, loss=0.00788, lr=0.00076]a photo of the nice <0>\n",
            "Steps:  62% 311/500 [06:20<03:43,  1.18s/it, loss=0.00644, lr=0.000756]a photo of the cool <0>\n",
            "Steps:  62% 312/500 [06:21<03:40,  1.17s/it, loss=0.00462, lr=0.000752]a cropped photo of the <0>\n",
            "tensor(0.0140, device='cuda:0')\n",
            "tensor([[0.4202]], device='cuda:0')\n",
            "Current Norm : tensor([0.4187], device='cuda:0')\n",
            "Steps:  63% 313/500 [06:22<03:40,  1.18s/it, loss=0.023, lr=0.000748]  a photo of the <0>\n",
            "Steps:  63% 314/500 [06:23<03:38,  1.17s/it, loss=0.000474, lr=0.000744]a photo of the cool <0>\n",
            "Steps:  63% 315/500 [06:24<03:41,  1.20s/it, loss=0.00119, lr=0.00074]  a photo of one <0>\n",
            "Steps:  63% 316/500 [06:26<03:43,  1.21s/it, loss=0.000495, lr=0.000736]a photo of the clean <0>\n",
            "tensor(0.0043, device='cuda:0')\n",
            "tensor([[0.4200]], device='cuda:0')\n",
            "Current Norm : tensor([0.4186], device='cuda:0')\n",
            "Steps:  63% 317/500 [06:27<03:45,  1.23s/it, loss=0.0112, lr=0.000732]  the photo of a <0>\n",
            "Steps:  64% 318/500 [06:28<03:45,  1.24s/it, loss=0.00346, lr=0.000728]a photo of the nice <0>\n",
            "Steps:  64% 319/500 [06:29<03:44,  1.24s/it, loss=0.0257, lr=0.000724] a photo of the cool <0>\n",
            "Steps:  64% 320/500 [06:31<03:44,  1.25s/it, loss=0.00543, lr=0.00072]a photo of a nice <0>\n",
            "tensor(0.0141, device='cuda:0')\n",
            "tensor([[0.4198]], device='cuda:0')\n",
            "Current Norm : tensor([0.4184], device='cuda:0')\n",
            "Steps:  64% 321/500 [06:32<03:44,  1.26s/it, loss=0.00226, lr=0.000716]a close-up photo of the <0>\n",
            "Steps:  64% 322/500 [06:33<03:43,  1.25s/it, loss=0.0182, lr=0.000712] a cropped photo of the <0>\n",
            "Steps:  65% 323/500 [06:34<03:42,  1.25s/it, loss=0.00224, lr=0.000708]a photo of the clean <0>\n",
            "Steps:  65% 324/500 [06:36<03:40,  1.25s/it, loss=0.00975, lr=0.000704]a close-up photo of the <0>\n",
            "tensor(0.0096, device='cuda:0')\n",
            "tensor([[0.4195]], device='cuda:0')\n",
            "Current Norm : tensor([0.4182], device='cuda:0')\n",
            "Steps:  65% 325/500 [06:37<03:35,  1.23s/it, loss=0.000697, lr=0.0007] a photo of a small <0>\n",
            "Steps:  65% 326/500 [06:38<03:30,  1.21s/it, loss=0.0441, lr=0.000696]a close-up photo of a <0>\n",
            "Steps:  65% 327/500 [06:39<03:27,  1.20s/it, loss=0.00162, lr=0.000692]a rendering of a <0>\n",
            "Steps:  66% 328/500 [06:40<03:24,  1.19s/it, loss=0.0299, lr=0.000688] a photo of the <0>\n",
            "tensor(0.0181, device='cuda:0')\n",
            "tensor([[0.4193]], device='cuda:0')\n",
            "Current Norm : tensor([0.4180], device='cuda:0')\n",
            "Steps:  66% 329/500 [06:41<03:23,  1.19s/it, loss=0.0799, lr=0.000684]a photo of a <0>\n",
            "Steps:  66% 330/500 [06:43<03:21,  1.18s/it, loss=0.0525, lr=0.00068] a photo of the small <0>\n",
            "Steps:  66% 331/500 [06:44<03:18,  1.18s/it, loss=0.036, lr=0.000676]a photo of the clean <0>\n",
            "Steps:  66% 332/500 [06:45<03:17,  1.18s/it, loss=0.0561, lr=0.000672]a photo of the clean <0>\n",
            "tensor(0.0148, device='cuda:0')\n",
            "tensor([[0.4191]], device='cuda:0')\n",
            "Current Norm : tensor([0.4178], device='cuda:0')\n",
            "Steps:  67% 333/500 [06:46<03:20,  1.20s/it, loss=0.0275, lr=0.000668]a photo of the cool <0>\n",
            "Steps:  67% 334/500 [06:48<03:22,  1.22s/it, loss=0.00117, lr=0.000664]a rendition of a <0>\n",
            "Steps:  67% 335/500 [06:49<03:22,  1.23s/it, loss=0.0159, lr=0.00066]  a photo of a <0>\n",
            "Steps:  67% 336/500 [06:50<03:23,  1.24s/it, loss=0.00612, lr=0.000656]a rendering of a <0>\n",
            "tensor(0.0113, device='cuda:0')\n",
            "tensor([[0.4188]], device='cuda:0')\n",
            "Current Norm : tensor([0.4176], device='cuda:0')\n",
            "Steps:  67% 337/500 [06:51<03:24,  1.25s/it, loss=0.000442, lr=0.000652]a cropped photo of the <0>\n",
            "Steps:  68% 338/500 [06:53<03:23,  1.25s/it, loss=0.00843, lr=0.000648] a photo of the small <0>\n",
            "Steps:  68% 339/500 [06:54<03:21,  1.25s/it, loss=0.00533, lr=0.000644]a photo of a small <0>\n",
            "Steps:  68% 340/500 [06:55<03:20,  1.25s/it, loss=0.000702, lr=0.00064]a cropped photo of a <0>\n",
            "tensor(0.0120, device='cuda:0')\n",
            "tensor([[0.4185]], device='cuda:0')\n",
            "Current Norm : tensor([0.4173], device='cuda:0')\n",
            "Steps:  68% 341/500 [06:56<03:20,  1.26s/it, loss=0.0345, lr=0.000636] a good photo of the <0>\n",
            "Steps:  68% 342/500 [06:58<03:18,  1.26s/it, loss=0.00256, lr=0.000632]a bright photo of the <0>\n",
            "Steps:  69% 343/500 [06:59<03:13,  1.23s/it, loss=0.0614, lr=0.000628] a photo of a small <0>\n",
            "Steps:  69% 344/500 [07:00<03:08,  1.21s/it, loss=0.0804, lr=0.000624]a photo of a clean <0>\n",
            "tensor(0.0083, device='cuda:0')\n",
            "tensor([[0.4182]], device='cuda:0')\n",
            "Current Norm : tensor([0.4171], device='cuda:0')\n",
            "Steps:  69% 345/500 [07:01<03:06,  1.20s/it, loss=0.000801, lr=0.00062]a photo of a <0>\n",
            "Steps:  69% 346/500 [07:02<03:03,  1.19s/it, loss=0.0204, lr=0.000616] a photo of a cool <0>\n",
            "Steps:  69% 347/500 [07:03<03:01,  1.19s/it, loss=0.00649, lr=0.000612]a cropped photo of the <0>\n",
            "Steps:  70% 348/500 [07:05<03:00,  1.18s/it, loss=0.000719, lr=0.000608]a photo of a dirty <0>\n",
            "tensor(0.0111, device='cuda:0')\n",
            "tensor([[0.4180]], device='cuda:0')\n",
            "Current Norm : tensor([0.4169], device='cuda:0')\n",
            "Steps:  70% 349/500 [07:06<02:59,  1.19s/it, loss=0.00602, lr=0.000604] a photo of a dirty <0>\n",
            "Steps:  70% 350/500 [07:07<02:57,  1.18s/it, loss=0.0055, lr=0.0006]   a photo of the cool <0>\n",
            "Steps:  70% 351/500 [07:08<02:54,  1.17s/it, loss=0.00394, lr=0.000596]a rendition of a <0>\n",
            "Steps:  70% 352/500 [07:09<02:57,  1.20s/it, loss=0.0201, lr=0.000592] a good photo of a <0>\n",
            "tensor(0.0079, device='cuda:0')\n",
            "tensor([[0.4178]], device='cuda:0')\n",
            "Current Norm : tensor([0.4167], device='cuda:0')\n",
            "Steps:  71% 353/500 [07:11<03:00,  1.23s/it, loss=0.0072, lr=0.000588]a rendering of a <0>\n",
            "Steps:  71% 354/500 [07:12<02:59,  1.23s/it, loss=0.0116, lr=0.000584]a rendering of a <0>\n",
            "Steps:  71% 355/500 [07:13<02:59,  1.24s/it, loss=0.00348, lr=0.00058]a photo of a nice <0>\n",
            "Steps:  71% 356/500 [07:14<02:59,  1.25s/it, loss=0.000936, lr=0.000576]a photo of a dirty <0>\n",
            "tensor(0.0047, device='cuda:0')\n",
            "tensor([[0.4175]], device='cuda:0')\n",
            "Current Norm : tensor([0.4165], device='cuda:0')\n",
            "Steps:  71% 357/500 [07:16<02:59,  1.25s/it, loss=0.000939, lr=0.000572]a rendering of a <0>\n",
            "Steps:  72% 358/500 [07:17<02:58,  1.26s/it, loss=0.0102, lr=0.000568]  a photo of the cool <0>\n",
            "Steps:  72% 359/500 [07:18<02:57,  1.26s/it, loss=0.000542, lr=0.000564]a close-up photo of a <0>\n",
            "Steps:  72% 360/500 [07:20<02:55,  1.26s/it, loss=0.00147, lr=0.00056]  a bright photo of the <0>\n",
            "tensor(0.0066, device='cuda:0')\n",
            "tensor([[0.4172]], device='cuda:0')\n",
            "Current Norm : tensor([0.4162], device='cuda:0')\n",
            "Steps:  72% 361/500 [07:21<02:55,  1.26s/it, loss=0.0908, lr=0.000556]a photo of a <0>\n",
            "Steps:  72% 362/500 [07:22<02:50,  1.23s/it, loss=0.000539, lr=0.000552]a photo of the small <0>\n",
            "Steps:  73% 363/500 [07:23<02:45,  1.21s/it, loss=0.00152, lr=0.000548] a rendering of a <0>\n",
            "Steps:  73% 364/500 [07:24<02:42,  1.20s/it, loss=0.000375, lr=0.000544]a photo of a <0>\n",
            "tensor(0.0057, device='cuda:0')\n",
            "tensor([[0.4169]], device='cuda:0')\n",
            "Current Norm : tensor([0.4160], device='cuda:0')\n",
            "Steps:  73% 365/500 [07:25<02:41,  1.19s/it, loss=0.0143, lr=0.00054]   a photo of the large <0>\n",
            "Steps:  73% 366/500 [07:27<02:38,  1.19s/it, loss=0.00099, lr=0.000536]a photo of a dirty <0>\n",
            "Steps:  73% 367/500 [07:28<02:36,  1.18s/it, loss=0.0307, lr=0.000532] a cropped photo of the <0>\n",
            "Steps:  74% 368/500 [07:29<02:35,  1.18s/it, loss=0.00907, lr=0.000528]a bright photo of the <0>\n",
            "tensor(0.0093, device='cuda:0')\n",
            "tensor([[0.4166]], device='cuda:0')\n",
            "Current Norm : tensor([0.4158], device='cuda:0')\n",
            "Steps:  74% 369/500 [07:30<02:34,  1.18s/it, loss=0.00922, lr=0.000524]a rendering of a <0>\n",
            "Steps:  74% 370/500 [07:31<02:35,  1.20s/it, loss=0.046, lr=0.00052]   a photo of the nice <0>\n",
            "Steps:  74% 371/500 [07:33<02:36,  1.21s/it, loss=0.00746, lr=0.000516]a photo of a <0>\n",
            "Steps:  74% 372/500 [07:34<02:37,  1.23s/it, loss=0.00761, lr=0.000512]a photo of a small <0>\n",
            "tensor(0.0107, device='cuda:0')\n",
            "tensor([[0.4164]], device='cuda:0')\n",
            "Current Norm : tensor([0.4156], device='cuda:0')\n",
            "Steps:  75% 373/500 [07:35<02:38,  1.25s/it, loss=0.0119, lr=0.000508] a photo of a nice <0>\n",
            "Steps:  75% 374/500 [07:36<02:37,  1.25s/it, loss=0.00366, lr=0.000504]a photo of a nice <0>\n",
            "Steps:  75% 375/500 [07:38<02:36,  1.25s/it, loss=0.00571, lr=0.0005]  a photo of a dirty <0>\n",
            "Steps:  75% 376/500 [07:39<02:34,  1.25s/it, loss=0.0235, lr=0.000496]a photo of the nice <0>\n",
            "tensor(0.0124, device='cuda:0')\n",
            "tensor([[0.4161]], device='cuda:0')\n",
            "Current Norm : tensor([0.4153], device='cuda:0')\n",
            "Steps:  75% 377/500 [07:40<02:34,  1.25s/it, loss=0.0143, lr=0.000492]a photo of the cool <0>\n",
            "Steps:  76% 378/500 [07:41<02:33,  1.25s/it, loss=0.0496, lr=0.000488]a photo of a <0>\n",
            "Steps:  76% 379/500 [07:43<02:31,  1.25s/it, loss=0.0311, lr=0.000484]a photo of a dirty <0>\n",
            "Steps:  76% 380/500 [07:44<02:27,  1.23s/it, loss=0.0102, lr=0.00048] a photo of the <0>\n",
            "tensor(0.0091, device='cuda:0')\n",
            "tensor([[0.4159]], device='cuda:0')\n",
            "Current Norm : tensor([0.4151], device='cuda:0')\n",
            "Steps:  76% 381/500 [07:45<02:24,  1.21s/it, loss=0.000789, lr=0.000476]a photo of the clean <0>\n",
            "Steps:  76% 382/500 [07:46<02:21,  1.20s/it, loss=0.0582, lr=0.000472]  a bright photo of the <0>\n",
            "Steps:  77% 383/500 [07:47<02:19,  1.19s/it, loss=0.0367, lr=0.000468]a photo of the clean <0>\n",
            "Steps:  77% 384/500 [07:49<02:17,  1.18s/it, loss=0.00128, lr=0.000464]the photo of a <0>\n",
            "tensor(0.0101, device='cuda:0')\n",
            "tensor([[0.4157]], device='cuda:0')\n",
            "Current Norm : tensor([0.4149], device='cuda:0')\n",
            "Steps:  77% 385/500 [07:50<02:16,  1.18s/it, loss=0.00362, lr=0.00046] a bright photo of the <0>\n",
            "Steps:  77% 386/500 [07:51<02:15,  1.19s/it, loss=0.00886, lr=0.000456]a cropped photo of a <0>\n",
            "Steps:  77% 387/500 [07:52<02:13,  1.18s/it, loss=0.019, lr=0.000452]  the photo of a <0>\n",
            "Steps:  78% 388/500 [07:53<02:11,  1.18s/it, loss=0.0832, lr=0.000448]a close-up photo of a <0>\n",
            "tensor(0.0092, device='cuda:0')\n",
            "tensor([[0.4154]], device='cuda:0')\n",
            "Current Norm : tensor([0.4148], device='cuda:0')\n",
            "Steps:  78% 389/500 [07:55<02:14,  1.21s/it, loss=0.0141, lr=0.000444]a photo of a small <0>\n",
            "Steps:  78% 390/500 [07:56<02:16,  1.24s/it, loss=0.000858, lr=0.00044]a photo of a clean <0>\n",
            "Steps:  78% 391/500 [07:57<02:15,  1.24s/it, loss=0.00613, lr=0.000436]a close-up photo of the <0>\n",
            "Steps:  78% 392/500 [07:58<02:14,  1.25s/it, loss=0.000873, lr=0.000432]a photo of a clean <0>\n",
            "tensor(0.0081, device='cuda:0')\n",
            "tensor([[0.4152]], device='cuda:0')\n",
            "Current Norm : tensor([0.4146], device='cuda:0')\n",
            "Steps:  79% 393/500 [08:00<02:14,  1.25s/it, loss=0.00194, lr=0.000428] a photo of the cool <0>\n",
            "Steps:  79% 394/500 [08:01<02:12,  1.25s/it, loss=0.000413, lr=0.000424]a photo of a small <0>\n",
            "Steps:  79% 395/500 [08:02<02:11,  1.25s/it, loss=0.00955, lr=0.00042]  a photo of a cool <0>\n",
            "Steps:  79% 396/500 [08:03<02:09,  1.25s/it, loss=0.000472, lr=0.000416]a rendering of a <0>\n",
            "tensor(0.0061, device='cuda:0')\n",
            "tensor([[0.4150]], device='cuda:0')\n",
            "Current Norm : tensor([0.4144], device='cuda:0')\n",
            "Steps:  79% 397/500 [08:05<02:09,  1.26s/it, loss=0.00073, lr=0.000412] a bright photo of the <0>\n",
            "Steps:  80% 398/500 [08:06<02:07,  1.25s/it, loss=0.00635, lr=0.000408]a bright photo of the <0>\n",
            "Steps:  80% 399/500 [08:07<02:03,  1.23s/it, loss=0.00295, lr=0.000404]a photo of the large <0>\n",
            "Steps:  80% 400/500 [08:08<02:01,  1.21s/it, loss=0.0155, lr=0.0004]   a photo of a nice <0>\n",
            "tensor(0.0108, device='cuda:0')\n",
            "tensor([[0.4148]], device='cuda:0')\n",
            "Current Norm : tensor([0.4142], device='cuda:0')\n",
            "Steps:  80% 401/500 [08:09<01:59,  1.20s/it, loss=0.01, lr=0.000396]a photo of a clean <0>\n",
            "Steps:  80% 402/500 [08:11<01:56,  1.19s/it, loss=0.00771, lr=0.000392]a dark photo of the <0>\n",
            "Steps:  81% 403/500 [08:12<01:54,  1.18s/it, loss=0.00338, lr=0.000388]a photo of the small <0>\n",
            "Steps:  81% 404/500 [08:13<01:53,  1.18s/it, loss=0.00136, lr=0.000384]a photo of a cool <0>\n",
            "tensor(0.0107, device='cuda:0')\n",
            "tensor([[0.4146]], device='cuda:0')\n",
            "Current Norm : tensor([0.4140], device='cuda:0')\n",
            "Steps:  81% 405/500 [08:14<01:52,  1.18s/it, loss=0.00219, lr=0.00038] a good photo of the <0>\n",
            "Steps:  81% 406/500 [08:15<01:50,  1.18s/it, loss=0.0713, lr=0.000376]a rendering of a <0>\n",
            "Steps:  81% 407/500 [08:17<01:52,  1.21s/it, loss=0.0123, lr=0.000372]a photo of my <0>\n",
            "Steps:  82% 408/500 [08:18<01:52,  1.22s/it, loss=0.00163, lr=0.000368]a good photo of the <0>\n",
            "tensor(0.0097, device='cuda:0')\n",
            "tensor([[0.4144]], device='cuda:0')\n",
            "Current Norm : tensor([0.4139], device='cuda:0')\n",
            "Steps:  82% 409/500 [08:19<01:52,  1.24s/it, loss=0.0105, lr=0.000364] a photo of the small <0>\n",
            "Steps:  82% 410/500 [08:20<01:51,  1.24s/it, loss=0.0161, lr=0.00036] a photo of the clean <0>\n",
            "Steps:  82% 411/500 [08:22<01:51,  1.25s/it, loss=0.00449, lr=0.000356]a photo of the weird <0>\n",
            "Steps:  82% 412/500 [08:23<01:50,  1.25s/it, loss=0.00769, lr=0.000352]the photo of a <0>\n",
            "tensor(0.0088, device='cuda:0')\n",
            "tensor([[0.4142]], device='cuda:0')\n",
            "Current Norm : tensor([0.4137], device='cuda:0')\n",
            "Steps:  83% 413/500 [08:24<01:49,  1.26s/it, loss=0.000461, lr=0.000348]a photo of a <0>\n",
            "Steps:  83% 414/500 [08:25<01:48,  1.26s/it, loss=0.0642, lr=0.000344]  a rendition of the <0>\n",
            "Steps:  83% 415/500 [08:27<01:47,  1.26s/it, loss=0.000333, lr=0.00034]a photo of the small <0>\n",
            "Steps:  83% 416/500 [08:28<01:46,  1.26s/it, loss=0.00443, lr=0.000336]a cropped photo of a <0>\n",
            "tensor(0.0127, device='cuda:0')\n",
            "tensor([[0.4140]], device='cuda:0')\n",
            "Current Norm : tensor([0.4136], device='cuda:0')\n",
            "Steps:  83% 417/500 [08:29<01:43,  1.24s/it, loss=0.0526, lr=0.000332] a photo of my <0>\n",
            "Steps:  84% 418/500 [08:30<01:40,  1.22s/it, loss=0.00301, lr=0.000328]the photo of a <0>\n",
            "Steps:  84% 419/500 [08:32<01:37,  1.20s/it, loss=0.00456, lr=0.000324]a photo of the cool <0>\n",
            "Steps:  84% 420/500 [08:33<01:35,  1.19s/it, loss=0.01, lr=0.00032]    the photo of a <0>\n",
            "tensor(0.0086, device='cuda:0')\n",
            "tensor([[0.4139]], device='cuda:0')\n",
            "Current Norm : tensor([0.4134], device='cuda:0')\n",
            "Steps:  84% 421/500 [08:34<01:33,  1.19s/it, loss=0.0132, lr=0.000316]a photo of my <0>\n",
            "Steps:  84% 422/500 [08:35<01:32,  1.19s/it, loss=0.00114, lr=0.000312]a photo of one <0>\n",
            "Steps:  85% 423/500 [08:36<01:31,  1.18s/it, loss=0.00683, lr=0.000308]a rendition of a <0>\n",
            "Steps:  85% 424/500 [08:37<01:29,  1.18s/it, loss=0.0394, lr=0.000304] a photo of the large <0>\n",
            "tensor(0.0098, device='cuda:0')\n",
            "tensor([[0.4137]], device='cuda:0')\n",
            "Current Norm : tensor([0.4133], device='cuda:0')\n",
            "Steps:  85% 425/500 [08:39<01:29,  1.19s/it, loss=0.0119, lr=0.0003]  a photo of a nice <0>\n",
            "Steps:  85% 426/500 [08:40<01:29,  1.21s/it, loss=0.0394, lr=0.000296]a rendition of the <0>\n",
            "Steps:  85% 427/500 [08:41<01:29,  1.23s/it, loss=0.00496, lr=0.000292]a cropped photo of the <0>\n",
            "Steps:  86% 428/500 [08:42<01:29,  1.24s/it, loss=0.0571, lr=0.000288] a cropped photo of a <0>\n",
            "tensor(0.0096, device='cuda:0')\n",
            "tensor([[0.4135]], device='cuda:0')\n",
            "Current Norm : tensor([0.4132], device='cuda:0')\n",
            "Steps:  86% 429/500 [08:44<01:28,  1.25s/it, loss=0.000953, lr=0.000284]a photo of a dirty <0>\n",
            "Steps:  86% 430/500 [08:45<01:27,  1.25s/it, loss=0.0268, lr=0.00028]   a photo of the clean <0>\n",
            "Steps:  86% 431/500 [08:46<01:26,  1.25s/it, loss=0.00343, lr=0.000276]a photo of one <0>\n",
            "Steps:  86% 432/500 [08:47<01:24,  1.25s/it, loss=0.0399, lr=0.000272] a photo of the small <0>\n",
            "tensor(0.0154, device='cuda:0')\n",
            "tensor([[0.4134]], device='cuda:0')\n",
            "Current Norm : tensor([0.4131], device='cuda:0')\n",
            "Steps:  87% 433/500 [08:49<01:24,  1.26s/it, loss=0.0414, lr=0.000268]a photo of a clean <0>\n",
            "Steps:  87% 434/500 [08:50<01:23,  1.26s/it, loss=0.000503, lr=0.000264]a photo of a clean <0>\n",
            "Steps:  87% 435/500 [08:51<01:21,  1.26s/it, loss=0.0024, lr=0.00026]   a photo of the large <0>\n",
            "Steps:  87% 436/500 [08:52<01:18,  1.23s/it, loss=0.00288, lr=0.000256]a photo of a dirty <0>\n",
            "tensor(0.0128, device='cuda:0')\n",
            "tensor([[0.4133]], device='cuda:0')\n",
            "Current Norm : tensor([0.4130], device='cuda:0')\n",
            "Steps:  87% 437/500 [08:54<01:16,  1.22s/it, loss=0.00031, lr=0.000252]the photo of a <0>\n",
            "Steps:  88% 438/500 [08:55<01:14,  1.20s/it, loss=0.0427, lr=0.000248] a photo of the cool <0>\n",
            "Steps:  88% 439/500 [08:56<01:12,  1.19s/it, loss=0.00714, lr=0.000244]a photo of the <0>\n",
            "Steps:  88% 440/500 [08:57<01:11,  1.19s/it, loss=0.00517, lr=0.00024] a rendition of a <0>\n",
            "tensor(0.0176, device='cuda:0')\n",
            "tensor([[0.4132]], device='cuda:0')\n",
            "Current Norm : tensor([0.4129], device='cuda:0')\n",
            "Steps:  88% 441/500 [08:58<01:09,  1.19s/it, loss=0.0034, lr=0.000236]a bright photo of the <0>\n",
            "Steps:  88% 442/500 [08:59<01:08,  1.18s/it, loss=0.000716, lr=0.000232]a photo of the large <0>\n",
            "Steps:  89% 443/500 [09:01<01:07,  1.18s/it, loss=0.0188, lr=0.000228]  a bright photo of the <0>\n",
            "Steps:  89% 444/500 [09:02<01:07,  1.20s/it, loss=0.0426, lr=0.000224]a rendering of a <0>\n",
            "tensor(0.0147, device='cuda:0')\n",
            "tensor([[0.4131]], device='cuda:0')\n",
            "Current Norm : tensor([0.4128], device='cuda:0')\n",
            "Steps:  89% 445/500 [09:03<01:07,  1.23s/it, loss=0.00214, lr=0.00022]a bright photo of the <0>\n",
            "Steps:  89% 446/500 [09:04<01:06,  1.23s/it, loss=0.00552, lr=0.000216]the photo of a <0>\n",
            "Steps:  89% 447/500 [09:06<01:05,  1.24s/it, loss=0.0766, lr=0.000212] a photo of the nice <0>\n",
            "Steps:  90% 448/500 [09:07<01:04,  1.25s/it, loss=0.0393, lr=0.000208]a bright photo of the <0>\n",
            "tensor(0.0130, device='cuda:0')\n",
            "tensor([[0.4130]], device='cuda:0')\n",
            "Current Norm : tensor([0.4127], device='cuda:0')\n",
            "Steps:  90% 449/500 [09:08<01:03,  1.25s/it, loss=0.0293, lr=0.000204]a photo of a nice <0>\n",
            "Steps:  90% 450/500 [09:09<01:02,  1.25s/it, loss=0.0013, lr=0.0002]  a photo of one <0>\n",
            "Steps:  90% 451/500 [09:11<01:01,  1.25s/it, loss=0.0238, lr=0.000196]a photo of the clean <0>\n",
            "Steps:  90% 452/500 [09:12<01:00,  1.25s/it, loss=0.00228, lr=0.000192]a photo of a cool <0>\n",
            "tensor(0.0154, device='cuda:0')\n",
            "tensor([[0.4129]], device='cuda:0')\n",
            "Current Norm : tensor([0.4126], device='cuda:0')\n",
            "Steps:  91% 453/500 [09:13<00:59,  1.26s/it, loss=0.00268, lr=0.000188]a close-up photo of a <0>\n",
            "Steps:  91% 454/500 [09:14<00:56,  1.23s/it, loss=0.00033, lr=0.000184]a dark photo of the <0>\n",
            "Steps:  91% 455/500 [09:16<00:54,  1.21s/it, loss=0.0361, lr=0.00018]  a good photo of the <0>\n",
            "Steps:  91% 456/500 [09:17<00:52,  1.20s/it, loss=0.00184, lr=0.000176]the photo of a <0>\n",
            "tensor(0.0062, device='cuda:0')\n",
            "tensor([[0.4128]], device='cuda:0')\n",
            "Current Norm : tensor([0.4126], device='cuda:0')\n",
            "Steps:  91% 457/500 [09:18<00:51,  1.19s/it, loss=0.000464, lr=0.000172]the photo of a <0>\n",
            "Steps:  92% 458/500 [09:19<00:49,  1.18s/it, loss=0.00345, lr=0.000168] a photo of the small <0>\n",
            "Steps:  92% 459/500 [09:20<00:48,  1.18s/it, loss=0.00151, lr=0.000164]a close-up photo of a <0>\n",
            "Steps:  92% 460/500 [09:21<00:47,  1.18s/it, loss=0.000649, lr=0.00016]a photo of a cool <0>\n",
            "tensor(0.0114, device='cuda:0')\n",
            "tensor([[0.4127]], device='cuda:0')\n",
            "Current Norm : tensor([0.4125], device='cuda:0')\n",
            "Steps:  92% 461/500 [09:23<00:46,  1.18s/it, loss=0.011, lr=0.000156]  a dark photo of the <0>\n",
            "Steps:  92% 462/500 [09:24<00:44,  1.18s/it, loss=0.0139, lr=0.000152]a photo of a <0>\n",
            "Steps:  93% 463/500 [09:25<00:44,  1.21s/it, loss=0.0016, lr=0.000148]a photo of the small <0>\n",
            "Steps:  93% 464/500 [09:26<00:44,  1.22s/it, loss=0.0228, lr=0.000144]a close-up photo of the <0>\n",
            "tensor(0.0115, device='cuda:0')\n",
            "tensor([[0.4126]], device='cuda:0')\n",
            "Current Norm : tensor([0.4124], device='cuda:0')\n",
            "Steps:  93% 465/500 [09:28<00:43,  1.24s/it, loss=0.01, lr=0.00014]   a photo of the cool <0>\n",
            "Steps:  93% 466/500 [09:29<00:42,  1.25s/it, loss=0.00928, lr=0.000136]a cropped photo of the <0>\n",
            "Steps:  93% 467/500 [09:30<00:41,  1.25s/it, loss=0.0203, lr=0.000132] the photo of a <0>\n",
            "Steps:  94% 468/500 [09:31<00:39,  1.25s/it, loss=0.0178, lr=0.000128]a rendition of the <0>\n",
            "tensor(0.0153, device='cuda:0')\n",
            "tensor([[0.4125]], device='cuda:0')\n",
            "Current Norm : tensor([0.4123], device='cuda:0')\n",
            "Steps:  94% 469/500 [09:33<00:38,  1.26s/it, loss=0.0104, lr=0.000124]a photo of the <0>\n",
            "Steps:  94% 470/500 [09:34<00:37,  1.26s/it, loss=0.0388, lr=0.00012] a photo of the clean <0>\n",
            "Steps:  94% 471/500 [09:35<00:36,  1.26s/it, loss=0.00418, lr=0.000116]a rendering of a <0>\n",
            "Steps:  94% 472/500 [09:36<00:34,  1.25s/it, loss=0.00708, lr=0.000112]a photo of a <0>\n",
            "tensor(0.0167, device='cuda:0')\n",
            "tensor([[0.4124]], device='cuda:0')\n",
            "Current Norm : tensor([0.4123], device='cuda:0')\n",
            "Steps:  95% 473/500 [09:38<00:33,  1.23s/it, loss=0.00973, lr=0.000108]a photo of a cool <0>\n",
            "Steps:  95% 474/500 [09:39<00:31,  1.21s/it, loss=0.00218, lr=0.000104]a good photo of a <0>\n",
            "Steps:  95% 475/500 [09:40<00:29,  1.20s/it, loss=0.00216, lr=0.0001]  a photo of the clean <0>\n",
            "Steps:  95% 476/500 [09:41<00:28,  1.19s/it, loss=0.00112, lr=9.6e-5]a rendition of a <0>\n",
            "tensor(0.0063, device='cuda:0')\n",
            "tensor([[0.4123]], device='cuda:0')\n",
            "Current Norm : tensor([0.4122], device='cuda:0')\n",
            "Steps:  95% 477/500 [09:42<00:27,  1.19s/it, loss=0.00198, lr=9.2e-5]a rendition of the <0>\n",
            "Steps:  96% 478/500 [09:43<00:25,  1.18s/it, loss=0.00142, lr=8.8e-5]a photo of a nice <0>\n",
            "Steps:  96% 479/500 [09:45<00:24,  1.17s/it, loss=0.0202, lr=8.4e-5] a photo of a small <0>\n",
            "Steps:  96% 480/500 [09:46<00:23,  1.17s/it, loss=0.0185, lr=8e-5]  a photo of the weird <0>\n",
            "tensor(0.0112, device='cuda:0')\n",
            "tensor([[0.4123]], device='cuda:0')\n",
            "Current Norm : tensor([0.4122], device='cuda:0')\n",
            "Steps:  96% 481/500 [09:47<00:22,  1.20s/it, loss=0.0244, lr=7.6e-5]a photo of a dirty <0>\n",
            "Steps:  96% 482/500 [09:48<00:22,  1.23s/it, loss=0.0482, lr=7.2e-5]a photo of the clean <0>\n",
            "Steps:  97% 483/500 [09:50<00:21,  1.24s/it, loss=0.0287, lr=6.8e-5]a photo of a <0>\n",
            "Steps:  97% 484/500 [09:51<00:19,  1.25s/it, loss=0.011, lr=6.4e-5] a close-up photo of a <0>\n",
            "tensor(0.0152, device='cuda:0')\n",
            "tensor([[0.4122]], device='cuda:0')\n",
            "Current Norm : tensor([0.4121], device='cuda:0')\n",
            "Steps:  97% 485/500 [09:52<00:18,  1.26s/it, loss=0.00499, lr=6e-5]a photo of a nice <0>\n",
            "Steps:  97% 486/500 [09:53<00:17,  1.25s/it, loss=0.0475, lr=5.6e-5]a close-up photo of the <0>\n",
            "Steps:  97% 487/500 [09:55<00:16,  1.26s/it, loss=0.00667, lr=5.2e-5]a photo of the nice <0>\n",
            "Steps:  98% 488/500 [09:56<00:15,  1.26s/it, loss=0.0108, lr=4.8e-5] a photo of my <0>\n",
            "tensor(0.0182, device='cuda:0')\n",
            "tensor([[0.4122]], device='cuda:0')\n",
            "Current Norm : tensor([0.4121], device='cuda:0')\n",
            "Steps:  98% 489/500 [09:57<00:13,  1.26s/it, loss=0.00149, lr=4.4e-5]a photo of a <0>\n",
            "Steps:  98% 490/500 [09:58<00:12,  1.26s/it, loss=0.00892, lr=4e-5]  a photo of a clean <0>\n",
            "Steps:  98% 491/500 [10:00<00:11,  1.23s/it, loss=0.003, lr=3.6e-5]a photo of the large <0>\n",
            "Steps:  98% 492/500 [10:01<00:09,  1.21s/it, loss=0.0174, lr=3.2e-5]a photo of the weird <0>\n",
            "tensor(0.0108, device='cuda:0')\n",
            "tensor([[0.4121]], device='cuda:0')\n",
            "Current Norm : tensor([0.4121], device='cuda:0')\n",
            "Steps:  99% 493/500 [10:02<00:08,  1.20s/it, loss=0.093, lr=2.8e-5] a photo of the nice <0>\n",
            "Steps:  99% 494/500 [10:03<00:07,  1.19s/it, loss=0.0221, lr=2.4e-5]a rendition of a <0>\n",
            "Steps:  99% 495/500 [10:04<00:05,  1.18s/it, loss=0.00833, lr=2e-5] a close-up photo of a <0>\n",
            "Steps:  99% 496/500 [10:05<00:04,  1.18s/it, loss=0.0892, lr=1.6e-5]a good photo of a <0>\n",
            "tensor(0.0098, device='cuda:0')\n",
            "tensor([[0.4121]], device='cuda:0')\n",
            "Current Norm : tensor([0.4121], device='cuda:0')\n",
            "Steps:  99% 497/500 [10:07<00:03,  1.18s/it, loss=0.000435, lr=1.2e-5]a rendition of a <0>\n",
            "Steps: 100% 498/500 [10:08<00:02,  1.18s/it, loss=0.0444, lr=8e-6]    a photo of a clean <0>\n",
            "Steps: 100% 499/500 [10:09<00:01,  1.18s/it, loss=0.000917, lr=4e-6]a close-up photo of the <0>\n",
            "Steps: 100% 500/500 [10:10<00:00,  1.20s/it, loss=0.00671, lr=0]    Current Learned Embeddings for <0>:, id 49408  tensor([-0.0133, -0.0012,  0.0127, -0.0132], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Saving weights to ./results/cat_0000/lora/step_inv_500.safetensors\n",
            "Steps: 100% 500/500 [10:10<00:00,  1.22s/it, loss=0.00671, lr=0]\n",
            "PTI : has 288 lora\n",
            "PTI : Before training:\n",
            "Steps:   0% 0/500 [00:00<?, ?it/s]a rendition of a <0>\n",
            "/usr/local/envs/3DFuse/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning:\n",
            "\n",
            "None of the inputs have requires_grad=True. Gradients will be None\n",
            "\n",
            "Steps:   0% 1/500 [00:01<13:54,  1.67s/it, loss=0.0601, lr=4e-6]a photo of a nice <0>\n",
            "Steps:   0% 2/500 [00:02<11:52,  1.43s/it, loss=0.157, lr=8e-6] a photo of a cool <0>\n",
            "Steps:   1% 3/500 [00:04<11:12,  1.35s/it, loss=0.154, lr=1.2e-5]a photo of the weird <0>\n",
            "Steps:   1% 4/500 [00:05<10:52,  1.32s/it, loss=0.0248, lr=1.6e-5]a photo of a small <0>\n",
            "Steps:   1% 5/500 [00:06<10:41,  1.30s/it, loss=0.0338, lr=2e-5]  a good photo of the <0>\n",
            "Steps:   1% 6/500 [00:07<10:27,  1.27s/it, loss=0.0186, lr=2.4e-5]a photo of my <0>\n",
            "Steps:   1% 7/500 [00:09<09:59,  1.22s/it, loss=0.0127, lr=2.8e-5]a photo of my <0>\n",
            "Steps:   2% 8/500 [00:10<09:41,  1.18s/it, loss=0.0572, lr=3.2e-5]a close-up photo of the <0>\n",
            "Steps:   2% 9/500 [00:11<09:29,  1.16s/it, loss=0.0141, lr=3.6e-5]a photo of the clean <0>\n",
            "Steps:   2% 10/500 [00:12<09:19,  1.14s/it, loss=0.0298, lr=4e-5]  a photo of the large <0>\n",
            "Steps:   2% 11/500 [00:13<09:13,  1.13s/it, loss=0.12, lr=4.4e-5]a good photo of the <0>\n",
            "Steps:   2% 12/500 [00:14<09:09,  1.13s/it, loss=0.0769, lr=4.8e-5]a photo of one <0>\n",
            "Steps:   3% 13/500 [00:15<09:05,  1.12s/it, loss=0.0105, lr=5.2e-5]a photo of the clean <0>\n",
            "Steps:   3% 14/500 [00:16<09:02,  1.12s/it, loss=0.0146, lr=5.6e-5]a photo of the nice <0>\n",
            "Steps:   3% 15/500 [00:17<09:05,  1.12s/it, loss=0.0264, lr=6e-5]  a photo of a small <0>\n",
            "Steps:   3% 16/500 [00:19<09:21,  1.16s/it, loss=0.106, lr=6.4e-5]a close-up photo of a <0>\n",
            "Steps:   3% 17/500 [00:20<09:34,  1.19s/it, loss=0.0491, lr=6.8e-5]the photo of a <0>\n",
            "Steps:   4% 18/500 [00:21<09:45,  1.22s/it, loss=0.0212, lr=7.2e-5]a photo of the <0>\n",
            "Steps:   4% 19/500 [00:22<09:50,  1.23s/it, loss=0.0204, lr=7.6e-5]a good photo of a <0>\n",
            "Steps:   4% 20/500 [00:24<09:55,  1.24s/it, loss=0.0281, lr=8e-5]  a photo of a nice <0>\n",
            "Steps:   4% 21/500 [00:25<09:59,  1.25s/it, loss=0.0549, lr=8.4e-5]a close-up photo of a <0>\n",
            "Steps:   4% 22/500 [00:26<09:58,  1.25s/it, loss=0.1, lr=8.8e-5]   a good photo of the <0>\n",
            "Steps:   5% 23/500 [00:28<09:56,  1.25s/it, loss=0.0641, lr=9.2e-5]a photo of a clean <0>\n",
            "Steps:   5% 24/500 [00:29<09:53,  1.25s/it, loss=0.0175, lr=9.6e-5]a photo of a cool <0>\n",
            "Steps:   5% 25/500 [00:30<09:48,  1.24s/it, loss=0.0474, lr=0.0001]a bright photo of the <0>\n",
            "Steps:   5% 26/500 [00:31<09:28,  1.20s/it, loss=0.0524, lr=0.000104]a photo of the clean <0>\n",
            "Steps:   5% 27/500 [00:32<09:15,  1.18s/it, loss=0.218, lr=0.000108] a photo of the clean <0>\n",
            "Steps:   6% 28/500 [00:33<09:06,  1.16s/it, loss=0.171, lr=0.000112]a close-up photo of a <0>\n",
            "Steps:   6% 29/500 [00:34<09:00,  1.15s/it, loss=0.0558, lr=0.000116]a close-up photo of the <0>\n",
            "Steps:   6% 30/500 [00:36<08:53,  1.14s/it, loss=0.0315, lr=0.00012] a cropped photo of the <0>\n",
            "Steps:   6% 31/500 [00:37<08:49,  1.13s/it, loss=0.0167, lr=0.000124]a photo of the <0>\n",
            "Steps:   6% 32/500 [00:38<08:45,  1.12s/it, loss=0.0406, lr=0.000128]a rendering of a <0>\n",
            "Steps:   7% 33/500 [00:39<08:42,  1.12s/it, loss=0.114, lr=0.000132] a photo of the clean <0>\n",
            "Steps:   7% 34/500 [00:40<08:46,  1.13s/it, loss=0.0259, lr=0.000136]a bright photo of the <0>\n",
            "Steps:   7% 35/500 [00:41<09:01,  1.16s/it, loss=0.0312, lr=0.00014] a photo of one <0>\n",
            "Steps:   7% 36/500 [00:43<09:13,  1.19s/it, loss=0.0122, lr=0.000144]a photo of my <0>\n",
            "Steps:   7% 37/500 [00:44<09:23,  1.22s/it, loss=0.0408, lr=0.000148]a photo of the large <0>\n",
            "Steps:   8% 38/500 [00:45<09:26,  1.23s/it, loss=0.164, lr=0.000152] a rendition of the <0>\n",
            "Steps:   8% 39/500 [00:46<09:27,  1.23s/it, loss=0.0365, lr=0.000156]a photo of a nice <0>\n",
            "Steps:   8% 40/500 [00:48<09:29,  1.24s/it, loss=0.0134, lr=0.00016] a dark photo of the <0>\n",
            "Steps:   8% 41/500 [00:49<09:33,  1.25s/it, loss=0.0459, lr=0.000164]the photo of a <0>\n",
            "Steps:   8% 42/500 [00:50<09:31,  1.25s/it, loss=0.013, lr=0.000168] a photo of a <0>\n",
            "Steps:   9% 43/500 [00:51<09:28,  1.24s/it, loss=0.00755, lr=0.000172]a photo of the large <0>\n",
            "Steps:   9% 44/500 [00:53<09:22,  1.23s/it, loss=0.283, lr=0.000176]  a photo of the large <0>\n",
            "Steps:   9% 45/500 [00:54<09:03,  1.19s/it, loss=0.014, lr=0.00018] a photo of the small <0>\n",
            "Steps:   9% 46/500 [00:55<08:51,  1.17s/it, loss=0.0177, lr=0.000184]a rendering of a <0>\n",
            "Steps:   9% 47/500 [00:56<08:41,  1.15s/it, loss=0.0153, lr=0.000188]a photo of a <0>\n",
            "Steps:  10% 48/500 [00:57<08:33,  1.14s/it, loss=0.0535, lr=0.000192]a photo of the weird <0>\n",
            "Steps:  10% 49/500 [00:58<08:28,  1.13s/it, loss=0.00981, lr=0.000196]a photo of one <0>\n",
            "Steps:  10% 50/500 [00:59<08:24,  1.12s/it, loss=0.0222, lr=0.0002]   a cropped photo of a <0>\n",
            "Steps:  10% 51/500 [01:00<08:22,  1.12s/it, loss=0.0119, lr=0.000204]a bright photo of the <0>\n",
            "Steps:  10% 52/500 [01:01<08:19,  1.11s/it, loss=0.144, lr=0.000208] a rendition of a <0>\n",
            "Steps:  11% 53/500 [01:03<08:22,  1.12s/it, loss=0.0131, lr=0.000212]a photo of the large <0>\n",
            "Steps:  11% 54/500 [01:04<08:34,  1.15s/it, loss=0.0599, lr=0.000216]the photo of a <0>\n",
            "Steps:  11% 55/500 [01:05<08:46,  1.18s/it, loss=0.101, lr=0.00022]  a photo of the weird <0>\n",
            "Steps:  11% 56/500 [01:06<08:55,  1.21s/it, loss=0.00621, lr=0.000224]a photo of a dirty <0>\n",
            "Steps:  11% 57/500 [01:08<08:59,  1.22s/it, loss=0.0307, lr=0.000228] a rendition of a <0>\n",
            "Steps:  12% 58/500 [01:09<09:04,  1.23s/it, loss=0.0222, lr=0.000232]a photo of a small <0>\n",
            "Steps:  12% 59/500 [01:10<09:09,  1.25s/it, loss=0.0361, lr=0.000236]a photo of a dirty <0>\n",
            "Steps:  12% 60/500 [01:11<09:08,  1.25s/it, loss=0.0223, lr=0.00024] a photo of the <0>\n",
            "Steps:  12% 61/500 [01:13<09:07,  1.25s/it, loss=0.236, lr=0.000244]a photo of a small <0>\n",
            "Steps:  12% 62/500 [01:14<09:10,  1.26s/it, loss=0.0107, lr=0.000248]a good photo of a <0>\n",
            "Steps:  13% 63/500 [01:15<09:03,  1.24s/it, loss=0.0122, lr=0.000252]a cropped photo of a <0>\n",
            "Steps:  13% 64/500 [01:16<08:45,  1.21s/it, loss=0.0455, lr=0.000256]a photo of a cool <0>\n",
            "Steps:  13% 65/500 [01:17<08:33,  1.18s/it, loss=0.00847, lr=0.00026]a photo of a clean <0>\n",
            "Steps:  13% 66/500 [01:18<08:23,  1.16s/it, loss=0.213, lr=0.000264] a cropped photo of the <0>\n",
            "Steps:  13% 67/500 [01:20<08:15,  1.15s/it, loss=0.164, lr=0.000268]a photo of a <0>\n",
            "Steps:  14% 68/500 [01:21<08:10,  1.14s/it, loss=0.0119, lr=0.000272]a bright photo of the <0>\n",
            "Steps:  14% 69/500 [01:22<08:06,  1.13s/it, loss=0.201, lr=0.000276] a photo of a small <0>\n",
            "Steps:  14% 70/500 [01:23<08:04,  1.13s/it, loss=0.0212, lr=0.00028]a dark photo of the <0>\n",
            "Steps:  14% 71/500 [01:24<08:01,  1.12s/it, loss=0.0346, lr=0.000284]a photo of a small <0>\n",
            "Steps:  14% 72/500 [01:25<08:02,  1.13s/it, loss=0.0318, lr=0.000288]a photo of a <0>\n",
            "Steps:  15% 73/500 [01:26<08:15,  1.16s/it, loss=0.0293, lr=0.000292]a dark photo of the <0>\n",
            "Steps:  15% 74/500 [01:28<08:27,  1.19s/it, loss=0.0102, lr=0.000296]a photo of the large <0>\n",
            "Steps:  15% 75/500 [01:29<08:34,  1.21s/it, loss=0.00847, lr=0.0003] a photo of the cool <0>\n",
            "Steps:  15% 76/500 [01:30<08:38,  1.22s/it, loss=0.0335, lr=0.000304]a good photo of the <0>\n",
            "Steps:  15% 77/500 [01:31<08:41,  1.23s/it, loss=0.0168, lr=0.000308]a close-up photo of a <0>\n",
            "Steps:  16% 78/500 [01:33<08:42,  1.24s/it, loss=0.00731, lr=0.000312]a photo of a small <0>\n",
            "Steps:  16% 79/500 [01:34<08:44,  1.25s/it, loss=0.073, lr=0.000316]  a photo of the clean <0>\n",
            "Steps:  16% 80/500 [01:35<08:47,  1.26s/it, loss=0.0743, lr=0.00032]a rendering of a <0>\n",
            "Steps:  16% 81/500 [01:36<08:47,  1.26s/it, loss=0.0305, lr=0.000324]a dark photo of the <0>\n",
            "Steps:  16% 82/500 [01:38<08:42,  1.25s/it, loss=0.125, lr=0.000328] a bright photo of the <0>\n",
            "Steps:  17% 83/500 [01:39<08:24,  1.21s/it, loss=0.00981, lr=0.000332]a photo of a small <0>\n",
            "Steps:  17% 84/500 [01:40<08:10,  1.18s/it, loss=0.00637, lr=0.000336]a photo of the <0>\n",
            "Steps:  17% 85/500 [01:41<08:00,  1.16s/it, loss=0.0891, lr=0.00034]  a photo of the cool <0>\n",
            "Steps:  17% 86/500 [01:42<07:53,  1.14s/it, loss=0.00743, lr=0.000344]a good photo of the <0>\n",
            "Steps:  17% 87/500 [01:43<07:46,  1.13s/it, loss=0.061, lr=0.000348]  a rendering of a <0>\n",
            "Steps:  18% 88/500 [01:44<07:43,  1.12s/it, loss=0.0125, lr=0.000352]a photo of a nice <0>\n",
            "Steps:  18% 89/500 [01:45<07:40,  1.12s/it, loss=0.0125, lr=0.000356]a photo of a clean <0>\n",
            "Steps:  18% 90/500 [01:47<07:36,  1.11s/it, loss=0.00714, lr=0.00036]a close-up photo of a <0>\n",
            "Steps:  18% 91/500 [01:48<07:38,  1.12s/it, loss=0.0308, lr=0.000364]a close-up photo of the <0>\n",
            "Steps:  18% 92/500 [01:49<07:51,  1.16s/it, loss=0.24, lr=0.000368]  a dark photo of the <0>\n",
            "Steps:  19% 93/500 [01:50<08:04,  1.19s/it, loss=0.0123, lr=0.000372]a photo of one <0>\n",
            "Steps:  19% 94/500 [01:51<08:13,  1.21s/it, loss=0.0677, lr=0.000376]a photo of my <0>\n",
            "Steps:  19% 95/500 [01:53<08:19,  1.23s/it, loss=0.221, lr=0.00038]  a photo of the clean <0>\n",
            "Steps:  19% 96/500 [01:54<08:22,  1.24s/it, loss=0.0953, lr=0.000384]a good photo of the <0>\n",
            "Steps:  19% 97/500 [01:55<08:25,  1.25s/it, loss=0.204, lr=0.000388] a photo of the nice <0>\n",
            "Steps:  20% 98/500 [01:57<08:26,  1.26s/it, loss=0.0849, lr=0.000392]a photo of the <0>\n",
            "Steps:  20% 99/500 [01:58<08:28,  1.27s/it, loss=0.0172, lr=0.000396]a photo of the large <0>\n",
            "Steps:  20% 100/500 [01:59<08:26,  1.27s/it, loss=0.0257, lr=0.0004]  a photo of a clean <0>\n",
            "Steps:  20% 101/500 [02:00<08:18,  1.25s/it, loss=0.0111, lr=0.000399]a rendition of the <0>\n",
            "Steps:  20% 102/500 [02:01<07:59,  1.21s/it, loss=0.0826, lr=0.000398]a photo of the small <0>\n",
            "Steps:  21% 103/500 [02:03<07:45,  1.17s/it, loss=0.00694, lr=0.000397]a photo of the clean <0>\n",
            "Steps:  21% 104/500 [02:04<07:36,  1.15s/it, loss=0.129, lr=0.000396]  a photo of the clean <0>\n",
            "Steps:  21% 105/500 [02:05<07:29,  1.14s/it, loss=0.102, lr=0.000395]a photo of the clean <0>\n",
            "Steps:  21% 106/500 [02:06<07:27,  1.13s/it, loss=0.0517, lr=0.000394]a bright photo of the <0>\n",
            "Steps:  21% 107/500 [02:07<07:23,  1.13s/it, loss=0.129, lr=0.000393] a photo of the cool <0>\n",
            "Steps:  22% 108/500 [02:08<07:20,  1.12s/it, loss=0.0388, lr=0.000392]a photo of the nice <0>\n",
            "Steps:  22% 109/500 [02:09<07:17,  1.12s/it, loss=0.0101, lr=0.000391]a photo of the nice <0>\n",
            "Steps:  22% 110/500 [02:10<07:22,  1.13s/it, loss=0.0206, lr=0.00039] a photo of the nice <0>\n",
            "Steps:  22% 111/500 [02:12<07:34,  1.17s/it, loss=0.0222, lr=0.000389]a photo of a <0>\n",
            "Steps:  22% 112/500 [02:13<07:43,  1.20s/it, loss=0.051, lr=0.000388] a rendering of a <0>\n",
            "Steps:  23% 113/500 [02:14<07:50,  1.22s/it, loss=0.0477, lr=0.000387]a photo of a dirty <0>\n",
            "Steps:  23% 114/500 [02:15<07:53,  1.23s/it, loss=0.0104, lr=0.000386]a cropped photo of a <0>\n",
            "Steps:  23% 115/500 [02:17<07:59,  1.25s/it, loss=0.0158, lr=0.000385]a bright photo of the <0>\n",
            "Steps:  23% 116/500 [02:18<08:00,  1.25s/it, loss=0.0412, lr=0.000384]a photo of a clean <0>\n",
            "Steps:  23% 117/500 [02:19<08:01,  1.26s/it, loss=0.0189, lr=0.000383]a photo of a nice <0>\n",
            "Steps:  24% 118/500 [02:20<08:02,  1.26s/it, loss=0.00729, lr=0.000382]a photo of the nice <0>\n",
            "Steps:  24% 119/500 [02:22<08:03,  1.27s/it, loss=0.0326, lr=0.000381] a photo of a dirty <0>\n",
            "Steps:  24% 120/500 [02:23<07:53,  1.25s/it, loss=0.0104, lr=0.00038] a close-up photo of a <0>\n",
            "Steps:  24% 121/500 [02:24<07:41,  1.22s/it, loss=0.0322, lr=0.000379]a bright photo of the <0>\n",
            "Steps:  24% 122/500 [02:25<07:29,  1.19s/it, loss=0.0602, lr=0.000378]a close-up photo of a <0>\n",
            "Steps:  25% 123/500 [02:26<07:19,  1.16s/it, loss=0.0338, lr=0.000377]a photo of my <0>\n",
            "Steps:  25% 124/500 [02:27<07:11,  1.15s/it, loss=0.0125, lr=0.000376]a rendition of a <0>\n",
            "Steps:  25% 125/500 [02:29<07:07,  1.14s/it, loss=0.0131, lr=0.000375]a photo of a nice <0>\n",
            "Steps:  25% 126/500 [02:30<07:02,  1.13s/it, loss=0.0308, lr=0.000374]a cropped photo of the <0>\n",
            "Steps:  25% 127/500 [02:31<06:59,  1.12s/it, loss=0.0259, lr=0.000373]a photo of a small <0>\n",
            "Steps:  26% 128/500 [02:32<06:57,  1.12s/it, loss=0.00752, lr=0.000372]the photo of a <0>\n",
            "Steps:  26% 129/500 [02:33<07:00,  1.13s/it, loss=0.308, lr=0.000371]  a photo of the weird <0>\n",
            "Steps:  26% 130/500 [02:34<07:12,  1.17s/it, loss=0.0153, lr=0.00037]a rendition of a <0>\n",
            "Steps:  26% 131/500 [02:36<07:25,  1.21s/it, loss=0.0114, lr=0.000369]a photo of the large <0>\n",
            "Steps:  26% 132/500 [02:37<07:30,  1.22s/it, loss=0.0453, lr=0.000368]a photo of my <0>\n",
            "Steps:  27% 133/500 [02:38<07:35,  1.24s/it, loss=0.00594, lr=0.000367]a photo of a <0>\n",
            "Steps:  27% 134/500 [02:39<07:38,  1.25s/it, loss=0.0263, lr=0.000366] a dark photo of the <0>\n",
            "Steps:  27% 135/500 [02:41<07:40,  1.26s/it, loss=0.0659, lr=0.000365]a photo of the small <0>\n",
            "Steps:  27% 136/500 [02:42<07:38,  1.26s/it, loss=0.034, lr=0.000364] a bright photo of the <0>\n",
            "Steps:  27% 137/500 [02:43<07:40,  1.27s/it, loss=0.0284, lr=0.000363]a photo of the weird <0>\n",
            "Steps:  28% 138/500 [02:45<07:38,  1.27s/it, loss=0.0819, lr=0.000362]a rendition of the <0>\n",
            "Steps:  28% 139/500 [02:46<07:27,  1.24s/it, loss=0.0169, lr=0.000361]a photo of one <0>\n",
            "Steps:  28% 140/500 [02:47<07:12,  1.20s/it, loss=0.139, lr=0.00036]  a photo of a cool <0>\n",
            "Steps:  28% 141/500 [02:48<07:00,  1.17s/it, loss=0.0316, lr=0.000359]a photo of the cool <0>\n",
            "Steps:  28% 142/500 [02:49<06:52,  1.15s/it, loss=0.0443, lr=0.000358]a photo of my <0>\n",
            "Steps:  29% 143/500 [02:50<06:46,  1.14s/it, loss=0.0501, lr=0.000357]a photo of a clean <0>\n",
            "Steps:  29% 144/500 [02:51<06:42,  1.13s/it, loss=0.0484, lr=0.000356]the photo of a <0>\n",
            "Steps:  29% 145/500 [02:52<06:39,  1.12s/it, loss=0.0201, lr=0.000355]a rendition of the <0>\n",
            "Steps:  29% 146/500 [02:53<06:37,  1.12s/it, loss=0.0122, lr=0.000354]a close-up photo of a <0>\n",
            "Steps:  29% 147/500 [02:55<06:35,  1.12s/it, loss=0.0094, lr=0.000353]a rendition of the <0>\n",
            "Steps:  30% 148/500 [02:56<06:36,  1.13s/it, loss=0.0188, lr=0.000352]a photo of the nice <0>\n",
            "Steps:  30% 149/500 [02:57<06:47,  1.16s/it, loss=0.00533, lr=0.000351]a rendition of the <0>\n",
            "Steps:  30% 150/500 [02:58<06:57,  1.19s/it, loss=0.117, lr=0.00035]   a photo of the small <0>\n",
            "Steps:  30% 151/500 [02:59<07:04,  1.22s/it, loss=0.0145, lr=0.000349]the photo of a <0>\n",
            "Steps:  30% 152/500 [03:01<07:08,  1.23s/it, loss=0.0598, lr=0.000348]a close-up photo of a <0>\n",
            "Steps:  31% 153/500 [03:02<07:10,  1.24s/it, loss=0.0309, lr=0.000347]a good photo of the <0>\n",
            "Steps:  31% 154/500 [03:03<07:11,  1.25s/it, loss=0.0117, lr=0.000346]the photo of a <0>\n",
            "Steps:  31% 155/500 [03:05<07:10,  1.25s/it, loss=0.163, lr=0.000345] a photo of one <0>\n",
            "Steps:  31% 156/500 [03:06<07:12,  1.26s/it, loss=0.0745, lr=0.000344]a photo of the small <0>\n",
            "Steps:  31% 157/500 [03:07<07:10,  1.26s/it, loss=0.00899, lr=0.000343]a dark photo of the <0>\n",
            "Steps:  32% 158/500 [03:08<07:00,  1.23s/it, loss=0.0528, lr=0.000342] a dark photo of the <0>\n",
            "Steps:  32% 159/500 [03:09<06:46,  1.19s/it, loss=0.0247, lr=0.000341]a good photo of a <0>\n",
            "Steps:  32% 160/500 [03:10<06:37,  1.17s/it, loss=0.0222, lr=0.00034] a photo of a dirty <0>\n",
            "Steps:  32% 161/500 [03:12<06:29,  1.15s/it, loss=0.0313, lr=0.000339]a rendition of the <0>\n",
            "Steps:  32% 162/500 [03:13<06:24,  1.14s/it, loss=0.216, lr=0.000338] a good photo of the <0>\n",
            "Steps:  33% 163/500 [03:14<06:19,  1.13s/it, loss=0.0126, lr=0.000337]a rendering of a <0>\n",
            "Steps:  33% 164/500 [03:15<06:17,  1.12s/it, loss=0.0283, lr=0.000336]a photo of a small <0>\n",
            "Steps:  33% 165/500 [03:16<06:17,  1.13s/it, loss=0.0154, lr=0.000335]a photo of the large <0>\n",
            "Steps:  33% 166/500 [03:17<06:14,  1.12s/it, loss=0.147, lr=0.000334] the photo of a <0>\n",
            "Steps:  33% 167/500 [03:18<06:17,  1.13s/it, loss=0.0118, lr=0.000333]a rendition of the <0>\n",
            "Steps:  34% 168/500 [03:20<06:26,  1.16s/it, loss=0.106, lr=0.000332] a close-up photo of the <0>\n",
            "Steps:  34% 169/500 [03:21<06:37,  1.20s/it, loss=0.0404, lr=0.000331]a close-up photo of the <0>\n",
            "Steps:  34% 170/500 [03:22<06:42,  1.22s/it, loss=0.0211, lr=0.00033] a rendition of a <0>\n",
            "Steps:  34% 171/500 [03:23<06:45,  1.23s/it, loss=0.0111, lr=0.000329]a photo of the large <0>\n",
            "Steps:  34% 172/500 [03:25<06:46,  1.24s/it, loss=0.0117, lr=0.000328]a cropped photo of the <0>\n",
            "Steps:  35% 173/500 [03:26<06:47,  1.25s/it, loss=0.0306, lr=0.000327]a photo of a dirty <0>\n",
            "Steps:  35% 174/500 [03:27<06:47,  1.25s/it, loss=0.131, lr=0.000326] a photo of a small <0>\n",
            "Steps:  35% 175/500 [03:28<06:48,  1.26s/it, loss=0.0271, lr=0.000325]a photo of one <0>\n",
            "Steps:  35% 176/500 [03:30<06:48,  1.26s/it, loss=0.00849, lr=0.000324]a cropped photo of a <0>\n",
            "Steps:  35% 177/500 [03:31<06:36,  1.23s/it, loss=0.0302, lr=0.000323] a bright photo of the <0>\n",
            "Steps:  36% 178/500 [03:32<06:23,  1.19s/it, loss=0.118, lr=0.000322] a good photo of a <0>\n",
            "Steps:  36% 179/500 [03:33<06:16,  1.17s/it, loss=0.0792, lr=0.000321]a photo of a cool <0>\n",
            "Steps:  36% 180/500 [03:34<06:08,  1.15s/it, loss=0.031, lr=0.00032]  a close-up photo of the <0>\n",
            "Steps:  36% 181/500 [03:35<06:03,  1.14s/it, loss=0.126, lr=0.000319]a photo of my <0>\n",
            "Steps:  36% 182/500 [03:36<06:00,  1.13s/it, loss=0.0639, lr=0.000318]a dark photo of the <0>\n",
            "Steps:  37% 183/500 [03:37<05:57,  1.13s/it, loss=0.0495, lr=0.000317]a bright photo of the <0>\n",
            "Steps:  37% 184/500 [03:39<05:55,  1.12s/it, loss=0.118, lr=0.000316] a dark photo of the <0>\n",
            "Steps:  37% 185/500 [03:40<05:52,  1.12s/it, loss=0.0244, lr=0.000315]a bright photo of the <0>\n",
            "Steps:  37% 186/500 [03:41<05:58,  1.14s/it, loss=0.0335, lr=0.000314]a photo of the cool <0>\n",
            "Steps:  37% 187/500 [03:42<06:12,  1.19s/it, loss=0.0777, lr=0.000313]a photo of a cool <0>\n",
            "Steps:  38% 188/500 [03:43<06:19,  1.22s/it, loss=0.0497, lr=0.000312]a good photo of the <0>\n",
            "Steps:  38% 189/500 [03:45<06:27,  1.25s/it, loss=0.0101, lr=0.000311]a photo of a clean <0>\n",
            "Steps:  38% 190/500 [03:46<06:28,  1.25s/it, loss=0.0772, lr=0.00031] a photo of a cool <0>\n",
            "Steps:  38% 191/500 [03:47<06:28,  1.26s/it, loss=0.013, lr=0.000309]a photo of the cool <0>\n",
            "Steps:  38% 192/500 [03:49<06:26,  1.25s/it, loss=0.0747, lr=0.000308]a photo of the weird <0>\n",
            "Steps:  39% 193/500 [03:50<06:26,  1.26s/it, loss=0.14, lr=0.000307]  a photo of one <0>\n",
            "Steps:  39% 194/500 [03:51<06:25,  1.26s/it, loss=0.0175, lr=0.000306]a good photo of the <0>\n",
            "Steps:  39% 195/500 [03:52<06:24,  1.26s/it, loss=0.0144, lr=0.000305]a good photo of a <0>\n",
            "Steps:  39% 196/500 [03:54<06:09,  1.22s/it, loss=0.141, lr=0.000304] a photo of the small <0>\n",
            "Steps:  39% 197/500 [03:55<05:59,  1.19s/it, loss=0.136, lr=0.000303]a photo of the weird <0>\n",
            "Steps:  40% 198/500 [03:56<05:52,  1.17s/it, loss=0.0503, lr=0.000302]a photo of a small <0>\n",
            "Steps:  40% 199/500 [03:57<05:45,  1.15s/it, loss=0.0118, lr=0.000301]a rendition of a <0>\n",
            "Steps:  40% 200/500 [03:58<05:41,  1.14s/it, loss=0.0436, lr=0.0003]  a photo of a nice <0>\n",
            "Steps:  40% 201/500 [03:59<05:37,  1.13s/it, loss=0.0913, lr=0.000299]a photo of a clean <0>\n",
            "Steps:  40% 202/500 [04:00<05:35,  1.13s/it, loss=0.023, lr=0.000298] a photo of the clean <0>\n",
            "Steps:  41% 203/500 [04:01<05:32,  1.12s/it, loss=0.0205, lr=0.000297]a photo of the small <0>\n",
            "Steps:  41% 204/500 [04:02<05:30,  1.12s/it, loss=0.023, lr=0.000296] a good photo of the <0>\n",
            "Steps:  41% 205/500 [04:04<05:39,  1.15s/it, loss=0.00775, lr=0.000295]a close-up photo of a <0>\n",
            "Steps:  41% 206/500 [04:05<05:47,  1.18s/it, loss=0.0753, lr=0.000294] a cropped photo of the <0>\n",
            "Steps:  41% 207/500 [04:06<05:53,  1.21s/it, loss=0.00803, lr=0.000293]a bright photo of the <0>\n",
            "Steps:  42% 208/500 [04:07<05:57,  1.22s/it, loss=0.0124, lr=0.000292] a photo of a dirty <0>\n",
            "Steps:  42% 209/500 [04:09<06:00,  1.24s/it, loss=0.107, lr=0.000291] a photo of a dirty <0>\n",
            "Steps:  42% 210/500 [04:10<06:01,  1.25s/it, loss=0.0328, lr=0.00029]a rendition of the <0>\n",
            "Steps:  42% 211/500 [04:11<06:02,  1.26s/it, loss=0.0842, lr=0.000289]a good photo of a <0>\n",
            "Steps:  42% 212/500 [04:13<06:04,  1.26s/it, loss=0.0877, lr=0.000288]the photo of a <0>\n",
            "Steps:  43% 213/500 [04:14<06:03,  1.27s/it, loss=0.00665, lr=0.000287]a cropped photo of a <0>\n",
            "Steps:  43% 214/500 [04:15<05:59,  1.26s/it, loss=0.05, lr=0.000286]   a photo of a clean <0>\n",
            "Steps:  43% 215/500 [04:16<05:45,  1.21s/it, loss=0.0348, lr=0.000285]a rendition of the <0>\n",
            "Steps:  43% 216/500 [04:17<05:35,  1.18s/it, loss=0.0698, lr=0.000284]a bright photo of the <0>\n",
            "Steps:  43% 217/500 [04:18<05:28,  1.16s/it, loss=0.0256, lr=0.000283]a photo of the weird <0>\n",
            "Steps:  44% 218/500 [04:19<05:23,  1.15s/it, loss=0.203, lr=0.000282] a photo of the small <0>\n",
            "Steps:  44% 219/500 [04:21<05:18,  1.13s/it, loss=0.00746, lr=0.000281]a photo of the small <0>\n",
            "Steps:  44% 220/500 [04:22<05:15,  1.13s/it, loss=0.0406, lr=0.00028]  a photo of a nice <0>\n",
            "Steps:  44% 221/500 [04:23<05:13,  1.12s/it, loss=0.0155, lr=0.000279]a close-up photo of the <0>\n",
            "Steps:  44% 222/500 [04:24<05:11,  1.12s/it, loss=0.0366, lr=0.000278]a good photo of the <0>\n",
            "Steps:  45% 223/500 [04:25<05:12,  1.13s/it, loss=0.0178, lr=0.000277]a photo of one <0>\n",
            "Steps:  45% 224/500 [04:26<05:20,  1.16s/it, loss=0.00823, lr=0.000276]a good photo of the <0>\n",
            "Steps:  45% 225/500 [04:28<05:26,  1.19s/it, loss=0.0083, lr=0.000275] a dark photo of the <0>\n",
            "Steps:  45% 226/500 [04:29<05:31,  1.21s/it, loss=0.0237, lr=0.000274]a photo of the cool <0>\n",
            "Steps:  45% 227/500 [04:30<05:36,  1.23s/it, loss=0.154, lr=0.000273] a cropped photo of the <0>\n",
            "Steps:  46% 228/500 [04:31<05:37,  1.24s/it, loss=0.0147, lr=0.000272]a photo of the nice <0>\n",
            "Steps:  46% 229/500 [04:33<05:37,  1.24s/it, loss=0.0146, lr=0.000271]a close-up photo of a <0>\n",
            "Steps:  46% 230/500 [04:34<05:37,  1.25s/it, loss=0.0759, lr=0.00027] a photo of the nice <0>\n",
            "Steps:  46% 231/500 [04:35<05:38,  1.26s/it, loss=0.287, lr=0.000269]a photo of the small <0>\n",
            "Steps:  46% 232/500 [04:36<05:38,  1.26s/it, loss=0.0194, lr=0.000268]a photo of the clean <0>\n",
            "Steps:  47% 233/500 [04:38<05:33,  1.25s/it, loss=0.0196, lr=0.000267]a photo of a small <0>\n",
            "Steps:  47% 234/500 [04:39<05:21,  1.21s/it, loss=0.00636, lr=0.000266]a good photo of a <0>\n",
            "Steps:  47% 235/500 [04:40<05:11,  1.18s/it, loss=0.0535, lr=0.000265] a photo of the clean <0>\n",
            "Steps:  47% 236/500 [04:41<05:04,  1.15s/it, loss=0.0111, lr=0.000264]a photo of the <0>\n",
            "Steps:  47% 237/500 [04:42<05:00,  1.14s/it, loss=0.0327, lr=0.000263]a photo of a <0>\n",
            "Steps:  48% 238/500 [04:43<04:58,  1.14s/it, loss=0.0282, lr=0.000262]a cropped photo of the <0>\n",
            "Steps:  48% 239/500 [04:44<04:54,  1.13s/it, loss=0.103, lr=0.000261] a photo of the small <0>\n",
            "Steps:  48% 240/500 [04:45<04:52,  1.13s/it, loss=0.00755, lr=0.00026]a photo of a cool <0>\n",
            "Steps:  48% 241/500 [04:47<04:50,  1.12s/it, loss=0.0988, lr=0.000259]a close-up photo of a <0>\n",
            "Steps:  48% 242/500 [04:48<04:50,  1.13s/it, loss=0.00826, lr=0.000258]a photo of the <0>\n",
            "Steps:  49% 243/500 [04:49<04:57,  1.16s/it, loss=0.00993, lr=0.000257]a dark photo of the <0>\n",
            "Steps:  49% 244/500 [04:50<05:02,  1.18s/it, loss=0.0255, lr=0.000256] a photo of the clean <0>\n",
            "Steps:  49% 245/500 [04:51<05:06,  1.20s/it, loss=0.0147, lr=0.000255]a rendition of a <0>\n",
            "Steps:  49% 246/500 [04:53<05:09,  1.22s/it, loss=0.00862, lr=0.000254]a photo of the nice <0>\n",
            "Steps:  49% 247/500 [04:54<05:10,  1.23s/it, loss=0.228, lr=0.000253]  a photo of the large <0>\n",
            "Steps:  50% 248/500 [04:55<05:12,  1.24s/it, loss=0.293, lr=0.000252]a bright photo of the <0>\n",
            "Steps:  50% 249/500 [04:56<05:11,  1.24s/it, loss=0.0493, lr=0.000251]a cropped photo of a <0>\n",
            "Steps:  50% 250/500 [04:58<05:11,  1.25s/it, loss=0.191, lr=0.00025]  a cropped photo of the <0>\n",
            "Steps:  50% 251/500 [04:59<05:12,  1.26s/it, loss=0.0337, lr=0.000249]a close-up photo of the <0>\n",
            "Steps:  50% 252/500 [05:00<05:10,  1.25s/it, loss=0.0145, lr=0.000248]a photo of the weird <0>\n",
            "Steps:  51% 253/500 [05:01<04:58,  1.21s/it, loss=0.0201, lr=0.000247]a photo of a cool <0>\n",
            "Steps:  51% 254/500 [05:02<04:49,  1.18s/it, loss=0.0119, lr=0.000246]a photo of a small <0>\n",
            "Steps:  51% 255/500 [05:04<04:44,  1.16s/it, loss=0.0843, lr=0.000245]a rendition of a <0>\n",
            "Steps:  51% 256/500 [05:05<04:39,  1.15s/it, loss=0.0888, lr=0.000244]a photo of the weird <0>\n",
            "Steps:  51% 257/500 [05:06<04:35,  1.13s/it, loss=0.0734, lr=0.000243]the photo of a <0>\n",
            "Steps:  52% 258/500 [05:07<04:32,  1.13s/it, loss=0.0473, lr=0.000242]the photo of a <0>\n",
            "Steps:  52% 259/500 [05:08<04:31,  1.13s/it, loss=0.00596, lr=0.000241]a photo of the cool <0>\n",
            "Steps:  52% 260/500 [05:09<04:29,  1.12s/it, loss=0.0276, lr=0.00024]  a dark photo of the <0>\n",
            "Steps:  52% 261/500 [05:10<04:29,  1.13s/it, loss=0.0419, lr=0.000239]a photo of the small <0>\n",
            "Steps:  52% 262/500 [05:11<04:37,  1.16s/it, loss=0.0386, lr=0.000238]a cropped photo of a <0>\n",
            "Steps:  53% 263/500 [05:13<04:44,  1.20s/it, loss=0.00429, lr=0.000237]a cropped photo of a <0>\n",
            "Steps:  53% 264/500 [05:14<04:48,  1.22s/it, loss=0.00779, lr=0.000236]a photo of a small <0>\n",
            "Steps:  53% 265/500 [05:15<04:50,  1.24s/it, loss=0.155, lr=0.000235]  a photo of the nice <0>\n",
            "Steps:  53% 266/500 [05:17<04:51,  1.25s/it, loss=0.0171, lr=0.000234]the photo of a <0>\n",
            "Steps:  53% 267/500 [05:18<04:52,  1.25s/it, loss=0.0148, lr=0.000233]a photo of the cool <0>\n",
            "Steps:  54% 268/500 [05:19<04:51,  1.26s/it, loss=0.251, lr=0.000232] a photo of a clean <0>\n",
            "Steps:  54% 269/500 [05:20<04:50,  1.26s/it, loss=0.0537, lr=0.000231]a close-up photo of a <0>\n",
            "Steps:  54% 270/500 [05:22<04:50,  1.26s/it, loss=0.112, lr=0.00023]  a close-up photo of a <0>\n",
            "Steps:  54% 271/500 [05:23<04:45,  1.25s/it, loss=0.0785, lr=0.000229]a photo of a dirty <0>\n",
            "Steps:  54% 272/500 [05:24<04:34,  1.21s/it, loss=0.00494, lr=0.000228]a photo of a nice <0>\n",
            "Steps:  55% 273/500 [05:25<04:28,  1.18s/it, loss=0.081, lr=0.000227]  a bright photo of the <0>\n",
            "Steps:  55% 274/500 [05:26<04:22,  1.16s/it, loss=0.0104, lr=0.000226]a photo of the clean <0>\n",
            "Steps:  55% 275/500 [05:27<04:17,  1.15s/it, loss=0.00658, lr=0.000225]a photo of the large <0>\n",
            "Steps:  55% 276/500 [05:28<04:14,  1.13s/it, loss=0.0206, lr=0.000224] a photo of the cool <0>\n",
            "Steps:  55% 277/500 [05:30<04:12,  1.13s/it, loss=0.0233, lr=0.000223]a rendition of the <0>\n",
            "Steps:  56% 278/500 [05:31<04:09,  1.12s/it, loss=0.00747, lr=0.000222]a rendition of the <0>\n",
            "Steps:  56% 279/500 [05:32<04:07,  1.12s/it, loss=0.0146, lr=0.000221] a photo of my <0>\n",
            "Steps:  56% 280/500 [05:33<04:07,  1.12s/it, loss=0.145, lr=0.00022]  a close-up photo of a <0>\n",
            "Steps:  56% 281/500 [05:34<04:15,  1.16s/it, loss=0.148, lr=0.000219]a photo of one <0>\n",
            "Steps:  56% 282/500 [05:35<04:20,  1.19s/it, loss=0.02, lr=0.000218] a photo of a nice <0>\n",
            "Steps:  57% 283/500 [05:37<04:23,  1.22s/it, loss=0.039, lr=0.000217]a dark photo of the <0>\n",
            "Steps:  57% 284/500 [05:38<04:26,  1.23s/it, loss=0.23, lr=0.000216] a cropped photo of the <0>\n",
            "Steps:  57% 285/500 [05:39<04:26,  1.24s/it, loss=0.0185, lr=0.000215]a rendering of a <0>\n",
            "Steps:  57% 286/500 [05:40<04:27,  1.25s/it, loss=0.00781, lr=0.000214]a photo of the <0>\n",
            "Steps:  57% 287/500 [05:42<04:27,  1.25s/it, loss=0.0111, lr=0.000213] a dark photo of the <0>\n",
            "Steps:  58% 288/500 [05:43<04:26,  1.26s/it, loss=0.0156, lr=0.000212]a good photo of a <0>\n",
            "Steps:  58% 289/500 [05:44<04:25,  1.26s/it, loss=0.0175, lr=0.000211]a photo of a small <0>\n",
            "Steps:  58% 290/500 [05:46<04:22,  1.25s/it, loss=0.00902, lr=0.00021]a photo of the <0>\n",
            "Steps:  58% 291/500 [05:47<04:13,  1.21s/it, loss=0.0368, lr=0.000209]a bright photo of the <0>\n",
            "Steps:  58% 292/500 [05:48<04:05,  1.18s/it, loss=0.0211, lr=0.000208]a photo of a <0>\n",
            "Steps:  59% 293/500 [05:49<03:59,  1.16s/it, loss=0.0225, lr=0.000207]a photo of the nice <0>\n",
            "Steps:  59% 294/500 [05:50<03:55,  1.14s/it, loss=0.0337, lr=0.000206]a photo of a small <0>\n",
            "Steps:  59% 295/500 [05:51<03:52,  1.13s/it, loss=0.0359, lr=0.000205]a photo of a dirty <0>\n",
            "Steps:  59% 296/500 [05:52<03:50,  1.13s/it, loss=0.0394, lr=0.000204]a photo of the small <0>\n",
            "Steps:  59% 297/500 [05:53<03:48,  1.13s/it, loss=0.0367, lr=0.000203]a photo of a clean <0>\n",
            "Steps:  60% 298/500 [05:54<03:46,  1.12s/it, loss=0.00656, lr=0.000202]a dark photo of the <0>\n",
            "Steps:  60% 299/500 [05:56<03:47,  1.13s/it, loss=0.0292, lr=0.000201] a rendition of a <0>\n",
            "Steps:  60% 300/500 [05:57<03:53,  1.17s/it, loss=0.341, lr=0.0002]   a photo of one <0>\n",
            "Steps:  60% 301/500 [05:58<03:57,  1.20s/it, loss=0.0125, lr=0.000199]a photo of a clean <0>\n",
            "Steps:  60% 302/500 [05:59<04:00,  1.21s/it, loss=0.0325, lr=0.000198]a photo of one <0>\n",
            "Steps:  61% 303/500 [06:01<04:01,  1.23s/it, loss=0.00538, lr=0.000197]a close-up photo of a <0>\n",
            "Steps:  61% 304/500 [06:02<04:01,  1.23s/it, loss=0.0505, lr=0.000196] a photo of the cool <0>\n",
            "Steps:  61% 305/500 [06:03<04:00,  1.23s/it, loss=0.0264, lr=0.000195]a cropped photo of a <0>\n",
            "Steps:  61% 306/500 [06:04<04:01,  1.24s/it, loss=0.00544, lr=0.000194]a dark photo of the <0>\n",
            "Steps:  61% 307/500 [06:06<04:00,  1.24s/it, loss=0.0512, lr=0.000193] a photo of one <0>\n",
            "Steps:  62% 308/500 [06:07<04:00,  1.25s/it, loss=0.00788, lr=0.000192]a photo of a dirty <0>\n",
            "Steps:  62% 309/500 [06:08<03:56,  1.24s/it, loss=0.0199, lr=0.000191] a photo of the large <0>\n",
            "Steps:  62% 310/500 [06:09<03:47,  1.20s/it, loss=0.0049, lr=0.00019] a photo of a small <0>\n",
            "Steps:  62% 311/500 [06:10<03:41,  1.17s/it, loss=0.011, lr=0.000189]a photo of a dirty <0>\n",
            "Steps:  62% 312/500 [06:11<03:36,  1.15s/it, loss=0.00978, lr=0.000188]a close-up photo of a <0>\n",
            "Steps:  63% 313/500 [06:13<03:33,  1.14s/it, loss=0.0299, lr=0.000187] a photo of the large <0>\n",
            "Steps:  63% 314/500 [06:14<03:30,  1.13s/it, loss=0.0457, lr=0.000186]a photo of the clean <0>\n",
            "Steps:  63% 315/500 [06:15<03:28,  1.13s/it, loss=0.018, lr=0.000185] a photo of the cool <0>\n",
            "Steps:  63% 316/500 [06:16<03:27,  1.13s/it, loss=0.185, lr=0.000184]a photo of the nice <0>\n",
            "Steps:  63% 317/500 [06:17<03:26,  1.13s/it, loss=0.0628, lr=0.000183]a photo of my <0>\n",
            "Steps:  64% 318/500 [06:18<03:26,  1.14s/it, loss=0.00777, lr=0.000182]a photo of my <0>\n",
            "Steps:  64% 319/500 [06:19<03:30,  1.16s/it, loss=0.0203, lr=0.000181] a dark photo of the <0>\n",
            "Steps:  64% 320/500 [06:21<03:34,  1.19s/it, loss=0.00389, lr=0.00018]a photo of the <0>\n",
            "Steps:  64% 321/500 [06:22<03:37,  1.21s/it, loss=0.0179, lr=0.000179]the photo of a <0>\n",
            "Steps:  64% 322/500 [06:23<03:39,  1.23s/it, loss=0.0479, lr=0.000178]a rendition of a <0>\n",
            "Steps:  65% 323/500 [06:24<03:39,  1.24s/it, loss=0.0954, lr=0.000177]the photo of a <0>\n",
            "Steps:  65% 324/500 [06:26<03:40,  1.25s/it, loss=0.00711, lr=0.000176]a photo of the cool <0>\n",
            "Steps:  65% 325/500 [06:27<03:41,  1.26s/it, loss=0.0527, lr=0.000175] a photo of a nice <0>\n",
            "Steps:  65% 326/500 [06:28<03:39,  1.26s/it, loss=0.00442, lr=0.000174]a photo of a dirty <0>\n",
            "Steps:  65% 327/500 [06:30<03:38,  1.26s/it, loss=0.00494, lr=0.000173]a rendering of a <0>\n",
            "Steps:  66% 328/500 [06:31<03:35,  1.25s/it, loss=0.00977, lr=0.000172]a close-up photo of a <0>\n",
            "Steps:  66% 329/500 [06:32<03:26,  1.21s/it, loss=0.103, lr=0.000171]  a photo of a clean <0>\n",
            "Steps:  66% 330/500 [06:33<03:20,  1.18s/it, loss=0.00915, lr=0.00017]the photo of a <0>\n",
            "Steps:  66% 331/500 [06:34<03:15,  1.16s/it, loss=0.00901, lr=0.000169]a photo of a clean <0>\n",
            "Steps:  66% 332/500 [06:35<03:11,  1.14s/it, loss=0.0182, lr=0.000168] a photo of the weird <0>\n",
            "Steps:  67% 333/500 [06:36<03:09,  1.13s/it, loss=0.0405, lr=0.000167]a photo of the cool <0>\n",
            "Steps:  67% 334/500 [06:37<03:07,  1.13s/it, loss=0.0248, lr=0.000166]a photo of a nice <0>\n",
            "Steps:  67% 335/500 [06:39<03:05,  1.12s/it, loss=0.0269, lr=0.000165]a bright photo of the <0>\n",
            "Steps:  67% 336/500 [06:40<03:03,  1.12s/it, loss=0.0615, lr=0.000164]a close-up photo of the <0>\n",
            "Steps:  67% 337/500 [06:41<03:03,  1.13s/it, loss=0.0512, lr=0.000163]a good photo of the <0>\n",
            "Steps:  68% 338/500 [06:42<03:09,  1.17s/it, loss=0.0164, lr=0.000162]a photo of my <0>\n",
            "Steps:  68% 339/500 [06:43<03:13,  1.20s/it, loss=0.161, lr=0.000161] a rendition of a <0>\n",
            "Steps:  68% 340/500 [06:45<03:15,  1.22s/it, loss=0.0588, lr=0.00016]a photo of a cool <0>\n",
            "Steps:  68% 341/500 [06:46<03:15,  1.23s/it, loss=0.0243, lr=0.000159]a close-up photo of a <0>\n",
            "Steps:  68% 342/500 [06:47<03:17,  1.25s/it, loss=0.0284, lr=0.000158]a photo of my <0>\n",
            "Steps:  69% 343/500 [06:48<03:17,  1.26s/it, loss=0.0312, lr=0.000157]a rendition of a <0>\n",
            "Steps:  69% 344/500 [06:50<03:17,  1.26s/it, loss=0.0545, lr=0.000156]a bright photo of the <0>\n",
            "Steps:  69% 345/500 [06:51<03:17,  1.27s/it, loss=0.00442, lr=0.000155]a photo of the small <0>\n",
            "Steps:  69% 346/500 [06:52<03:15,  1.27s/it, loss=0.00775, lr=0.000154]a bright photo of the <0>\n",
            "Steps:  69% 347/500 [06:53<03:11,  1.25s/it, loss=0.0201, lr=0.000153] a photo of the large <0>\n",
            "Steps:  70% 348/500 [06:55<03:03,  1.21s/it, loss=0.0182, lr=0.000152]a rendition of the <0>\n",
            "Steps:  70% 349/500 [06:56<02:57,  1.18s/it, loss=0.0202, lr=0.000151]a photo of the small <0>\n",
            "Steps:  70% 350/500 [06:57<02:53,  1.15s/it, loss=0.0345, lr=0.00015] a rendering of a <0>\n",
            "Steps:  70% 351/500 [06:58<02:50,  1.15s/it, loss=0.0986, lr=0.000149]a photo of the weird <0>\n",
            "Steps:  70% 352/500 [06:59<02:48,  1.14s/it, loss=0.00457, lr=0.000148]a photo of a <0>\n",
            "Steps:  71% 353/500 [07:00<02:45,  1.13s/it, loss=0.0898, lr=0.000147] a cropped photo of a <0>\n",
            "Steps:  71% 354/500 [07:01<02:44,  1.12s/it, loss=0.0125, lr=0.000146]a photo of a small <0>\n",
            "Steps:  71% 355/500 [07:02<02:42,  1.12s/it, loss=0.00573, lr=0.000145]a cropped photo of the <0>\n",
            "Steps:  71% 356/500 [07:03<02:41,  1.12s/it, loss=0.0144, lr=0.000144] a photo of the clean <0>\n",
            "Steps:  71% 357/500 [07:05<02:46,  1.16s/it, loss=0.294, lr=0.000143] a photo of a clean <0>\n",
            "Steps:  72% 358/500 [07:06<02:50,  1.20s/it, loss=0.0719, lr=0.000142]a photo of a cool <0>\n",
            "Steps:  72% 359/500 [07:07<02:52,  1.22s/it, loss=0.0126, lr=0.000141]a bright photo of the <0>\n",
            "Steps:  72% 360/500 [07:09<02:53,  1.24s/it, loss=0.0102, lr=0.00014] a photo of the nice <0>\n",
            "Steps:  72% 361/500 [07:10<02:53,  1.25s/it, loss=0.00587, lr=0.000139]a photo of a clean <0>\n",
            "Steps:  72% 362/500 [07:11<02:53,  1.25s/it, loss=0.00589, lr=0.000138]a photo of the nice <0>\n",
            "Steps:  73% 363/500 [07:12<02:52,  1.26s/it, loss=0.0109, lr=0.000137] a rendition of a <0>\n",
            "Steps:  73% 364/500 [07:14<02:51,  1.26s/it, loss=0.156, lr=0.000136] a cropped photo of the <0>\n",
            "Steps:  73% 365/500 [07:15<02:50,  1.26s/it, loss=0.156, lr=0.000135]a rendition of a <0>\n",
            "Steps:  73% 366/500 [07:16<02:46,  1.24s/it, loss=0.0359, lr=0.000134]a rendering of a <0>\n",
            "Steps:  73% 367/500 [07:17<02:40,  1.21s/it, loss=0.032, lr=0.000133] a photo of a nice <0>\n",
            "Steps:  74% 368/500 [07:18<02:35,  1.18s/it, loss=0.0138, lr=0.000132]a good photo of a <0>\n",
            "Steps:  74% 369/500 [07:19<02:31,  1.16s/it, loss=0.11, lr=0.000131]  a photo of my <0>\n",
            "Steps:  74% 370/500 [07:21<02:29,  1.15s/it, loss=0.0159, lr=0.00013]a photo of a <0>\n",
            "Steps:  74% 371/500 [07:22<02:26,  1.14s/it, loss=0.0249, lr=0.000129]a photo of a <0>\n",
            "Steps:  74% 372/500 [07:23<02:24,  1.13s/it, loss=0.00441, lr=0.000128]a close-up photo of a <0>\n",
            "Steps:  75% 373/500 [07:24<02:22,  1.12s/it, loss=0.0393, lr=0.000127] a photo of the nice <0>\n",
            "Steps:  75% 374/500 [07:25<02:21,  1.12s/it, loss=0.167, lr=0.000126] a cropped photo of a <0>\n",
            "Steps:  75% 375/500 [07:26<02:21,  1.13s/it, loss=0.096, lr=0.000125]a cropped photo of a <0>\n",
            "Steps:  75% 376/500 [07:27<02:24,  1.17s/it, loss=0.00864, lr=0.000124]a photo of my <0>\n",
            "Steps:  75% 377/500 [07:29<02:27,  1.20s/it, loss=0.0301, lr=0.000123] a photo of my <0>\n",
            "Steps:  76% 378/500 [07:30<02:28,  1.22s/it, loss=0.0387, lr=0.000122]a dark photo of the <0>\n",
            "Steps:  76% 379/500 [07:31<02:28,  1.23s/it, loss=0.0276, lr=0.000121]a photo of a small <0>\n",
            "Steps:  76% 380/500 [07:32<02:28,  1.24s/it, loss=0.01, lr=0.00012]   a photo of the large <0>\n",
            "Steps:  76% 381/500 [07:34<02:28,  1.24s/it, loss=0.0616, lr=0.000119]a photo of the clean <0>\n",
            "Steps:  76% 382/500 [07:35<02:27,  1.25s/it, loss=0.0148, lr=0.000118]a good photo of the <0>\n",
            "Steps:  77% 383/500 [07:36<02:26,  1.25s/it, loss=0.0177, lr=0.000117]a photo of the small <0>\n",
            "Steps:  77% 384/500 [07:38<02:25,  1.26s/it, loss=0.00492, lr=0.000116]a photo of the nice <0>\n",
            "Steps:  77% 385/500 [07:39<02:22,  1.24s/it, loss=0.0111, lr=0.000115] a rendition of a <0>\n",
            "Steps:  77% 386/500 [07:40<02:16,  1.20s/it, loss=0.00898, lr=0.000114]a dark photo of the <0>\n",
            "Steps:  77% 387/500 [07:41<02:12,  1.17s/it, loss=0.00436, lr=0.000113]a photo of a clean <0>\n",
            "Steps:  78% 388/500 [07:42<02:09,  1.16s/it, loss=0.0106, lr=0.000112] a dark photo of the <0>\n",
            "Steps:  78% 389/500 [07:43<02:06,  1.14s/it, loss=0.0148, lr=0.000111]a good photo of a <0>\n",
            "Steps:  78% 390/500 [07:44<02:04,  1.13s/it, loss=0.0127, lr=0.00011] a photo of one <0>\n",
            "Steps:  78% 391/500 [07:45<02:02,  1.12s/it, loss=0.0121, lr=0.000109]a photo of a <0>\n",
            "Steps:  78% 392/500 [07:46<02:00,  1.12s/it, loss=0.00857, lr=0.000108]a cropped photo of the <0>\n",
            "Steps:  79% 393/500 [07:48<01:59,  1.11s/it, loss=0.0253, lr=0.000107] a photo of the small <0>\n",
            "Steps:  79% 394/500 [07:49<02:00,  1.14s/it, loss=0.0699, lr=0.000106]a photo of one <0>\n",
            "Steps:  79% 395/500 [07:50<02:02,  1.17s/it, loss=0.00577, lr=0.000105]a bright photo of the <0>\n",
            "Steps:  79% 396/500 [07:51<02:05,  1.21s/it, loss=0.0309, lr=0.000104] a photo of a nice <0>\n",
            "Steps:  79% 397/500 [07:53<02:06,  1.23s/it, loss=0.0129, lr=0.000103]a close-up photo of a <0>\n",
            "Steps:  80% 398/500 [07:54<02:06,  1.24s/it, loss=0.0134, lr=0.000102]a close-up photo of a <0>\n",
            "Steps:  80% 399/500 [07:55<02:05,  1.24s/it, loss=0.158, lr=0.000101] a bright photo of the <0>\n",
            "Steps:  80% 400/500 [07:56<02:04,  1.25s/it, loss=0.0404, lr=0.0001] a bright photo of the <0>\n",
            "Steps:  80% 401/500 [07:58<02:04,  1.26s/it, loss=0.0503, lr=9.9e-5]a good photo of the <0>\n",
            "Steps:  80% 402/500 [07:59<02:03,  1.27s/it, loss=0.0126, lr=9.8e-5]a good photo of a <0>\n",
            "Steps:  81% 403/500 [08:00<02:02,  1.26s/it, loss=0.0088, lr=9.7e-5]a photo of my <0>\n",
            "Steps:  81% 404/500 [08:01<01:59,  1.24s/it, loss=0.00468, lr=9.6e-5]a bright photo of the <0>\n",
            "Steps:  81% 405/500 [08:02<01:54,  1.21s/it, loss=0.00557, lr=9.5e-5]a photo of a clean <0>\n",
            "Steps:  81% 406/500 [08:04<01:51,  1.18s/it, loss=0.00445, lr=9.4e-5]a good photo of a <0>\n",
            "Steps:  81% 407/500 [08:05<01:47,  1.16s/it, loss=0.00408, lr=9.3e-5]a cropped photo of the <0>\n",
            "Steps:  82% 408/500 [08:06<01:44,  1.14s/it, loss=0.00561, lr=9.2e-5]the photo of a <0>\n",
            "Steps:  82% 409/500 [08:07<01:43,  1.13s/it, loss=0.00923, lr=9.1e-5]a rendition of a <0>\n",
            "Steps:  82% 410/500 [08:08<01:41,  1.13s/it, loss=0.0937, lr=9e-5]   a photo of a <0>\n",
            "Steps:  82% 411/500 [08:09<01:39,  1.12s/it, loss=0.00646, lr=8.9e-5]a photo of a dirty <0>\n",
            "Steps:  82% 412/500 [08:10<01:38,  1.12s/it, loss=0.0139, lr=8.8e-5] the photo of a <0>\n",
            "Steps:  83% 413/500 [08:11<01:37,  1.13s/it, loss=0.0322, lr=8.7e-5]a good photo of a <0>\n",
            "Steps:  83% 414/500 [08:13<01:39,  1.16s/it, loss=0.0181, lr=8.6e-5]a good photo of the <0>\n",
            "Steps:  83% 415/500 [08:14<01:41,  1.20s/it, loss=0.0332, lr=8.5e-5]a photo of a cool <0>\n",
            "Steps:  83% 416/500 [08:15<01:42,  1.23s/it, loss=0.0284, lr=8.4e-5]a photo of the small <0>\n",
            "Steps:  83% 417/500 [08:16<01:42,  1.24s/it, loss=0.00528, lr=8.3e-5]the photo of a <0>\n",
            "Steps:  84% 418/500 [08:18<01:44,  1.27s/it, loss=0.274, lr=8.2e-5]  a rendition of the <0>\n",
            "Steps:  84% 419/500 [08:19<01:44,  1.29s/it, loss=0.00603, lr=8.1e-5]a photo of my <0>\n",
            "Steps:  84% 420/500 [08:20<01:42,  1.28s/it, loss=0.00547, lr=8e-5]  a photo of the clean <0>\n",
            "Steps:  84% 421/500 [08:22<01:41,  1.28s/it, loss=0.00576, lr=7.9e-5]the photo of a <0>\n",
            "Steps:  84% 422/500 [08:23<01:39,  1.28s/it, loss=0.0158, lr=7.8e-5] a photo of a clean <0>\n",
            "Steps:  85% 423/500 [08:24<01:34,  1.23s/it, loss=0.00498, lr=7.7e-5]a close-up photo of a <0>\n",
            "Steps:  85% 424/500 [08:25<01:30,  1.20s/it, loss=0.00761, lr=7.6e-5]the photo of a <0>\n",
            "Steps:  85% 425/500 [08:26<01:27,  1.17s/it, loss=0.00884, lr=7.5e-5]a good photo of the <0>\n",
            "Steps:  85% 426/500 [08:27<01:25,  1.15s/it, loss=0.0389, lr=7.4e-5] a rendition of a <0>\n",
            "Steps:  85% 427/500 [08:29<01:23,  1.14s/it, loss=0.0521, lr=7.3e-5]a photo of a nice <0>\n",
            "Steps:  86% 428/500 [08:30<01:21,  1.13s/it, loss=0.00892, lr=7.2e-5]a rendering of a <0>\n",
            "Steps:  86% 429/500 [08:31<01:19,  1.12s/it, loss=0.0196, lr=7.1e-5] a photo of the weird <0>\n",
            "Steps:  86% 430/500 [08:32<01:18,  1.12s/it, loss=0.00835, lr=7e-5] a photo of the small <0>\n",
            "Steps:  86% 431/500 [08:33<01:17,  1.12s/it, loss=0.0146, lr=6.9e-5]a bright photo of the <0>\n",
            "Steps:  86% 432/500 [08:34<01:17,  1.14s/it, loss=0.0744, lr=6.8e-5]the photo of a <0>\n",
            "Steps:  87% 433/500 [08:35<01:18,  1.18s/it, loss=0.0132, lr=6.7e-5]a cropped photo of a <0>\n",
            "Steps:  87% 434/500 [08:37<01:19,  1.21s/it, loss=0.0117, lr=6.6e-5]a photo of the weird <0>\n",
            "Steps:  87% 435/500 [08:38<01:19,  1.23s/it, loss=0.0277, lr=6.5e-5]a cropped photo of a <0>\n",
            "Steps:  87% 436/500 [08:39<01:19,  1.24s/it, loss=0.00978, lr=6.4e-5]a photo of the large <0>\n",
            "Steps:  87% 437/500 [08:41<01:18,  1.25s/it, loss=0.0152, lr=6.3e-5] a photo of the weird <0>\n",
            "Steps:  88% 438/500 [08:42<01:18,  1.26s/it, loss=0.0249, lr=6.2e-5]a close-up photo of a <0>\n",
            "Steps:  88% 439/500 [08:43<01:16,  1.26s/it, loss=0.00514, lr=6.1e-5]a dark photo of the <0>\n",
            "Steps:  88% 440/500 [08:44<01:15,  1.26s/it, loss=0.0111, lr=6e-5]   a close-up photo of the <0>\n",
            "Steps:  88% 441/500 [08:46<01:14,  1.25s/it, loss=0.0213, lr=5.9e-5]a rendition of the <0>\n",
            "Steps:  88% 442/500 [08:47<01:10,  1.21s/it, loss=0.0157, lr=5.8e-5]a photo of my <0>\n",
            "Steps:  89% 443/500 [08:48<01:07,  1.18s/it, loss=0.0559, lr=5.7e-5]a photo of my <0>\n",
            "Steps:  89% 444/500 [08:49<01:05,  1.16s/it, loss=0.00712, lr=5.6e-5]a good photo of the <0>\n",
            "Steps:  89% 445/500 [08:50<01:03,  1.15s/it, loss=0.0186, lr=5.5e-5] a photo of the weird <0>\n",
            "Steps:  89% 446/500 [08:51<01:01,  1.14s/it, loss=0.0507, lr=5.4e-5]a close-up photo of the <0>\n",
            "Steps:  89% 447/500 [08:52<00:59,  1.13s/it, loss=0.0138, lr=5.3e-5]a rendition of a <0>\n",
            "Steps:  90% 448/500 [08:53<00:58,  1.12s/it, loss=0.0319, lr=5.2e-5]a photo of my <0>\n",
            "Steps:  90% 449/500 [08:55<00:57,  1.12s/it, loss=0.0312, lr=5.1e-5]a dark photo of the <0>\n",
            "Steps:  90% 450/500 [08:56<00:56,  1.13s/it, loss=0.0949, lr=5e-5]  a photo of the <0>\n",
            "Steps:  90% 451/500 [08:57<00:56,  1.16s/it, loss=0.184, lr=4.9e-5]a photo of a dirty <0>\n",
            "Steps:  90% 452/500 [08:58<00:57,  1.19s/it, loss=0.00759, lr=4.8e-5]a dark photo of the <0>\n",
            "Steps:  91% 453/500 [08:59<00:57,  1.22s/it, loss=0.00643, lr=4.7e-5]a photo of the <0>\n",
            "Steps:  91% 454/500 [09:01<00:56,  1.24s/it, loss=0.0403, lr=4.6e-5] a photo of the large <0>\n",
            "Steps:  91% 455/500 [09:02<00:55,  1.24s/it, loss=0.0681, lr=4.5e-5]a photo of the cool <0>\n",
            "Steps:  91% 456/500 [09:03<00:55,  1.26s/it, loss=0.033, lr=4.4e-5] a photo of a cool <0>\n",
            "Steps:  91% 457/500 [09:05<00:54,  1.27s/it, loss=0.00393, lr=4.3e-5]a rendering of a <0>\n",
            "Steps:  92% 458/500 [09:06<00:53,  1.27s/it, loss=0.0138, lr=4.2e-5] a photo of a nice <0>\n",
            "Steps:  92% 459/500 [09:07<00:52,  1.28s/it, loss=0.00489, lr=4.1e-5]a photo of the large <0>\n",
            "Steps:  92% 460/500 [09:08<00:50,  1.27s/it, loss=0.00397, lr=4e-5]  a close-up photo of the <0>\n",
            "Steps:  92% 461/500 [09:09<00:47,  1.22s/it, loss=0.0495, lr=3.9e-5]a photo of the clean <0>\n",
            "Steps:  92% 462/500 [09:11<00:45,  1.19s/it, loss=0.158, lr=3.8e-5] a rendering of a <0>\n",
            "Steps:  93% 463/500 [09:12<00:43,  1.17s/it, loss=0.0268, lr=3.7e-5]a close-up photo of a <0>\n",
            "Steps:  93% 464/500 [09:13<00:41,  1.15s/it, loss=0.035, lr=3.6e-5] a rendition of the <0>\n",
            "Steps:  93% 465/500 [09:14<00:39,  1.14s/it, loss=0.00606, lr=3.5e-5]a good photo of a <0>\n",
            "Steps:  93% 466/500 [09:15<00:38,  1.13s/it, loss=0.0763, lr=3.4e-5] a photo of the nice <0>\n",
            "Steps:  93% 467/500 [09:16<00:37,  1.12s/it, loss=0.00954, lr=3.3e-5]a good photo of the <0>\n",
            "Steps:  94% 468/500 [09:17<00:35,  1.12s/it, loss=0.0129, lr=3.2e-5] a photo of a dirty <0>\n",
            "Steps:  94% 469/500 [09:18<00:35,  1.13s/it, loss=0.0561, lr=3.1e-5]a photo of the weird <0>\n",
            "Steps:  94% 470/500 [09:20<00:35,  1.17s/it, loss=0.0362, lr=3e-5]  a rendition of the <0>\n",
            "Steps:  94% 471/500 [09:21<00:34,  1.20s/it, loss=0.00783, lr=2.9e-5]a photo of the nice <0>\n",
            "Steps:  94% 472/500 [09:22<00:34,  1.23s/it, loss=0.0049, lr=2.8e-5] a dark photo of the <0>\n",
            "Steps:  95% 473/500 [09:24<00:33,  1.25s/it, loss=0.00685, lr=2.7e-5]a close-up photo of the <0>\n",
            "Steps:  95% 474/500 [09:25<00:32,  1.26s/it, loss=0.0578, lr=2.6e-5] a photo of the small <0>\n",
            "Steps:  95% 475/500 [09:26<00:31,  1.27s/it, loss=0.00539, lr=2.5e-5]the photo of a <0>\n",
            "Steps:  95% 476/500 [09:27<00:30,  1.28s/it, loss=0.00568, lr=2.4e-5]a photo of my <0>\n",
            "Steps:  95% 477/500 [09:29<00:29,  1.28s/it, loss=0.178, lr=2.3e-5]  a close-up photo of the <0>\n",
            "Steps:  96% 478/500 [09:30<00:28,  1.28s/it, loss=0.00745, lr=2.2e-5]a close-up photo of the <0>\n",
            "Steps:  96% 479/500 [09:31<00:26,  1.26s/it, loss=0.0107, lr=2.1e-5] a good photo of a <0>\n",
            "Steps:  96% 480/500 [09:32<00:24,  1.21s/it, loss=0.0124, lr=2e-5]  the photo of a <0>\n",
            "Steps:  96% 481/500 [09:33<00:22,  1.18s/it, loss=0.00486, lr=1.9e-5]the photo of a <0>\n",
            "Steps:  96% 482/500 [09:35<00:20,  1.16s/it, loss=0.0417, lr=1.8e-5] a cropped photo of the <0>\n",
            "Steps:  97% 483/500 [09:36<00:19,  1.15s/it, loss=0.0101, lr=1.7e-5]a close-up photo of a <0>\n",
            "Steps:  97% 484/500 [09:37<00:18,  1.14s/it, loss=0.0055, lr=1.6e-5]a photo of the small <0>\n",
            "Steps:  97% 485/500 [09:38<00:16,  1.13s/it, loss=0.0143, lr=1.5e-5]the photo of a <0>\n",
            "Steps:  97% 486/500 [09:39<00:15,  1.12s/it, loss=0.0311, lr=1.4e-5]a cropped photo of the <0>\n",
            "Steps:  97% 487/500 [09:40<00:14,  1.12s/it, loss=0.0202, lr=1.3e-5]a bright photo of the <0>\n",
            "Steps:  98% 488/500 [09:41<00:13,  1.12s/it, loss=0.0689, lr=1.2e-5]a photo of the weird <0>\n",
            "Steps:  98% 489/500 [09:42<00:12,  1.15s/it, loss=0.0101, lr=1.1e-5]a cropped photo of the <0>\n",
            "Steps:  98% 490/500 [09:44<00:11,  1.19s/it, loss=0.00787, lr=1e-5] a cropped photo of a <0>\n",
            "Steps:  98% 491/500 [09:45<00:10,  1.22s/it, loss=0.0254, lr=9e-6] a photo of the small <0>\n",
            "Steps:  98% 492/500 [09:46<00:09,  1.24s/it, loss=0.0116, lr=8e-6]a close-up photo of the <0>\n",
            "Steps:  99% 493/500 [09:48<00:08,  1.25s/it, loss=0.0198, lr=7e-6]a cropped photo of the <0>\n",
            "Steps:  99% 494/500 [09:49<00:07,  1.26s/it, loss=0.00604, lr=6e-6]a cropped photo of a <0>\n",
            "Steps:  99% 495/500 [09:50<00:06,  1.28s/it, loss=0.0508, lr=5e-6] a close-up photo of a <0>\n",
            "Steps:  99% 496/500 [09:51<00:05,  1.27s/it, loss=0.00612, lr=4e-6]a cropped photo of a <0>\n",
            "Steps:  99% 497/500 [09:53<00:03,  1.27s/it, loss=0.00568, lr=3e-6]a rendition of the <0>\n",
            "Steps: 100% 498/500 [09:54<00:02,  1.24s/it, loss=0.00389, lr=2e-6]a photo of the small <0>\n",
            "Steps: 100% 499/500 [09:55<00:01,  1.21s/it, loss=0.00556, lr=1e-6]a rendering of a <0>\n",
            "Steps: 100% 500/500 [09:56<00:00,  1.18s/it, loss=0.0367, lr=0]    Current Learned Embeddings for <0>:, id 49408  tensor([-0.0123,  0.0013,  0.0139, -0.0125], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Saving weights to ./results/cat_0000/lora/step_500.safetensors\n",
            "LORA Unet Moved 0.004445913713425398\n",
            "LORA CLIP Moved 0.0004234836669638753\n",
            "Current Learned Embeddings for <0>:, id 49408  tensor([-0.0123,  0.0013,  0.0139, -0.0125], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Saving weights to ./results/cat_0000/lora/final_lora.safetensors\n",
            "Steps: 100% 500/500 [09:56<00:00,  1.19s/it, loss=0.0367, lr=0]\n",
            "No module 'xformers'. Proceeding without it.\n",
            "ControlLDM: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Downloading (â€¦)olve/main/vocab.json: 100% 961k/961k [00:00<00:00, 9.99MB/s]\n",
            "Downloading (â€¦)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 56.6MB/s]\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 54.0kB/s]\n",
            "Downloading (â€¦)okenizer_config.json: 100% 905/905 [00:00<00:00, 130kB/s]\n",
            "Downloading (â€¦)lve/main/config.json: 100% 4.52k/4.52k [00:00<00:00, 645kB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.71G/1.71G [00:09<00:00, 171MB/s]\n",
            "Loaded model config from [cldm_v15.yaml]\n",
            "Loaded state_dict from [weights/3DFuse_sparse_depth_injector.ckpt]\n",
            "Downloading (â€¦)ain/model_index.json: 100% 541/541 [00:00<00:00, 276kB/s]\n",
            "Fetching 15 files:   0% 0/15 [00:00<?, ?it/s]\n",
            "Downloading (â€¦)_checker/config.json: 100% 4.72k/4.72k [00:00<00:00, 846kB/s]\n",
            "\n",
            "Downloading (â€¦)rocessor_config.json: 100% 342/342 [00:00<00:00, 63.2kB/s]\n",
            "Fetching 15 files:   7% 1/15 [00:00<00:02,  5.75it/s]\n",
            "Downloading model.safetensors:   0% 0.00/1.22G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading model.safetensors:   1% 10.5M/1.22G [00:00<00:17, 69.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:   2% 21.0M/1.22G [00:00<00:18, 64.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:   3% 31.5M/1.22G [00:00<00:16, 72.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:   3% 41.9M/1.22G [00:00<00:15, 75.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:   4% 52.4M/1.22G [00:00<00:14, 79.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:   5% 62.9M/1.22G [00:00<00:13, 82.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:   6% 73.4M/1.22G [00:00<00:13, 86.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:   7% 83.9M/1.22G [00:01<00:13, 83.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:   8% 94.4M/1.22G [00:01<00:15, 74.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:   9% 105M/1.22G [00:01<00:16, 67.8MB/s] \u001b[A\n",
            "Downloading model.safetensors:   9% 115M/1.22G [00:01<00:15, 72.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  10% 126M/1.22G [00:01<00:14, 77.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  11% 136M/1.22G [00:01<00:13, 77.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  12% 147M/1.22G [00:01<00:13, 81.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  13% 157M/1.22G [00:02<00:12, 83.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  14% 168M/1.22G [00:02<00:13, 78.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  15% 178M/1.22G [00:02<00:13, 75.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  16% 189M/1.22G [00:02<00:13, 76.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  16% 199M/1.22G [00:02<00:13, 75.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  17% 210M/1.22G [00:02<00:13, 73.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  18% 220M/1.22G [00:02<00:12, 78.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  19% 231M/1.22G [00:02<00:12, 82.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  20% 241M/1.22G [00:03<00:11, 83.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  21% 252M/1.22G [00:03<00:12, 78.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  22% 262M/1.22G [00:03<00:12, 76.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  22% 273M/1.22G [00:03<00:11, 81.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  23% 283M/1.22G [00:03<00:11, 84.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  24% 294M/1.22G [00:03<00:10, 85.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  25% 304M/1.22G [00:03<00:10, 86.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  26% 315M/1.22G [00:03<00:10, 86.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  27% 325M/1.22G [00:04<00:10, 86.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  28% 336M/1.22G [00:04<00:10, 84.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  28% 346M/1.22G [00:04<00:10, 84.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  29% 357M/1.22G [00:04<00:10, 78.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  30% 367M/1.22G [00:04<00:10, 80.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  31% 377M/1.22G [00:04<00:11, 75.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  32% 388M/1.22G [00:04<00:11, 75.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  33% 398M/1.22G [00:05<00:10, 76.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  34% 409M/1.22G [00:05<00:10, 78.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  34% 419M/1.22G [00:05<00:09, 81.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  35% 430M/1.22G [00:05<00:10, 76.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  36% 440M/1.22G [00:05<00:10, 75.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  37% 451M/1.22G [00:05<00:09, 79.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  38% 461M/1.22G [00:05<00:09, 79.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  39% 472M/1.22G [00:05<00:09, 81.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  40% 482M/1.22G [00:06<00:09, 81.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  41% 493M/1.22G [00:06<00:09, 72.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  41% 503M/1.22G [00:06<00:09, 74.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  42% 514M/1.22G [00:06<00:11, 62.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  43% 524M/1.22G [00:06<00:11, 61.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  44% 535M/1.22G [00:06<00:10, 63.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  45% 545M/1.22G [00:07<00:13, 48.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  46% 556M/1.22G [00:07<00:11, 56.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  47% 566M/1.22G [00:07<00:11, 57.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  47% 577M/1.22G [00:07<00:11, 56.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  48% 587M/1.22G [00:07<00:10, 61.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  49% 598M/1.22G [00:08<00:09, 62.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  50% 608M/1.22G [00:08<00:09, 66.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  51% 619M/1.22G [00:08<00:08, 71.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 629M/1.22G [00:08<00:07, 74.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  53% 640M/1.22G [00:08<00:07, 73.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  53% 650M/1.22G [00:08<00:08, 65.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  54% 661M/1.22G [00:08<00:07, 70.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  55% 671M/1.22G [00:09<00:07, 74.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  56% 682M/1.22G [00:09<00:07, 67.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  57% 692M/1.22G [00:09<00:08, 62.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  58% 703M/1.22G [00:09<00:08, 63.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  59% 713M/1.22G [00:09<00:07, 67.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  60% 724M/1.22G [00:09<00:07, 69.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  60% 734M/1.22G [00:10<00:06, 71.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  61% 744M/1.22G [00:10<00:06, 76.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  62% 755M/1.22G [00:10<00:05, 79.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  63% 765M/1.22G [00:10<00:05, 81.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  64% 776M/1.22G [00:10<00:05, 83.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  65% 786M/1.22G [00:10<00:05, 79.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  66% 797M/1.22G [00:10<00:06, 61.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  66% 807M/1.22G [00:11<00:05, 68.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  67% 818M/1.22G [00:11<00:05, 73.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  68% 828M/1.22G [00:11<00:04, 78.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  69% 839M/1.22G [00:11<00:04, 82.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  70% 849M/1.22G [00:11<00:04, 80.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  71% 860M/1.22G [00:11<00:04, 82.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  72% 870M/1.22G [00:11<00:04, 82.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  72% 881M/1.22G [00:11<00:04, 81.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  73% 891M/1.22G [00:12<00:04, 72.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  74% 902M/1.22G [00:12<00:04, 69.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  75% 912M/1.22G [00:12<00:04, 70.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  76% 923M/1.22G [00:12<00:03, 74.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  77% 933M/1.22G [00:12<00:04, 70.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  78% 944M/1.22G [00:12<00:03, 76.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  78% 954M/1.22G [00:12<00:03, 71.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  79% 965M/1.22G [00:13<00:03, 73.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  80% 975M/1.22G [00:13<00:03, 75.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  81% 986M/1.22G [00:13<00:02, 79.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  82% 996M/1.22G [00:13<00:02, 82.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  83% 1.01G/1.22G [00:13<00:02, 85.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  84% 1.02G/1.22G [00:13<00:02, 84.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  85% 1.03G/1.22G [00:13<00:02, 84.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  85% 1.04G/1.22G [00:13<00:02, 77.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  86% 1.05G/1.22G [00:14<00:02, 77.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  87% 1.06G/1.22G [00:14<00:02, 60.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  88% 1.07G/1.22G [00:14<00:02, 66.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  89% 1.08G/1.22G [00:14<00:01, 71.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  90% 1.09G/1.22G [00:14<00:01, 72.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  91% 1.10G/1.22G [00:14<00:01, 76.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  91% 1.11G/1.22G [00:14<00:01, 76.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  92% 1.12G/1.22G [00:15<00:01, 69.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  93% 1.13G/1.22G [00:15<00:01, 62.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  94% 1.14G/1.22G [00:15<00:01, 66.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  95% 1.15G/1.22G [00:15<00:00, 71.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  96% 1.16G/1.22G [00:15<00:00, 73.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  97% 1.17G/1.22G [00:15<00:00, 75.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  97% 1.18G/1.22G [00:16<00:00, 69.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  98% 1.20G/1.22G [00:16<00:00, 70.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  99% 1.21G/1.22G [00:16<00:00, 74.4MB/s]\u001b[A\n",
            "Downloading model.safetensors: 100% 1.22G/1.22G [00:16<00:00, 73.7MB/s]\n",
            "Fetching 15 files: 100% 15/15 [00:16<00:00,  1.12s/it]\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in to_q\n",
            "Collapsing Lin Lora in to_k\n",
            "Collapsing Lin Lora in to_v\n",
            "Collapsing Lin Lora in 0\n",
            "Collapsing Lin Lora in proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "Collapsing Lin Lora in k_proj\n",
            "Collapsing Lin Lora in v_proj\n",
            "Collapsing Lin Lora in q_proj\n",
            "Collapsing Lin Lora in out_proj\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}